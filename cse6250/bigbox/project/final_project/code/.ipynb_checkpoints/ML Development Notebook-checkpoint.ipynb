{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/VincentLa/anaconda3/envs/cse6250-project/lib/python3.6/site-packages/psycopg2/__init__.py:144: UserWarning: The psycopg2 wheel package will be renamed from release 2.8; in order to keep installing from binary please use \"pip install psycopg2-binary\" instead. For details see: <http://initd.org/psycopg/docs/install.html#binary-install-from-pypi>.\n",
      "  \"\"\")\n"
     ]
    }
   ],
   "source": [
    "import datetime as dt\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import interp\n",
    "import scipy.stats as stats\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, auc, confusion_matrix, roc_curve, average_precision_score, precision_recall_curve\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import sqlalchemy as sa\n",
    "from sqlalchemy import create_engine\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "sys.path.append('../')\n",
    "from utilities import sql_utils as su\n",
    "from utilities import model_eval_utils as meu\n",
    "\n",
    "DWH = os.getenv('MIMIC_DWH')\n",
    "engine = create_engine(DWH)\n",
    "\n",
    "pd.options.display.max_columns = 1000\n",
    "pd.options.display.max_rows = 1000\n",
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "QUERY = \"\"\"\n",
    "select\n",
    "  *\n",
    "from datasets.model_demog_dx\n",
    "\"\"\"\n",
    "with engine.begin() as conn:\n",
    "    df = pd.read_sql(QUERY, conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring The Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.hospital_expire_flag.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('insurance').describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def split_dataset(dataset, train_percentage, feature_headers, target_header):\n",
    "    \"\"\"\n",
    "    Split the dataset with train_percentage\n",
    "    \n",
    "    Keyword Args:\n",
    "    dataset: The Actual Dataset\n",
    "    train_percentage: Percentage of Dataset to split into Training\n",
    "    feature_headers: columns that are features to include\n",
    "    target_header: column that is the outcome variable of interest\n",
    "    :return: train_x, test_x, train_y, test_y\n",
    "    \"\"\"\n",
    "\n",
    "    # Split dataset into train and test dataset\n",
    "    train_x, test_x, train_y, test_y = train_test_split(dataset[feature_headers],\n",
    "                                                        dataset[target_header],\n",
    "                                                        train_size=train_percentage)\n",
    "    return train_x, test_x, train_y, test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "admission_type_dummies = \\\n",
    "    pd.get_dummies(df.admission_type, prefix='admission_type', dummy_na=True)\n",
    "insurance_dummies = \\\n",
    "    pd.get_dummies(df.insurance, prefix='insurance', dummy_na=True)\n",
    "language_dummies = \\\n",
    "    pd.get_dummies(df.language, prefix='language', dummy_na=True)\n",
    "marital_dummies = \\\n",
    "    pd.get_dummies(df.marital_status, prefix='marital', dummy_na=True)\n",
    "ethnicity_dummies = \\\n",
    "    pd.get_dummies(df.ethnicity, prefix='ethnicity', dummy_na=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_model = pd.concat([df, admission_type_dummies, insurance_dummies,\n",
    "                     language_dummies, marital_dummies, ethnicity_dummies], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_header = 'hospital_expire_flag'\n",
    "demog_features = ['is_male',\n",
    "                  # 'age_at_admit',\n",
    "                 ]\n",
    "ccs_features = [c for c in df.columns if 'ccs' in c]\n",
    "feature_headers = list(admission_type_dummies.columns) +\\\n",
    "                  list(insurance_dummies.columns) +\\\n",
    "                  list(language_dummies.columns) +\\\n",
    "                  list(marital_dummies.columns) +\\\n",
    "                  list(ethnicity_dummies.columns) +\\\n",
    "                  demog_features + ccs_features\n",
    "X = df_model.loc[:, feature_headers]\n",
    "y = df_model.hospital_expire_flag\n",
    "train_x, test_x, train_y, test_y = split_dataset(df_model, 0.7, feature_headers, target_header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and Test dataset size details\n",
    "print(\"Train_x Shape :: \", train_x.shape)\n",
    "print(\"Train_y Shape :: \", train_y.shape)\n",
    "print(\"Test_x Shape :: \", test_x.shape)\n",
    "print(\"Test_y Shape :: \", test_y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier()\n",
    "trained_model = clf.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Run classifier with cross-validation and plot ROC curves\n",
    "cv = StratifiedKFold(n_splits=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating ROC Curve with Cross Validation\n",
    "meu.draw_cv_roc_curve(clf, cv, train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting Precision Recall Curve\n",
    "meu.plot_precision_recall_curve(clf, test_x, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions = trained_model.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and Test Accuracy\n",
    "print(\"Train Accuracy :: \", accuracy_score(train_y, trained_model.predict(train_x)))\n",
    "print(\"Test Accuracy  :: \", accuracy_score(test_y, predictions))\n",
    "print(\" Confusion matrix \", confusion_matrix(test_y, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meu.show_confusion_matrix(confusion_matrix(test_y, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = trained_model.feature_importances_\n",
    "std = np.std([tree.feature_importances_ for tree in trained_model.estimators_], axis=0)\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "# Print the feature ranking\n",
    "print(\"Feature ranking:\")\n",
    "\n",
    "#for f in range(train_x.shape[1]):\n",
    "for f in range(25): \n",
    "    column = train_x.columns[indices[f]]\n",
    "    print(\"{ranking}. feature {column} ({importance})\".format(ranking=f+1,\n",
    "                                                             column=column,\n",
    "                                                             importance=importances[indices[f]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the feature importances of the forest\n",
    "top_features = 10\n",
    "plt.figure(figsize=(20, 10))\n",
    "plt.title(\"Feature importances\")\n",
    "plt.bar(range(top_features),\n",
    "        importances[indices[0:top_features]],\n",
    "        color=\"r\",\n",
    "        yerr=std[indices[0:top_features]],\n",
    "        align=\"center\")\n",
    "plt.xticks(range(top_features), train_x.columns[indices[0:top_features]])\n",
    "plt.xlim([-1, top_features])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (cse6250-project)",
   "language": "python",
   "name": "cse6250-project"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
