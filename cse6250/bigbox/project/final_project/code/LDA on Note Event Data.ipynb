{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/VincentLa/anaconda3/envs/cse6250-project/lib/python3.6/site-packages/psycopg2/__init__.py:144: UserWarning: The psycopg2 wheel package will be renamed from release 2.8; in order to keep installing from binary please use \"pip install psycopg2-binary\" instead. For details see: <http://initd.org/psycopg/docs/install.html#binary-install-from-pypi>.\n",
      "  \"\"\")\n"
     ]
    }
   ],
   "source": [
    "import datetime as dt\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import interp\n",
    "import scipy.stats as stats\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, auc, confusion_matrix, roc_curve, average_precision_score, precision_recall_curve\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import sqlalchemy as sa\n",
    "from sqlalchemy import create_engine\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "sys.path.append('../')\n",
    "from utilities import sql_utils as su\n",
    "from utilities import model_eval_utils as meu\n",
    "\n",
    "DWH = os.getenv('MIMIC_DWH')\n",
    "engine = create_engine(DWH)\n",
    "\n",
    "pd.options.display.max_columns = 1000\n",
    "pd.options.display.max_rows = 1000\n",
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "QUERY = \"\"\"\n",
    "select\n",
    "  subject_id,\n",
    "  hadm_id,\n",
    "  chartdate,\n",
    "  text\n",
    "from mimiciii.noteevents\n",
    "limit 200000\n",
    "\"\"\"\n",
    "with engine.connect() as conn:\n",
    "    df = pd.read_sql(QUERY, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200000, 4)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject_id</th>\n",
       "      <th>hadm_id</th>\n",
       "      <th>chartdate</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22532</td>\n",
       "      <td>167853.000</td>\n",
       "      <td>2151-08-04</td>\n",
       "      <td>Admission Date:  [**2151-7-16**]       Dischar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13702</td>\n",
       "      <td>107527.000</td>\n",
       "      <td>2118-06-14</td>\n",
       "      <td>Admission Date:  [**2118-6-2**]       Discharg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13702</td>\n",
       "      <td>167118.000</td>\n",
       "      <td>2119-05-25</td>\n",
       "      <td>Admission Date:  [**2119-5-4**]              D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13702</td>\n",
       "      <td>196489.000</td>\n",
       "      <td>2124-08-18</td>\n",
       "      <td>Admission Date:  [**2124-7-21**]              ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>26880</td>\n",
       "      <td>135453.000</td>\n",
       "      <td>2162-03-25</td>\n",
       "      <td>Admission Date:  [**2162-3-3**]              D...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   subject_id    hadm_id  chartdate  \\\n",
       "0       22532 167853.000 2151-08-04   \n",
       "1       13702 107527.000 2118-06-14   \n",
       "2       13702 167118.000 2119-05-25   \n",
       "3       13702 196489.000 2124-08-18   \n",
       "4       26880 135453.000 2162-03-25   \n",
       "\n",
       "                                                text  \n",
       "0  Admission Date:  [**2151-7-16**]       Dischar...  \n",
       "1  Admission Date:  [**2118-6-2**]       Discharg...  \n",
       "2  Admission Date:  [**2119-5-4**]              D...  \n",
       "3  Admission Date:  [**2124-7-21**]              ...  \n",
       "4  Admission Date:  [**2162-3-3**]              D...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/VincentLa/anaconda3/envs/cse6250-project/lib/python3.6/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "data_text = df[['text']]\n",
    "data_text['index'] = data_text.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Admission Date:  [**2151-7-16**]       Dischar...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Admission Date:  [**2118-6-2**]       Discharg...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Admission Date:  [**2119-5-4**]              D...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Admission Date:  [**2124-7-21**]              ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Admission Date:  [**2162-3-3**]              D...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  index\n",
       "0  Admission Date:  [**2151-7-16**]       Dischar...      0\n",
       "1  Admission Date:  [**2118-6-2**]       Discharg...      1\n",
       "2  Admission Date:  [**2119-5-4**]              D...      2\n",
       "3  Admission Date:  [**2124-7-21**]              ...      3\n",
       "4  Admission Date:  [**2162-3-3**]              D...      4"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_text.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "documents = data_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Admission Date:  [**2151-7-16**]       Dischar...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Admission Date:  [**2118-6-2**]       Discharg...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Admission Date:  [**2119-5-4**]              D...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Admission Date:  [**2124-7-21**]              ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Admission Date:  [**2162-3-3**]              D...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  index\n",
       "0  Admission Date:  [**2151-7-16**]       Dischar...      0\n",
       "1  Admission Date:  [**2118-6-2**]       Discharg...      1\n",
       "2  Admission Date:  [**2119-5-4**]              D...      2\n",
       "3  Admission Date:  [**2124-7-21**]              ...      3\n",
       "4  Admission Date:  [**2162-3-3**]              D...      4"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200000\n",
      "                                                text  index\n",
      "0  Admission Date:  [**2151-7-16**]       Dischar...      0\n",
      "1  Admission Date:  [**2118-6-2**]       Discharg...      1\n",
      "2  Admission Date:  [**2119-5-4**]              D...      2\n",
      "3  Admission Date:  [**2124-7-21**]              ...      3\n",
      "4  Admission Date:  [**2162-3-3**]              D...      4\n"
     ]
    }
   ],
   "source": [
    "print(len(documents))\n",
    "print(documents[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Tokenization: Split the text into sentences and the sentences into words. Lowercase the words and remove punctuation.\n",
    "2. Words that have fewer than 3 characters are removed.\n",
    "3. All stopwords are removed.\n",
    "4. Words are lemmatized — words in third person are changed to first person and verbs in past and future tenses are changed into present.\n",
    "5. Words are stemmed — words are reduced to their root form."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading gensim and nltk libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/VincentLa/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
    "from nltk.stem.porter import *\n",
    "# import nltk.stem as stemmer\n",
    "import numpy as np\n",
    "np.random.seed(2018)\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "\n",
    "stemmer = SnowballStemmer('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lemmatize_stemming(text):\n",
    "    \"\"\"\n",
    "    Lemmatize: lemmatized — words in third person are changed to first person\n",
    "    \n",
    "    Verbs in past and future tenses are changed into present.\n",
    "    \"\"\"\n",
    "    return stemmer.stem(WordNetLemmatizer().lemmatize(text, pos='v'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    \"\"\"\n",
    "    Preprocess Text:\n",
    "    \n",
    "    Remove words in \"STOPWORDS\" and remove words 3 letters or less\n",
    "    \"\"\"\n",
    "    result = []\n",
    "    for token in gensim.utils.simple_preprocess(text):\n",
    "        if token not in gensim.parsing.preprocessing.STOPWORDS and len(token) > 3:\n",
    "            result.append(lemmatize_stemming(token))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original document: \n",
      "['Admission', 'Date:', '', '[**2171-5-6**]', '', '', '', '', 'Discharge', 'Date:', '', '[**2171-5-8**]\\n\\nDate', 'of', 'Birth:', '', '', '[**2147-8-13**]', '', '', '', '', 'Sex:', '', 'F\\n\\nService:', '', '[**Hospital1', '212**]\\n\\nCHIEF', 'COMPLAINT:', '', 'Hypoxia,', 'hemoptysis,', 'fever.\\n\\nHISTORY', 'OF', 'PRESENT', 'ILLNESS:', '', 'This', 'is', 'a', '23', 'year', 'old', 'woman', 'with\\nSLE,', 'lupus', 'nephritis,', 'end', 'stage', 'renal', 'disease', 'on\\nhemodialysis,', 'warm', 'antibody', 'hemolytic', 'anemia', 'on', '50', 'mg', 'of\\nprednisone', 'times', 'one', 'month', 'who', 'was', 'in', 'her', 'usual', 'state', 'of\\nhealth', 'until', 'Friday,', '[**2171-5-3**],', 'when', 'she', 'developed', 'a', 'cough.\\nShe', 'was', 'otherwise', 'well', 'and', 'was', 'able', 'to', 'undergo', 'all', 'her', 'normal\\nweekend', 'activities', 'until', 'the', 'morning', 'of', '[**5-6**]', 'when', 'she\\ndeveloped', 'fever,', 'chills,', 'a', 'few', 'teaspoons', 'of', 'hemoptysis', 'and\\nright', 'upper', 'quadrant', 'pain.', '', 'She', 'was', 'brought', 'to', 'the', 'emergency\\nroom', 'where', 'she', 'had', 'sats', 'of', '82%', 'in', 'room', 'air', 'which', 'then\\nimproved', 'to', '97%', 'on', '4', 'liters.', '', 'She', 'has', 'respiratory', 'rate', 'in', 'the\\n50s', 'and', 'T-max', 'up', 'to', '102.', '', 'She', 'was', 'given', 'ceftriaxone,\\nLopressor', '25', 'and', 'Tylenol.', '', 'Right', 'upper', 'quadrant', 'and', 'shortness\\nof', 'breath', 'improved.\\n\\nPAST', 'MEDICAL', 'HISTORY:', '', 'Notable', 'for', 'SLE', 'which', 'was', 'diagnosed', 'in\\n3/97', 'and', 'treated', 'with', 'prednisone,', '....................', 'and\\ncyclophosphamide.', '', 'Warm', 'antibody', 'hemolytic', 'anemia', 'diagnosed\\nin', '[**4-9**]', 'on', 'prednisone', 'taper', 'initially', 'of', '60', 'mg', 'times', 'one\\nmonth,', 'now', 'on', '50', 'mg.', '', 'End', 'stage', 'renal', 'disease', 'on', 'hemodialysis\\nsince', '[**2166**].', '', 'Pneumococcal', 'sepsis', 'in', '10/97', 'status', 'post\\nintubation.', '', 'Sickle', 'cell', 'trait.', '', 'Status', 'post', 'VSD', 'repair', 'in\\n3/97.', '', 'Status', 'post', 'LSO', 'secondary', 'to', '[**Last', 'Name', '(un)', '**]', 'in', '1/97.', '', 'History', 'of\\nC.diff.', '', 'Hypertension.\\n\\nALLERGIES:', '', 'Demerol', 'from', 'which', 'she', 'gets', 'angioedema.\\nVancomycin.\\n\\nMEDICATIONS:', '', 'Include', 'prednisone', '50', 'mg', 'q.d.,', 'Nephrocaps', 'one\\ntab', 'q.d.,', 'Rocaltrol,', 'Epogen', '15,000', 'units', 'IV', 'Monday,\\nWednesday,', 'Friday', 'at', 'hemodialysis,', 'Procardia', 'XL', '60', 'mg', 'q.d.,\\nPrilosec', '20', 'mg', 'p.o.', 'q.d.,', 'Tums', '1', 'gm', 'p.o.', 't.i.d.', 'with', 'meals,\\nInFeD', '50', 'mg', 'IV', 'q.Wednesday', 'at', 'hemodialysis.\\n\\nPHYSICAL', 'EXAMINATION:', '', 'On', '[**5-7**]', 'on', 'transfer', 'to', 'the', 'medical\\nservice', 'vitals', 'were', 'temperature', 'of', '99.1,', 'heart', 'rate', '110,\\nrespiratory', 'rate', '20,', 'blood', 'pressure', '140/100,', 'O2', '96%', 'in', 'room\\nair.', '', 'Generally', 'she', 'was', 'comfortable', 'looking,', 'cushingoid\\nfacies.', '', 'HEENT:', 'throat', 'was', 'clear,', 'no', 'erythema.', '', 'Moist', 'mucous\\nmembranes.', '', 'No', 'cervical', 'or', 'inguinal', 'lymphadenopathy.', '', 'CV\\ntachycardic,', 'normal', 'S1,', 'S2,', 'no', 'murmur.', '', 'Pulmonary:', 'rales\\nbilaterally', 'half', 'way', 'up,', 'no', 'egophony,', 'positive', 'dullness', 'at\\nright', 'base.', '', 'Abdomen', 'was', 'soft,', 'slightly', 'tender', 'in', 'the', 'right\\nupper', 'quadrant', 'with', 'deep', 'palpation,', 'positive', 'bowel', 'sounds.\\nExtremities', 'had', 'no', 'edema', 'or', 'rash.\\n\\nLABORATORY', 'DATA:', '', 'Notable', 'for', 'white', 'count', 'of', '18.4,', 'hemoglobin\\n12.0,', 'hematocrit', '39.3,', 'platelets', '56.', '', 'Differential', 'showed', '77\\nneutrophils,', '1', 'band,', '15', 'lymphocytes,', '5', 'monos,', '2', 'eosinophils.\\nSodium', 'was', '138,', 'potassium', '5.7', 'with', 'repeat', 'of', '5.3,', 'chloride\\n102,', 'CO2', '19,', 'BUN', '39,', 'creatinine', '8.9,', 'glucose', '109.', '', 'ALT', 'was\\n232,', 'AST', '96,', 'alka', 'phos', '93,', 'lipase', '25,', 'total', 'bili', '0.03.\\nLegionella', 'antigen', 'was', 'negative.', '', 'Sputum', 'showed', 'greater', 'than\\n25', 'polys,', '3+', 'gram', 'positive', 'cocci,', '3+', 'gram', 'negative', 'rods.\\nChest', 'x-ray', 'showed', 'right', 'lower', 'lobe', 'dense', 'infiltrate', 'with\\nsmall', 'effusion.', '', 'Abdominal', 'ultrasound', 'showed', 'liver', 'diffusely\\nhypoechoic,', 'focal', 'echogenicity', 'relative', 'around', 'the', 'portal\\ntriad', 'in', 'a', 'starry', '[**Hospital', 'Ward', 'Name', '**]', 'pattern,', 'no', 'focal', 'mass,', 'no', 'intrahepatic\\nbiliary', 'ductal', 'dilatation.', '', 'Common', 'bile', 'duct', 'measured', '4.\\nGallbladder', 'was', 'abnormal', 'with', 'thickened', 'wall', 'and', 'edematous.\\nNo', 'fluid', 'collection.', '', 'Impression', 'was', 'hepatitis.\\n\\nHOSPITAL', 'COURSE:', '', 'The', 'patient', 'was', 'initially', 'admitted', 'to', 'the\\nMICU', 'where', 'she', 'did', 'well', 'overnight.', '', 'Her', 'O2', 'was', 'weaned', 'and', 'in\\nthe', 'a.m.', 'on', '[**5-7**]', 'she', 'was', 'sating', '96%', 'in', 'room', 'air.', '', 'On', '[**5-7**]\\na.m.', 'she', 'was', 'transferred', 'to', 'the', 'medical', 'floor', 'at', 'which', 'time\\nshe', 'continued', 'to', 'improve', 'on', 'levofloxacin', '250', 'mg.', '', 'She\\nreceived', 'the', 'first', 'dose', 'of', 'levofloxacin', 'on', '[**5-6**].', '', 'She\\nreceived', 'the', 'second', 'dose', 'of', '250', 'mg', 'on', '[**5-7**]', 'and', 'because', 'of\\nhemodialysis,', 'the', 'next', 'dose', 'was', 'scheduled', 'for', '[**5-9**].\\n\\nBy', 'the', 'morning', 'of', '[**5-8**]', 'the', 'patient', 'was', 'well', 'appearing,', 'sating\\n97%', 'in', 'room', 'air,', 'eating', 'well.', '', 'The', 'right', 'upper', 'quadrant', 'pain\\nhad', 'largely', 'resolved.', '', 'The', 'patient', 'only', 'complained', 'of', 'mild\\ntenderness', 'on', 'deep', 'palpation.', '', 'Transaminases', 'began', 'trending\\ndown.', '', 'ALT', 'dropped', 'to', '170,', 'AST', 'to', '46.', '', 'Blood', 'cultures', 'were\\npending', 'at', 'the', 'time', 'of', 'discharge.', '', 'Urine', 'culture', 'was\\nnegative.', '', 'The', 'patient', 'was', 'discharged', 'home', 'on', '[**5-8**]', 'after\\nhemodialysis', 'with', 'plans', 'to', 'follow', 'up', 'with', 'Dr.', '[**Last', 'Name', '(STitle)', '**]', 'on', '[**5-14**].\\n\\nIssues', 'at', 'time', 'of', 'discharge', 'included', '(1)', 'community', 'acquired\\npneumonia.', '', 'Plan', 'is', 'for', 'the', 'patient', 'to', 'finish', 'a', '14', 'day', 'course\\nof', 'levofloxacin.', '', '(2)', 'Cardiac', 'issues.', '', 'The', 'patient', 'was\\nstable.', '', 'Blood', 'pressure', 'was', 'adequately', 'controlled', 'on\\nProcardia', 'XL.', '', 'Tachycardia', 'resolved', 'and', 'was', 'likely', 'secondary\\nto', 'infection.', '', 'EKG', 'on', 'admission', 'showed', 'no', 'changes.', '', '(3)', 'GI.\\nThe', 'patient', 'was', 'tolerating', 'full', 'diet', 'with', 'no', 'complaints', 'of\\nabdominal', 'pain.', '', 'Dr.', '[**Last', 'Name', '(STitle)', '**]', 'will', 'follow', 'up', 'the', \"patient's\\ntransaminases\", 'as', 'an', 'outpatient.', '', 'Hepatitis', 'serologies', 'for\\nhepatitis', 'A', 'and', 'C', 'were', 'ordered', 'and', 'will', 'be', 'followed', 'up', 'by\\nDr.', '[**Last', 'Name', '(STitle)', '**].', '', '(4)', 'Hematology.', '', 'Anemia', 'of', 'mixed', 'etiology', 'warm\\nantibody', 'hemolytic', 'anemia', 'and', 'anemia', 'secondary', 'to', 'chronic\\ndisease', 'followed', 'by', 'Dr.', '[**Last', 'Name', '(STitle)', '**].', '', 'The', 'patient', 'will', 'continue', 'to\\ntake', 'iron,', 'Epogen', 'and', 'prednisone.\\n\\nThe', 'patient', 'was', 'discharged', 'in', 'stable', 'condition.', '', 'The', 'patient\\nwas', 'discharged', 'home.\\n\\nDISCHARGE', 'DIAGNOSIS:', '', 'Community', 'acquired', 'pneumonia.\\n\\n\\n\\n', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '[**Doctor', 'First', 'Name', '306**]', 'C-', '[**Name8', '(MD)', '308**],', 'M.D.', '', '[**MD', 'Number(1)', '11871**]\\n\\nDictated', 'By:[**Doctor', 'Last', 'Name', '18598**]\\n\\nMEDQUIST36\\n\\nD:', '', '[**2171-5-8**]', '', '22:34\\nT:', '', '[**2171-5-10**]', '', '15:24\\nJOB#:', '', '[**Job', 'Number', '18599**]\\n']\n",
      "\n",
      "\n",
      " tokenized and lemmatized document: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['admiss', 'date', 'discharg', 'date', 'date', 'birth', 'servic', 'hospit', 'chief', 'complaint', 'hypoxia', 'hemoptysi', 'fever', 'histori', 'present', 'ill', 'year', 'woman', 'lupus', 'nephriti', 'stage', 'renal', 'diseas', 'hemodialysi', 'warm', 'antibodi', 'hemolyt', 'anemia', 'prednison', 'time', 'month', 'usual', 'state', 'health', 'friday', 'develop', 'cough', 'abl', 'undergo', 'normal', 'weekend', 'activ', 'morn', 'develop', 'fever', 'chill', 'teaspoon', 'hemoptysi', 'right', 'upper', 'quadrant', 'pain', 'bring', 'emerg', 'room', 'sat', 'room', 'improv', 'liter', 'respiratori', 'rate', 'give', 'ceftriaxon', 'lopressor', 'tylenol', 'right', 'upper', 'quadrant', 'short', 'breath', 'improv', 'past', 'medic', 'histori', 'notabl', 'diagnos', 'treat', 'prednison', 'warm', 'antibodi', 'hemolyt', 'anemia', 'diagnos', 'prednison', 'taper', 'initi', 'time', 'month', 'stage', 'renal', 'diseas', 'hemodialysi', 'pneumococc', 'sepsi', 'status', 'post', 'intub', 'sickl', 'cell', 'trait', 'status', 'post', 'repair', 'status', 'post', 'secondari', 'histori', 'diff', 'hypertens', 'allergi', 'demerol', 'get', 'angioedema', 'vancomycin', 'medic', 'includ', 'prednison', 'nephrocap', 'rocaltrol', 'epogen', 'unit', 'monday', 'wednesday', 'friday', 'hemodialysi', 'procardia', 'prilosec', 'tum', 'meal', 'inf', 'wednesday', 'hemodialysi', 'physic', 'examin', 'transfer', 'medic', 'servic', 'vital', 'temperatur', 'heart', 'rate', 'respiratori', 'rate', 'blood', 'pressur', 'room', 'general', 'comfort', 'look', 'cushingoid', 'faci', 'heent', 'throat', 'clear', 'erythema', 'moist', 'mucous', 'membran', 'cervic', 'inguin', 'lymphadenopathi', 'tachycard', 'normal', 'murmur', 'pulmonari', 'rale', 'bilater', 'half', 'egophoni', 'posit', 'dull', 'right', 'base', 'abdomen', 'soft', 'slight', 'tender', 'right', 'upper', 'quadrant', 'deep', 'palpat', 'posit', 'bowel', 'sound', 'extrem', 'edema', 'rash', 'laboratori', 'data', 'notabl', 'white', 'count', 'hemoglobin', 'hematocrit', 'platelet', 'differenti', 'show', 'neutrophil', 'band', 'lymphocyt', 'mono', 'eosinophil', 'sodium', 'potassium', 'repeat', 'chlorid', 'creatinin', 'glucos', 'alka', 'phos', 'lipas', 'total', 'bili', 'legionella', 'antigen', 'negat', 'sputum', 'show', 'greater', 'poli', 'gram', 'posit', 'cocci', 'gram', 'negat', 'rod', 'chest', 'show', 'right', 'lower', 'lobe', 'dens', 'infiltr', 'small', 'effus', 'abdomin', 'ultrasound', 'show', 'liver', 'diffus', 'hypoecho', 'focal', 'echogen', 'relat', 'portal', 'triad', 'starri', 'hospit', 'ward', 'pattern', 'focal', 'mass', 'intrahepat', 'biliari', 'ductal', 'dilat', 'common', 'bile', 'duct', 'measur', 'gallbladd', 'abnorm', 'thicken', 'wall', 'edemat', 'fluid', 'collect', 'impress', 'hepat', 'hospit', 'cours', 'patient', 'initi', 'admit', 'micu', 'overnight', 'wean', 'sate', 'room', 'transfer', 'medic', 'floor', 'time', 'continu', 'improv', 'levofloxacin', 'receiv', 'dose', 'levofloxacin', 'receiv', 'second', 'dose', 'hemodialysi', 'dose', 'schedul', 'morn', 'patient', 'appear', 'sate', 'room', 'eat', 'right', 'upper', 'quadrant', 'pain', 'larg', 'resolv', 'patient', 'complain', 'mild', 'tender', 'deep', 'palpat', 'transaminas', 'begin', 'trend', 'drop', 'blood', 'cultur', 'pend', 'time', 'discharg', 'urin', 'cultur', 'negat', 'patient', 'discharg', 'home', 'hemodialysi', 'plan', 'follow', 'stitl', 'issu', 'time', 'discharg', 'includ', 'communiti', 'acquir', 'pneumonia', 'plan', 'patient', 'finish', 'cours', 'levofloxacin', 'cardiac', 'issu', 'patient', 'stabl', 'blood', 'pressur', 'adequ', 'control', 'procardia', 'tachycardia', 'resolv', 'like', 'secondari', 'infect', 'admiss', 'show', 'chang', 'patient', 'toler', 'diet', 'complaint', 'abdomin', 'pain', 'stitl', 'follow', 'patient', 'transaminas', 'outpati', 'hepat', 'serolog', 'hepat', 'order', 'follow', 'stitl', 'hematolog', 'anemia', 'mix', 'etiolog', 'warm', 'antibodi', 'hemolyt', 'anemia', 'anemia', 'secondari', 'chronic', 'diseas', 'follow', 'stitl', 'patient', 'continu', 'iron', 'epogen', 'prednison', 'patient', 'discharg', 'stabl', 'condit', 'patient', 'discharg', 'home', 'discharg', 'diagnosi', 'communiti', 'acquir', 'pneumonia', 'doctor', 'number', 'dictat', 'doctor', 'medquist', 'number']\n"
     ]
    }
   ],
   "source": [
    "doc_sample = documents[documents['index'] == 4310].values[0][0]\n",
    "print('original document: ')\n",
    "\n",
    "words = []\n",
    "for word in doc_sample.split(' '):\n",
    "    words.append(word)\n",
    "print(words)\n",
    "print('\\n\\n tokenized and lemmatized document: ')\n",
    "print(preprocess(doc_sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [admiss, date, discharg, date, servic, addendu...\n",
       "1    [admiss, date, discharg, date, date, birth, se...\n",
       "2    [admiss, date, discharg, date, servic, cardiot...\n",
       "3    [admiss, date, discharg, date, servic, medicin...\n",
       "4    [admiss, date, discharg, date, date, birth, se...\n",
       "5    [admiss, date, discharg, date, date, birth, se...\n",
       "6    [admiss, date, discharg, date, servic, medicin...\n",
       "7    [admiss, date, discharg, date, date, birth, se...\n",
       "8    [admiss, date, discharg, date, date, birth, se...\n",
       "9    [admiss, date, discharg, date, date, birth, se...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_docs = documents['text'].map(preprocess)\n",
    "processed_docs[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bag of Words on the Data set\n",
    "Create a dictionary from ‘processed_docs’ containing the number of times a word appears in the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 abdomin\n",
      "1 addendum\n",
      "2 admiss\n",
      "3 apex\n",
      "4 cavitari\n",
      "5 chest\n",
      "6 confirm\n",
      "7 consist\n",
      "8 date\n",
      "9 dictat\n",
      "10 discharg\n"
     ]
    }
   ],
   "source": [
    "dictionary = gensim.corpora.Dictionary(processed_docs)\n",
    "count = 0\n",
    "for k, v in dictionary.iteritems():\n",
    "    print(k, v)\n",
    "    count += 1\n",
    "    if count > 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gensim filter_extremes\n",
    "Filter out tokens that appear in\n",
    "\n",
    "1. less than 15 documents (absolute number) or\n",
    "2. more than 0.5 documents (fraction of total corpus size, not absolute number).\n",
    "3. after the above two steps, keep only the first 100000 most frequent tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dictionary.filter_extremes(no_below=15, no_above=0.5, keep_n=100000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gensim doc2bow (Bag of Words)\n",
    "For each document we create a dictionary reporting how many\n",
    "words and how many times those words appear. Save this to ‘bow_corpus’, then check our selected document earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 2),\n",
       " (2, 2),\n",
       " (5, 1),\n",
       " (8, 1),\n",
       " (9, 7),\n",
       " (11, 1),\n",
       " (12, 4),\n",
       " (15, 3),\n",
       " (16, 3),\n",
       " (18, 2),\n",
       " (23, 1),\n",
       " (25, 1),\n",
       " (26, 4),\n",
       " (27, 1),\n",
       " (30, 2),\n",
       " (32, 1),\n",
       " (33, 1),\n",
       " (37, 1),\n",
       " (39, 3),\n",
       " (40, 2),\n",
       " (41, 5),\n",
       " (46, 1),\n",
       " (47, 1),\n",
       " (52, 1),\n",
       " (53, 1),\n",
       " (62, 1),\n",
       " (68, 1),\n",
       " (80, 1),\n",
       " (81, 1),\n",
       " (84, 3),\n",
       " (86, 1),\n",
       " (87, 1),\n",
       " (98, 1),\n",
       " (102, 1),\n",
       " (104, 1),\n",
       " (105, 1),\n",
       " (114, 2),\n",
       " (117, 1),\n",
       " (119, 2),\n",
       " (120, 1),\n",
       " (124, 1),\n",
       " (125, 2),\n",
       " (138, 2),\n",
       " (146, 2),\n",
       " (149, 1),\n",
       " (154, 1),\n",
       " (162, 1),\n",
       " (172, 1),\n",
       " (179, 2),\n",
       " (184, 1),\n",
       " (193, 1),\n",
       " (194, 1),\n",
       " (195, 1),\n",
       " (196, 1),\n",
       " (198, 1),\n",
       " (202, 1),\n",
       " (204, 1),\n",
       " (213, 2),\n",
       " (218, 1),\n",
       " (220, 1),\n",
       " (223, 3),\n",
       " (226, 1),\n",
       " (227, 1),\n",
       " (231, 2),\n",
       " (238, 1),\n",
       " (248, 1),\n",
       " (254, 3),\n",
       " (261, 1),\n",
       " (263, 1),\n",
       " (265, 1),\n",
       " (268, 1),\n",
       " (270, 1),\n",
       " (283, 1),\n",
       " (286, 1),\n",
       " (288, 1),\n",
       " (296, 1),\n",
       " (308, 3),\n",
       " (324, 1),\n",
       " (328, 3),\n",
       " (331, 11),\n",
       " (332, 1),\n",
       " (337, 1),\n",
       " (340, 2),\n",
       " (341, 1),\n",
       " (342, 2),\n",
       " (345, 3),\n",
       " (346, 3),\n",
       " (348, 5),\n",
       " (350, 1),\n",
       " (352, 2),\n",
       " (364, 1),\n",
       " (369, 1),\n",
       " (370, 1),\n",
       " (371, 3),\n",
       " (374, 2),\n",
       " (381, 1),\n",
       " (385, 2),\n",
       " (393, 6),\n",
       " (395, 5),\n",
       " (408, 1),\n",
       " (416, 1),\n",
       " (420, 1),\n",
       " (424, 1),\n",
       " (428, 3),\n",
       " (432, 4),\n",
       " (450, 1),\n",
       " (451, 1),\n",
       " (454, 1),\n",
       " (458, 1),\n",
       " (460, 1),\n",
       " (461, 5),\n",
       " (463, 1),\n",
       " (467, 2),\n",
       " (470, 1),\n",
       " (477, 1),\n",
       " (478, 4),\n",
       " (491, 1),\n",
       " (495, 1),\n",
       " (497, 1),\n",
       " (526, 1),\n",
       " (530, 1),\n",
       " (534, 1),\n",
       " (537, 1),\n",
       " (539, 1),\n",
       " (550, 1),\n",
       " (554, 2),\n",
       " (563, 2),\n",
       " (565, 1),\n",
       " (567, 1),\n",
       " (568, 1),\n",
       " (571, 3),\n",
       " (577, 3),\n",
       " (585, 1),\n",
       " (608, 1),\n",
       " (612, 1),\n",
       " (620, 1),\n",
       " (651, 1),\n",
       " (668, 1),\n",
       " (683, 2),\n",
       " (698, 1),\n",
       " (700, 1),\n",
       " (704, 1),\n",
       " (705, 1),\n",
       " (721, 1),\n",
       " (729, 1),\n",
       " (731, 1),\n",
       " (734, 1),\n",
       " (736, 1),\n",
       " (738, 1),\n",
       " (740, 1),\n",
       " (743, 1),\n",
       " (761, 1),\n",
       " (765, 1),\n",
       " (787, 1),\n",
       " (829, 1),\n",
       " (841, 2),\n",
       " (853, 1),\n",
       " (883, 1),\n",
       " (884, 2),\n",
       " (888, 1),\n",
       " (911, 1),\n",
       " (941, 2),\n",
       " (963, 2),\n",
       " (983, 1),\n",
       " (986, 1),\n",
       " (987, 3),\n",
       " (988, 2),\n",
       " (1033, 1),\n",
       " (1038, 1),\n",
       " (1056, 2),\n",
       " (1062, 1),\n",
       " (1096, 1),\n",
       " (1098, 2),\n",
       " (1103, 1),\n",
       " (1138, 1),\n",
       " (1152, 1),\n",
       " (1207, 2),\n",
       " (1328, 1),\n",
       " (1349, 1),\n",
       " (1355, 2),\n",
       " (1384, 1),\n",
       " (1418, 1),\n",
       " (1421, 1),\n",
       " (1440, 1),\n",
       " (1468, 1),\n",
       " (1568, 1),\n",
       " (1606, 1),\n",
       " (1643, 1),\n",
       " (1647, 1),\n",
       " (1654, 1),\n",
       " (1659, 1),\n",
       " (1718, 2),\n",
       " (1722, 1),\n",
       " (1767, 1),\n",
       " (1784, 5),\n",
       " (1788, 1),\n",
       " (1791, 1),\n",
       " (1812, 1),\n",
       " (1822, 2),\n",
       " (1837, 1),\n",
       " (1841, 1),\n",
       " (1851, 1),\n",
       " (1893, 1),\n",
       " (1904, 1),\n",
       " (1914, 1),\n",
       " (1952, 3),\n",
       " (1962, 1),\n",
       " (1984, 4),\n",
       " (2048, 2),\n",
       " (2049, 3),\n",
       " (2074, 1),\n",
       " (2134, 1),\n",
       " (2145, 1),\n",
       " (2148, 2),\n",
       " (2195, 6),\n",
       " (2205, 2),\n",
       " (2213, 1),\n",
       " (2231, 1),\n",
       " (2235, 2),\n",
       " (2364, 1),\n",
       " (2369, 1),\n",
       " (2463, 1),\n",
       " (2506, 1),\n",
       " (2593, 1),\n",
       " (2602, 1),\n",
       " (2606, 1),\n",
       " (2622, 1),\n",
       " (2660, 1),\n",
       " (2661, 1),\n",
       " (2671, 1),\n",
       " (2675, 1),\n",
       " (2683, 1),\n",
       " (2690, 2),\n",
       " (2719, 2),\n",
       " (2897, 1),\n",
       " (2901, 1),\n",
       " (2958, 1),\n",
       " (2962, 1),\n",
       " (3008, 1),\n",
       " (3115, 2),\n",
       " (3123, 2),\n",
       " (3137, 1),\n",
       " (3157, 1),\n",
       " (3213, 1),\n",
       " (3356, 1),\n",
       " (3474, 1),\n",
       " (3516, 1),\n",
       " (3754, 1),\n",
       " (3795, 1),\n",
       " (3810, 1),\n",
       " (3834, 1),\n",
       " (3861, 3),\n",
       " (4211, 1),\n",
       " (4333, 2),\n",
       " (4523, 1),\n",
       " (4626, 1),\n",
       " (4912, 1),\n",
       " (5040, 1),\n",
       " (5593, 1),\n",
       " (6413, 1),\n",
       " (6427, 2),\n",
       " (6452, 1),\n",
       " (6920, 1),\n",
       " (7491, 1),\n",
       " (8034, 1),\n",
       " (8551, 1),\n",
       " (9070, 1),\n",
       " (11987, 1),\n",
       " (13028, 1)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow_corpus = [dictionary.doc2bow(doc) for doc in processed_docs]\n",
    "bow_corpus[4310]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word 0 (\"abdomin\") appears 2 time.\n",
      "Word 2 (\"admiss\") appears 2 time.\n",
      "Word 5 (\"chest\") appears 1 time.\n",
      "Word 8 (\"dictat\") appears 1 time.\n",
      "Word 9 (\"discharg\") appears 7 time.\n",
      "Word 11 (\"effus\") appears 1 time.\n",
      "Word 12 (\"follow\") appears 4 time.\n",
      "Word 15 (\"histori\") appears 3 time.\n",
      "Word 16 (\"hospit\") appears 3 time.\n",
      "Word 18 (\"includ\") appears 2 time.\n",
      "Word 23 (\"like\") appears 1 time.\n",
      "Word 25 (\"mass\") appears 1 time.\n",
      "Word 26 (\"medic\") appears 4 time.\n",
      "Word 27 (\"medquist\") appears 1 time.\n",
      "Word 30 (\"number\") appears 2 time.\n",
      "Word 32 (\"outpati\") appears 1 time.\n",
      "Word 33 (\"past\") appears 1 time.\n",
      "Word 37 (\"repeat\") appears 1 time.\n",
      "Word 39 (\"secondari\") appears 3 time.\n",
      "Word 40 (\"servic\") appears 2 time.\n",
      "Word 41 (\"show\") appears 5 time.\n",
      "Word 46 (\"abl\") appears 1 time.\n",
      "Word 47 (\"abnorm\") appears 1 time.\n",
      "Word 52 (\"adequ\") appears 1 time.\n",
      "Word 53 (\"admit\") appears 1 time.\n",
      "Word 62 (\"allergi\") appears 1 time.\n",
      "Word 68 (\"appear\") appears 1 time.\n",
      "Word 80 (\"bilater\") appears 1 time.\n",
      "Word 81 (\"birth\") appears 1 time.\n",
      "Word 84 (\"blood\") appears 3 time.\n",
      "Word 86 (\"bowel\") appears 1 time.\n",
      "Word 87 (\"breath\") appears 1 time.\n",
      "Word 98 (\"cell\") appears 1 time.\n",
      "Word 102 (\"chang\") appears 1 time.\n",
      "Word 104 (\"chill\") appears 1 time.\n",
      "Word 105 (\"chronic\") appears 1 time.\n",
      "Word 114 (\"complaint\") appears 2 time.\n",
      "Word 117 (\"condit\") appears 1 time.\n",
      "Word 119 (\"continu\") appears 2 time.\n",
      "Word 120 (\"control\") appears 1 time.\n",
      "Word 124 (\"count\") appears 1 time.\n",
      "Word 125 (\"cours\") appears 2 time.\n",
      "Word 138 (\"diagnos\") appears 2 time.\n",
      "Word 146 (\"doctor\") appears 2 time.\n",
      "Word 149 (\"edema\") appears 1 time.\n",
      "Word 154 (\"emerg\") appears 1 time.\n",
      "Word 162 (\"etiolog\") appears 1 time.\n",
      "Word 172 (\"extrem\") appears 1 time.\n",
      "Word 179 (\"fever\") appears 2 time.\n",
      "Word 184 (\"floor\") appears 1 time.\n",
      "Word 193 (\"general\") appears 1 time.\n",
      "Word 194 (\"get\") appears 1 time.\n",
      "Word 195 (\"give\") appears 1 time.\n",
      "Word 196 (\"glucos\") appears 1 time.\n",
      "Word 198 (\"greater\") appears 1 time.\n",
      "Word 202 (\"heart\") appears 1 time.\n",
      "Word 204 (\"hematocrit\") appears 1 time.\n",
      "Word 213 (\"home\") appears 2 time.\n",
      "Word 218 (\"hypertens\") appears 1 time.\n",
      "Word 220 (\"ill\") appears 1 time.\n",
      "Word 223 (\"improv\") appears 3 time.\n",
      "Word 226 (\"infect\") appears 1 time.\n",
      "Word 227 (\"infiltr\") appears 1 time.\n",
      "Word 231 (\"initi\") appears 2 time.\n",
      "Word 238 (\"intub\") appears 1 time.\n",
      "Word 248 (\"laboratori\") appears 1 time.\n",
      "Word 254 (\"levofloxacin\") appears 3 time.\n",
      "Word 261 (\"liter\") appears 1 time.\n",
      "Word 263 (\"lobe\") appears 1 time.\n",
      "Word 265 (\"look\") appears 1 time.\n",
      "Word 268 (\"lower\") appears 1 time.\n",
      "Word 270 (\"lymphadenopathi\") appears 1 time.\n",
      "Word 283 (\"membran\") appears 1 time.\n",
      "Word 286 (\"micu\") appears 1 time.\n",
      "Word 288 (\"mild\") appears 1 time.\n",
      "Word 296 (\"mucous\") appears 1 time.\n",
      "Word 308 (\"negat\") appears 3 time.\n",
      "Word 324 (\"order\") appears 1 time.\n",
      "Word 328 (\"pain\") appears 3 time.\n",
      "Word 331 (\"patient\") appears 11 time.\n",
      "Word 332 (\"pattern\") appears 1 time.\n",
      "Word 337 (\"physic\") appears 1 time.\n",
      "Word 340 (\"plan\") appears 2 time.\n",
      "Word 341 (\"platelet\") appears 1 time.\n",
      "Word 342 (\"pneumonia\") appears 2 time.\n",
      "Word 345 (\"posit\") appears 3 time.\n",
      "Word 346 (\"post\") appears 3 time.\n",
      "Word 348 (\"prednison\") appears 5 time.\n",
      "Word 350 (\"present\") appears 1 time.\n",
      "Word 352 (\"pressur\") appears 2 time.\n",
      "Word 364 (\"pulmonari\") appears 1 time.\n",
      "Word 369 (\"rale\") appears 1 time.\n",
      "Word 370 (\"rash\") appears 1 time.\n",
      "Word 371 (\"rate\") appears 3 time.\n",
      "Word 374 (\"receiv\") appears 2 time.\n",
      "Word 381 (\"relat\") appears 1 time.\n",
      "Word 385 (\"respiratori\") appears 2 time.\n",
      "Word 393 (\"right\") appears 6 time.\n",
      "Word 395 (\"room\") appears 5 time.\n",
      "Word 408 (\"short\") appears 1 time.\n",
      "Word 416 (\"small\") appears 1 time.\n",
      "Word 420 (\"soft\") appears 1 time.\n",
      "Word 424 (\"sound\") appears 1 time.\n",
      "Word 428 (\"status\") appears 3 time.\n",
      "Word 432 (\"stitl\") appears 4 time.\n",
      "Word 450 (\"tachycard\") appears 1 time.\n",
      "Word 451 (\"taper\") appears 1 time.\n",
      "Word 454 (\"temperatur\") appears 1 time.\n",
      "Word 458 (\"thicken\") appears 1 time.\n",
      "Word 460 (\"throat\") appears 1 time.\n",
      "Word 461 (\"time\") appears 5 time.\n",
      "Word 463 (\"toler\") appears 1 time.\n",
      "Word 467 (\"transfer\") appears 2 time.\n",
      "Word 470 (\"treat\") appears 1 time.\n",
      "Word 477 (\"unit\") appears 1 time.\n",
      "Word 478 (\"upper\") appears 4 time.\n",
      "Word 491 (\"wean\") appears 1 time.\n",
      "Word 495 (\"white\") appears 1 time.\n",
      "Word 497 (\"year\") appears 1 time.\n",
      "Word 526 (\"bring\") appears 1 time.\n",
      "Word 530 (\"cardiac\") appears 1 time.\n",
      "Word 534 (\"chief\") appears 1 time.\n",
      "Word 537 (\"chlorid\") appears 1 time.\n",
      "Word 539 (\"clear\") appears 1 time.\n",
      "Word 550 (\"cough\") appears 1 time.\n",
      "Word 554 (\"cultur\") appears 2 time.\n",
      "Word 563 (\"develop\") appears 2 time.\n",
      "Word 565 (\"diagnosi\") appears 1 time.\n",
      "Word 567 (\"diet\") appears 1 time.\n",
      "Word 568 (\"diffus\") appears 1 time.\n",
      "Word 571 (\"diseas\") appears 3 time.\n",
      "Word 577 (\"dose\") appears 3 time.\n",
      "Word 585 (\"erythema\") appears 1 time.\n",
      "Word 608 (\"heent\") appears 1 time.\n",
      "Word 612 (\"hypoxia\") appears 1 time.\n",
      "Word 620 (\"larg\") appears 1 time.\n",
      "Word 651 (\"overnight\") appears 1 time.\n",
      "Word 668 (\"prilosec\") appears 1 time.\n",
      "Word 683 (\"resolv\") appears 2 time.\n",
      "Word 698 (\"slight\") appears 1 time.\n",
      "Word 700 (\"sodium\") appears 1 time.\n",
      "Word 704 (\"sputum\") appears 1 time.\n",
      "Word 705 (\"state\") appears 1 time.\n",
      "Word 721 (\"total\") appears 1 time.\n",
      "Word 729 (\"ultrasound\") appears 1 time.\n",
      "Word 731 (\"undergo\") appears 1 time.\n",
      "Word 734 (\"vancomycin\") appears 1 time.\n",
      "Word 736 (\"wall\") appears 1 time.\n",
      "Word 738 (\"woman\") appears 1 time.\n",
      "Word 740 (\"abdomen\") appears 1 time.\n",
      "Word 743 (\"activ\") appears 1 time.\n",
      "Word 761 (\"base\") appears 1 time.\n",
      "Word 765 (\"begin\") appears 1 time.\n",
      "Word 787 (\"comfort\") appears 1 time.\n",
      "Word 829 (\"examin\") appears 1 time.\n",
      "Word 841 (\"gram\") appears 2 time.\n",
      "Word 853 (\"impress\") appears 1 time.\n",
      "Word 883 (\"mono\") appears 1 time.\n",
      "Word 884 (\"morn\") appears 2 time.\n",
      "Word 888 (\"murmur\") appears 1 time.\n",
      "Word 911 (\"phos\") appears 1 time.\n",
      "Word 941 (\"stabl\") appears 2 time.\n",
      "Word 963 (\"tender\") appears 2 time.\n",
      "Word 983 (\"vital\") appears 1 time.\n",
      "Word 986 (\"ward\") appears 1 time.\n",
      "Word 987 (\"warm\") appears 3 time.\n",
      "Word 988 (\"wednesday\") appears 2 time.\n",
      "Word 1033 (\"cervic\") appears 1 time.\n",
      "Word 1038 (\"collect\") appears 1 time.\n",
      "Word 1056 (\"deep\") appears 2 time.\n",
      "Word 1062 (\"dens\") appears 1 time.\n",
      "Word 1096 (\"fluid\") appears 1 time.\n",
      "Word 1098 (\"focal\") appears 2 time.\n",
      "Word 1103 (\"gallbladd\") appears 1 time.\n",
      "Word 1138 (\"liver\") appears 1 time.\n",
      "Word 1152 (\"measur\") appears 1 time.\n",
      "Word 1207 (\"renal\") appears 2 time.\n",
      "Word 1328 (\"half\") appears 1 time.\n",
      "Word 1349 (\"meal\") appears 1 time.\n",
      "Word 1355 (\"month\") appears 2 time.\n",
      "Word 1384 (\"schedul\") appears 1 time.\n",
      "Word 1418 (\"ceftriaxon\") appears 1 time.\n",
      "Word 1421 (\"complain\") appears 1 time.\n",
      "Word 1440 (\"health\") appears 1 time.\n",
      "Word 1468 (\"tylenol\") appears 1 time.\n",
      "Word 1568 (\"potassium\") appears 1 time.\n",
      "Word 1606 (\"urin\") appears 1 time.\n",
      "Word 1643 (\"common\") appears 1 time.\n",
      "Word 1647 (\"creatinin\") appears 1 time.\n",
      "Word 1654 (\"dilat\") appears 1 time.\n",
      "Word 1659 (\"drop\") appears 1 time.\n",
      "Word 1718 (\"palpat\") appears 2 time.\n",
      "Word 1722 (\"pend\") appears 1 time.\n",
      "Word 1767 (\"usual\") appears 1 time.\n",
      "Word 1784 (\"anemia\") appears 5 time.\n",
      "Word 1788 (\"band\") appears 1 time.\n",
      "Word 1791 (\"bili\") appears 1 time.\n",
      "Word 1812 (\"diff\") appears 1 time.\n",
      "Word 1822 (\"friday\") appears 2 time.\n",
      "Word 1837 (\"iron\") appears 1 time.\n",
      "Word 1841 (\"lopressor\") appears 1 time.\n",
      "Word 1851 (\"monday\") appears 1 time.\n",
      "Word 1893 (\"sepsi\") appears 1 time.\n",
      "Word 1904 (\"tachycardia\") appears 1 time.\n",
      "Word 1914 (\"trend\") appears 1 time.\n",
      "Word 1952 (\"antibodi\") appears 3 time.\n",
      "Word 1962 (\"data\") appears 1 time.\n",
      "Word 1984 (\"quadrant\") appears 4 time.\n",
      "Word 2048 (\"hemoptysi\") appears 2 time.\n",
      "Word 2049 (\"hepat\") appears 3 time.\n",
      "Word 2074 (\"poli\") appears 1 time.\n",
      "Word 2134 (\"hematolog\") appears 1 time.\n",
      "Word 2145 (\"neutrophil\") appears 1 time.\n",
      "Word 2148 (\"notabl\") appears 2 time.\n",
      "Word 2195 (\"hemodialysi\") appears 6 time.\n",
      "Word 2205 (\"issu\") appears 2 time.\n",
      "Word 2213 (\"nephrocap\") appears 1 time.\n",
      "Word 2231 (\"sat\") appears 1 time.\n",
      "Word 2235 (\"stage\") appears 2 time.\n",
      "Word 2364 (\"bile\") appears 1 time.\n",
      "Word 2369 (\"duct\") appears 1 time.\n",
      "Word 2463 (\"serolog\") appears 1 time.\n",
      "Word 2506 (\"differenti\") appears 1 time.\n",
      "Word 2593 (\"biliari\") appears 1 time.\n",
      "Word 2602 (\"demerol\") appears 1 time.\n",
      "Word 2606 (\"finish\") appears 1 time.\n",
      "Word 2622 (\"lipas\") appears 1 time.\n",
      "Word 2660 (\"ductal\") appears 1 time.\n",
      "Word 2661 (\"echogen\") appears 1 time.\n",
      "Word 2671 (\"intrahepat\") appears 1 time.\n",
      "Word 2675 (\"portal\") appears 1 time.\n",
      "Word 2683 (\"second\") appears 1 time.\n",
      "Word 2690 (\"transaminas\") appears 2 time.\n",
      "Word 2719 (\"epogen\") appears 2 time.\n",
      "Word 2897 (\"inguin\") appears 1 time.\n",
      "Word 2901 (\"moist\") appears 1 time.\n",
      "Word 2958 (\"cocci\") appears 1 time.\n",
      "Word 2962 (\"dull\") appears 1 time.\n",
      "Word 3008 (\"repair\") appears 1 time.\n",
      "Word 3115 (\"acquir\") appears 2 time.\n",
      "Word 3123 (\"communiti\") appears 2 time.\n",
      "Word 3137 (\"legionella\") appears 1 time.\n",
      "Word 3157 (\"weekend\") appears 1 time.\n",
      "Word 3213 (\"teaspoon\") appears 1 time.\n",
      "Word 3356 (\"rod\") appears 1 time.\n",
      "Word 3474 (\"eat\") appears 1 time.\n",
      "Word 3516 (\"mix\") appears 1 time.\n",
      "Word 3754 (\"lymphocyt\") appears 1 time.\n",
      "Word 3795 (\"edemat\") appears 1 time.\n",
      "Word 3810 (\"lupus\") appears 1 time.\n",
      "Word 3834 (\"sickl\") appears 1 time.\n",
      "Word 3861 (\"hemolyt\") appears 3 time.\n",
      "Word 4211 (\"antigen\") appears 1 time.\n",
      "Word 4333 (\"sate\") appears 2 time.\n",
      "Word 4523 (\"hemoglobin\") appears 1 time.\n",
      "Word 4626 (\"eosinophil\") appears 1 time.\n",
      "Word 4912 (\"angioedema\") appears 1 time.\n",
      "Word 5040 (\"tum\") appears 1 time.\n",
      "Word 5593 (\"pneumococc\") appears 1 time.\n",
      "Word 6413 (\"trait\") appears 1 time.\n",
      "Word 6427 (\"procardia\") appears 2 time.\n",
      "Word 6452 (\"egophoni\") appears 1 time.\n",
      "Word 6920 (\"nephriti\") appears 1 time.\n",
      "Word 7491 (\"hypoecho\") appears 1 time.\n",
      "Word 8034 (\"rocaltrol\") appears 1 time.\n",
      "Word 8551 (\"faci\") appears 1 time.\n",
      "Word 9070 (\"cushingoid\") appears 1 time.\n",
      "Word 11987 (\"triad\") appears 1 time.\n",
      "Word 13028 (\"alka\") appears 1 time.\n"
     ]
    }
   ],
   "source": [
    "bow_doc_4310 = bow_corpus[4310]\n",
    "for i in range(len(bow_doc_4310)):\n",
    "    print(\"Word {} (\\\"{}\\\") appears {} time.\".format(bow_doc_4310[i][0], \n",
    "                                               dictionary[bow_doc_4310[i][0]], \n",
    "bow_doc_4310[i][1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF IDF \n",
    "Create tf-idf model object using models.TfidfModel on ‘bow_corpus’ and save it to ‘tfidf’, then apply transformation to the entire corpus and call it ‘corpus_tfidf’. Finally we preview TF-IDF scores for our first document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0.20984918688538046),\n",
      " (1, 0.1734458382975791),\n",
      " (2, 0.05878068974385455),\n",
      " (3, 0.13768462239052914),\n",
      " (4, 0.2888172222311172),\n",
      " (5, 0.07264987984801156),\n",
      " (6, 0.15198630791070009),\n",
      " (7, 0.1724289077557035),\n",
      " (8, 0.11261352342192697),\n",
      " (9, 0.058850794221396274),\n",
      " (10, 0.1336591513998094),\n",
      " (11, 0.05421785856883934),\n",
      " (12, 0.06450866721623826),\n",
      " (13, 0.20657681946685544),\n",
      " (14, 0.13409115367756516),\n",
      " (15, 0.06229248355414667),\n",
      " (16, 0.05931060352926453),\n",
      " (17, 0.07302414488312661),\n",
      " (18, 0.08682731994405998),\n",
      " (19, 0.08223894821140666),\n",
      " (20, 0.1333669640980876),\n",
      " (21, 0.16233409514367825),\n",
      " (22, 0.2374998012980466),\n",
      " (23, 0.08257282324492556),\n",
      " (24, 0.07908867735750663),\n",
      " (25, 0.09376000101596972),\n",
      " (26, 0.05975402634300554),\n",
      " (27, 0.11535716578158435),\n",
      " (28, 0.06666382785366787),\n",
      " (29, 0.20786951323489367),\n",
      " (30, 0.1643090375098856),\n",
      " (31, 0.2128710642947576),\n",
      " (32, 0.0991744671072435),\n",
      " (33, 0.06721596082119884),\n",
      " (34, 0.1086420714397059),\n",
      " (35, 0.13476007304855736),\n",
      " (36, 0.31024328431842607),\n",
      " (37, 0.10793773012746036),\n",
      " (38, 0.27606721689069474),\n",
      " (39, 0.0940655963693465),\n",
      " (40, 0.058958593677802734),\n",
      " (41, 0.15797709669386256),\n",
      " (42, 0.05901012788721802),\n",
      " (43, 0.13817798755022162),\n",
      " (44, 0.29258117978907544)]\n"
     ]
    }
   ],
   "source": [
    "from gensim import corpora, models\n",
    "tfidf = models.TfidfModel(bow_corpus)\n",
    "corpus_tfidf = tfidf[bow_corpus]\n",
    "from pprint import pprint\n",
    "for doc in corpus_tfidf:\n",
    "    pprint(doc)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running LDA using Bag of Words\n",
    "Train our lda model using gensim.models.LdaMulticore and save it to ‘lda_model’"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lda_model = gensim.models.LdaMulticore(bow_corpus,\n",
    "                                       num_topics=10,\n",
    "                                       id2word=dictionary,\n",
    "                                       passes=2,\n",
    "                                       workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gensim.models.ldamulticore.LdaMulticore"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(lda_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each topic, we will explore the words occuring in that topic and its relative weight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: 0 \n",
      "Words: 0.050*\"valv\" + 0.036*\"mild\" + 0.032*\"aortic\" + 0.027*\"mitral\" + 0.025*\"ventricular\" + 0.024*\"leaflet\" + 0.019*\"right\" + 0.018*\"size\" + 0.018*\"systol\" + 0.017*\"wall\"\n",
      "Topic: 1 \n",
      "Words: 0.035*\"blood\" + 0.012*\"patient\" + 0.010*\"hospit\" + 0.009*\"cultur\" + 0.008*\"discharg\" + 0.007*\"tablet\" + 0.007*\"daili\" + 0.005*\"negat\" + 0.005*\"continu\" + 0.005*\"final\"\n",
      "Topic: 2 \n",
      "Words: 0.051*\"patient\" + 0.014*\"discharg\" + 0.011*\"histori\" + 0.010*\"hospit\" + 0.008*\"medic\" + 0.008*\"time\" + 0.008*\"blood\" + 0.008*\"admiss\" + 0.007*\"arteri\" + 0.007*\"status\"\n",
      "Topic: 3 \n",
      "Words: 0.050*\"tablet\" + 0.023*\"daili\" + 0.016*\"discharg\" + 0.013*\"pain\" + 0.012*\"blood\" + 0.011*\"refil\" + 0.011*\"disp\" + 0.011*\"medic\" + 0.010*\"histori\" + 0.009*\"hospit\"\n",
      "Topic: 4 \n",
      "Words: 0.015*\"right\" + 0.009*\"hospit\" + 0.009*\"patient\" + 0.009*\"discharg\" + 0.008*\"head\" + 0.007*\"bilater\" + 0.006*\"medic\" + 0.006*\"histori\" + 0.006*\"hemorrhag\" + 0.006*\"tablet\"\n",
      "Topic: 5 \n",
      "Words: 0.015*\"patient\" + 0.010*\"discharg\" + 0.009*\"bleed\" + 0.009*\"liver\" + 0.009*\"abdomin\" + 0.009*\"hospit\" + 0.008*\"histori\" + 0.008*\"blood\" + 0.007*\"medic\" + 0.006*\"pain\"\n",
      "Topic: 6 \n",
      "Words: 0.018*\"infant\" + 0.017*\"discharg\" + 0.012*\"life\" + 0.011*\"hospit\" + 0.010*\"week\" + 0.010*\"blood\" + 0.010*\"namepattern\" + 0.009*\"feed\" + 0.009*\"admiss\" + 0.009*\"screen\"\n",
      "Topic: 7 \n",
      "Words: 0.050*\"wave\" + 0.050*\"chang\" + 0.048*\"rhythm\" + 0.032*\"atrial\" + 0.030*\"compar\" + 0.029*\"ventricular\" + 0.026*\"lead\" + 0.024*\"abnorm\" + 0.019*\"infarct\" + 0.017*\"suggest\"\n",
      "Topic: 8 \n",
      "Words: 0.023*\"tablet\" + 0.016*\"daili\" + 0.015*\"hospit\" + 0.013*\"discharg\" + 0.009*\"patient\" + 0.009*\"histori\" + 0.009*\"medic\" + 0.008*\"admiss\" + 0.008*\"blood\" + 0.007*\"time\"\n",
      "Topic: 9 \n",
      "Words: 0.036*\"interpret\" + 0.022*\"offic\" + 0.022*\"note\" + 0.020*\"physician\" + 0.019*\"namei\" + 0.018*\"order\" + 0.017*\"correspond\" + 0.014*\"fractur\" + 0.014*\"discharg\" + 0.011*\"know\"\n"
     ]
    }
   ],
   "source": [
    "for idx, topic in lda_model.print_topics(-1):\n",
    "    print('Topic: {} \\nWords: {}'.format(idx, topic))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running LDA using TF-IDF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: 0 Word: 0.006*\"blood\" + 0.006*\"reappear\" + 0.005*\"cultur\" + 0.005*\"tablet\" + 0.004*\"final\" + 0.004*\"analyz\" + 0.004*\"discharg\" + 0.004*\"hospit\" + 0.004*\"negat\" + 0.003*\"daili\"\n",
      "Topic: 1 Word: 0.020*\"tablet\" + 0.011*\"daili\" + 0.006*\"discharg\" + 0.006*\"blood\" + 0.006*\"disp\" + 0.005*\"refil\" + 0.005*\"hospit\" + 0.005*\"releas\" + 0.004*\"histori\" + 0.004*\"capsul\"\n",
      "Topic: 2 Word: 0.023*\"infant\" + 0.012*\"life\" + 0.009*\"immun\" + 0.008*\"feed\" + 0.008*\"newborn\" + 0.008*\"screen\" + 0.007*\"gestat\" + 0.007*\"babi\" + 0.007*\"discharg\" + 0.007*\"deliveri\"\n",
      "Topic: 3 Word: 0.008*\"tablet\" + 0.005*\"blood\" + 0.005*\"discharg\" + 0.005*\"hospit\" + 0.005*\"daili\" + 0.004*\"histori\" + 0.003*\"medic\" + 0.003*\"patient\" + 0.003*\"admiss\" + 0.002*\"seizur\"\n",
      "Topic: 4 Word: 0.009*\"tablet\" + 0.006*\"fractur\" + 0.006*\"discharg\" + 0.006*\"mar\" + 0.005*\"blood\" + 0.005*\"pain\" + 0.004*\"hospit\" + 0.004*\"medic\" + 0.004*\"daili\" + 0.003*\"histori\"\n",
      "Topic: 5 Word: 0.012*\"discharg\" + 0.010*\"postop\" + 0.009*\"patient\" + 0.009*\"number\" + 0.008*\"exercis\" + 0.007*\"namepattern\" + 0.007*\"graft\" + 0.007*\"know\" + 0.007*\"addendum\" + 0.006*\"coronari\"\n",
      "Topic: 6 Word: 0.012*\"patient\" + 0.007*\"discharg\" + 0.006*\"hospit\" + 0.005*\"number\" + 0.005*\"histori\" + 0.005*\"blood\" + 0.004*\"namepattern\" + 0.004*\"unit\" + 0.004*\"admiss\" + 0.004*\"medic\"\n",
      "Topic: 7 Word: 0.032*\"wave\" + 0.027*\"rhythm\" + 0.026*\"chang\" + 0.021*\"lead\" + 0.021*\"compar\" + 0.017*\"block\" + 0.017*\"tachycardia\" + 0.017*\"atrial\" + 0.017*\"diagnost\" + 0.016*\"signific\"\n",
      "Topic: 8 Word: 0.038*\"valv\" + 0.023*\"aortic\" + 0.021*\"mild\" + 0.020*\"leaflet\" + 0.020*\"mitral\" + 0.014*\"size\" + 0.014*\"doppler\" + 0.013*\"atrium\" + 0.012*\"wall\" + 0.012*\"thicken\"\n",
      "Topic: 9 Word: 0.157*\"correspond\" + 0.118*\"order\" + 0.111*\"namei\" + 0.107*\"interpret\" + 0.099*\"physician\" + 0.098*\"offic\" + 0.061*\"note\" + 0.002*\"know\" + 0.002*\"addendum\" + 0.002*\"discharg\"\n"
     ]
    }
   ],
   "source": [
    "lda_model_tfidf = gensim.models.LdaMulticore(corpus_tfidf, num_topics=10, id2word=dictionary, passes=2, workers=4)\n",
    "for idx, topic in lda_model_tfidf.print_topics(-1):\n",
    "    print('Topic: {} Word: {}'.format(idx, topic))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance evaluation by classifying sample document using LDA Bag of Words model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['admiss',\n",
       " 'date',\n",
       " 'discharg',\n",
       " 'date',\n",
       " 'date',\n",
       " 'birth',\n",
       " 'servic',\n",
       " 'hospit',\n",
       " 'chief',\n",
       " 'complaint',\n",
       " 'hypoxia',\n",
       " 'hemoptysi',\n",
       " 'fever',\n",
       " 'histori',\n",
       " 'present',\n",
       " 'ill',\n",
       " 'year',\n",
       " 'woman',\n",
       " 'lupus',\n",
       " 'nephriti',\n",
       " 'stage',\n",
       " 'renal',\n",
       " 'diseas',\n",
       " 'hemodialysi',\n",
       " 'warm',\n",
       " 'antibodi',\n",
       " 'hemolyt',\n",
       " 'anemia',\n",
       " 'prednison',\n",
       " 'time',\n",
       " 'month',\n",
       " 'usual',\n",
       " 'state',\n",
       " 'health',\n",
       " 'friday',\n",
       " 'develop',\n",
       " 'cough',\n",
       " 'abl',\n",
       " 'undergo',\n",
       " 'normal',\n",
       " 'weekend',\n",
       " 'activ',\n",
       " 'morn',\n",
       " 'develop',\n",
       " 'fever',\n",
       " 'chill',\n",
       " 'teaspoon',\n",
       " 'hemoptysi',\n",
       " 'right',\n",
       " 'upper',\n",
       " 'quadrant',\n",
       " 'pain',\n",
       " 'bring',\n",
       " 'emerg',\n",
       " 'room',\n",
       " 'sat',\n",
       " 'room',\n",
       " 'improv',\n",
       " 'liter',\n",
       " 'respiratori',\n",
       " 'rate',\n",
       " 'give',\n",
       " 'ceftriaxon',\n",
       " 'lopressor',\n",
       " 'tylenol',\n",
       " 'right',\n",
       " 'upper',\n",
       " 'quadrant',\n",
       " 'short',\n",
       " 'breath',\n",
       " 'improv',\n",
       " 'past',\n",
       " 'medic',\n",
       " 'histori',\n",
       " 'notabl',\n",
       " 'diagnos',\n",
       " 'treat',\n",
       " 'prednison',\n",
       " 'warm',\n",
       " 'antibodi',\n",
       " 'hemolyt',\n",
       " 'anemia',\n",
       " 'diagnos',\n",
       " 'prednison',\n",
       " 'taper',\n",
       " 'initi',\n",
       " 'time',\n",
       " 'month',\n",
       " 'stage',\n",
       " 'renal',\n",
       " 'diseas',\n",
       " 'hemodialysi',\n",
       " 'pneumococc',\n",
       " 'sepsi',\n",
       " 'status',\n",
       " 'post',\n",
       " 'intub',\n",
       " 'sickl',\n",
       " 'cell',\n",
       " 'trait',\n",
       " 'status',\n",
       " 'post',\n",
       " 'repair',\n",
       " 'status',\n",
       " 'post',\n",
       " 'secondari',\n",
       " 'histori',\n",
       " 'diff',\n",
       " 'hypertens',\n",
       " 'allergi',\n",
       " 'demerol',\n",
       " 'get',\n",
       " 'angioedema',\n",
       " 'vancomycin',\n",
       " 'medic',\n",
       " 'includ',\n",
       " 'prednison',\n",
       " 'nephrocap',\n",
       " 'rocaltrol',\n",
       " 'epogen',\n",
       " 'unit',\n",
       " 'monday',\n",
       " 'wednesday',\n",
       " 'friday',\n",
       " 'hemodialysi',\n",
       " 'procardia',\n",
       " 'prilosec',\n",
       " 'tum',\n",
       " 'meal',\n",
       " 'inf',\n",
       " 'wednesday',\n",
       " 'hemodialysi',\n",
       " 'physic',\n",
       " 'examin',\n",
       " 'transfer',\n",
       " 'medic',\n",
       " 'servic',\n",
       " 'vital',\n",
       " 'temperatur',\n",
       " 'heart',\n",
       " 'rate',\n",
       " 'respiratori',\n",
       " 'rate',\n",
       " 'blood',\n",
       " 'pressur',\n",
       " 'room',\n",
       " 'general',\n",
       " 'comfort',\n",
       " 'look',\n",
       " 'cushingoid',\n",
       " 'faci',\n",
       " 'heent',\n",
       " 'throat',\n",
       " 'clear',\n",
       " 'erythema',\n",
       " 'moist',\n",
       " 'mucous',\n",
       " 'membran',\n",
       " 'cervic',\n",
       " 'inguin',\n",
       " 'lymphadenopathi',\n",
       " 'tachycard',\n",
       " 'normal',\n",
       " 'murmur',\n",
       " 'pulmonari',\n",
       " 'rale',\n",
       " 'bilater',\n",
       " 'half',\n",
       " 'egophoni',\n",
       " 'posit',\n",
       " 'dull',\n",
       " 'right',\n",
       " 'base',\n",
       " 'abdomen',\n",
       " 'soft',\n",
       " 'slight',\n",
       " 'tender',\n",
       " 'right',\n",
       " 'upper',\n",
       " 'quadrant',\n",
       " 'deep',\n",
       " 'palpat',\n",
       " 'posit',\n",
       " 'bowel',\n",
       " 'sound',\n",
       " 'extrem',\n",
       " 'edema',\n",
       " 'rash',\n",
       " 'laboratori',\n",
       " 'data',\n",
       " 'notabl',\n",
       " 'white',\n",
       " 'count',\n",
       " 'hemoglobin',\n",
       " 'hematocrit',\n",
       " 'platelet',\n",
       " 'differenti',\n",
       " 'show',\n",
       " 'neutrophil',\n",
       " 'band',\n",
       " 'lymphocyt',\n",
       " 'mono',\n",
       " 'eosinophil',\n",
       " 'sodium',\n",
       " 'potassium',\n",
       " 'repeat',\n",
       " 'chlorid',\n",
       " 'creatinin',\n",
       " 'glucos',\n",
       " 'alka',\n",
       " 'phos',\n",
       " 'lipas',\n",
       " 'total',\n",
       " 'bili',\n",
       " 'legionella',\n",
       " 'antigen',\n",
       " 'negat',\n",
       " 'sputum',\n",
       " 'show',\n",
       " 'greater',\n",
       " 'poli',\n",
       " 'gram',\n",
       " 'posit',\n",
       " 'cocci',\n",
       " 'gram',\n",
       " 'negat',\n",
       " 'rod',\n",
       " 'chest',\n",
       " 'show',\n",
       " 'right',\n",
       " 'lower',\n",
       " 'lobe',\n",
       " 'dens',\n",
       " 'infiltr',\n",
       " 'small',\n",
       " 'effus',\n",
       " 'abdomin',\n",
       " 'ultrasound',\n",
       " 'show',\n",
       " 'liver',\n",
       " 'diffus',\n",
       " 'hypoecho',\n",
       " 'focal',\n",
       " 'echogen',\n",
       " 'relat',\n",
       " 'portal',\n",
       " 'triad',\n",
       " 'starri',\n",
       " 'hospit',\n",
       " 'ward',\n",
       " 'pattern',\n",
       " 'focal',\n",
       " 'mass',\n",
       " 'intrahepat',\n",
       " 'biliari',\n",
       " 'ductal',\n",
       " 'dilat',\n",
       " 'common',\n",
       " 'bile',\n",
       " 'duct',\n",
       " 'measur',\n",
       " 'gallbladd',\n",
       " 'abnorm',\n",
       " 'thicken',\n",
       " 'wall',\n",
       " 'edemat',\n",
       " 'fluid',\n",
       " 'collect',\n",
       " 'impress',\n",
       " 'hepat',\n",
       " 'hospit',\n",
       " 'cours',\n",
       " 'patient',\n",
       " 'initi',\n",
       " 'admit',\n",
       " 'micu',\n",
       " 'overnight',\n",
       " 'wean',\n",
       " 'sate',\n",
       " 'room',\n",
       " 'transfer',\n",
       " 'medic',\n",
       " 'floor',\n",
       " 'time',\n",
       " 'continu',\n",
       " 'improv',\n",
       " 'levofloxacin',\n",
       " 'receiv',\n",
       " 'dose',\n",
       " 'levofloxacin',\n",
       " 'receiv',\n",
       " 'second',\n",
       " 'dose',\n",
       " 'hemodialysi',\n",
       " 'dose',\n",
       " 'schedul',\n",
       " 'morn',\n",
       " 'patient',\n",
       " 'appear',\n",
       " 'sate',\n",
       " 'room',\n",
       " 'eat',\n",
       " 'right',\n",
       " 'upper',\n",
       " 'quadrant',\n",
       " 'pain',\n",
       " 'larg',\n",
       " 'resolv',\n",
       " 'patient',\n",
       " 'complain',\n",
       " 'mild',\n",
       " 'tender',\n",
       " 'deep',\n",
       " 'palpat',\n",
       " 'transaminas',\n",
       " 'begin',\n",
       " 'trend',\n",
       " 'drop',\n",
       " 'blood',\n",
       " 'cultur',\n",
       " 'pend',\n",
       " 'time',\n",
       " 'discharg',\n",
       " 'urin',\n",
       " 'cultur',\n",
       " 'negat',\n",
       " 'patient',\n",
       " 'discharg',\n",
       " 'home',\n",
       " 'hemodialysi',\n",
       " 'plan',\n",
       " 'follow',\n",
       " 'stitl',\n",
       " 'issu',\n",
       " 'time',\n",
       " 'discharg',\n",
       " 'includ',\n",
       " 'communiti',\n",
       " 'acquir',\n",
       " 'pneumonia',\n",
       " 'plan',\n",
       " 'patient',\n",
       " 'finish',\n",
       " 'cours',\n",
       " 'levofloxacin',\n",
       " 'cardiac',\n",
       " 'issu',\n",
       " 'patient',\n",
       " 'stabl',\n",
       " 'blood',\n",
       " 'pressur',\n",
       " 'adequ',\n",
       " 'control',\n",
       " 'procardia',\n",
       " 'tachycardia',\n",
       " 'resolv',\n",
       " 'like',\n",
       " 'secondari',\n",
       " 'infect',\n",
       " 'admiss',\n",
       " 'show',\n",
       " 'chang',\n",
       " 'patient',\n",
       " 'toler',\n",
       " 'diet',\n",
       " 'complaint',\n",
       " 'abdomin',\n",
       " 'pain',\n",
       " 'stitl',\n",
       " 'follow',\n",
       " 'patient',\n",
       " 'transaminas',\n",
       " 'outpati',\n",
       " 'hepat',\n",
       " 'serolog',\n",
       " 'hepat',\n",
       " 'order',\n",
       " 'follow',\n",
       " 'stitl',\n",
       " 'hematolog',\n",
       " 'anemia',\n",
       " 'mix',\n",
       " 'etiolog',\n",
       " 'warm',\n",
       " 'antibodi',\n",
       " 'hemolyt',\n",
       " 'anemia',\n",
       " 'anemia',\n",
       " 'secondari',\n",
       " 'chronic',\n",
       " 'diseas',\n",
       " 'follow',\n",
       " 'stitl',\n",
       " 'patient',\n",
       " 'continu',\n",
       " 'iron',\n",
       " 'epogen',\n",
       " 'prednison',\n",
       " 'patient',\n",
       " 'discharg',\n",
       " 'stabl',\n",
       " 'condit',\n",
       " 'patient',\n",
       " 'discharg',\n",
       " 'home',\n",
       " 'discharg',\n",
       " 'diagnosi',\n",
       " 'communiti',\n",
       " 'acquir',\n",
       " 'pneumonia',\n",
       " 'doctor',\n",
       " 'number',\n",
       " 'dictat',\n",
       " 'doctor',\n",
       " 'medquist',\n",
       " 'number']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_docs[4310]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Score: 0.48047584295272827\t \n",
      "Topic: 0.051*\"patient\" + 0.014*\"discharg\" + 0.011*\"histori\" + 0.010*\"hospit\" + 0.008*\"medic\" + 0.008*\"time\" + 0.008*\"blood\" + 0.008*\"admiss\" + 0.007*\"arteri\" + 0.007*\"status\"\n",
      "\n",
      "Score: 0.2322763204574585\t \n",
      "Topic: 0.015*\"patient\" + 0.010*\"discharg\" + 0.009*\"bleed\" + 0.009*\"liver\" + 0.009*\"abdomin\" + 0.009*\"hospit\" + 0.008*\"histori\" + 0.008*\"blood\" + 0.007*\"medic\" + 0.006*\"pain\"\n",
      "\n",
      "Score: 0.16941964626312256\t \n",
      "Topic: 0.023*\"tablet\" + 0.016*\"daili\" + 0.015*\"hospit\" + 0.013*\"discharg\" + 0.009*\"patient\" + 0.009*\"histori\" + 0.009*\"medic\" + 0.008*\"admiss\" + 0.008*\"blood\" + 0.007*\"time\"\n",
      "\n",
      "Score: 0.06561106443405151\t \n",
      "Topic: 0.035*\"blood\" + 0.012*\"patient\" + 0.010*\"hospit\" + 0.009*\"cultur\" + 0.008*\"discharg\" + 0.007*\"tablet\" + 0.007*\"daili\" + 0.005*\"negat\" + 0.005*\"continu\" + 0.005*\"final\"\n",
      "\n",
      "Score: 0.05099734663963318\t \n",
      "Topic: 0.018*\"infant\" + 0.017*\"discharg\" + 0.012*\"life\" + 0.011*\"hospit\" + 0.010*\"week\" + 0.010*\"blood\" + 0.010*\"namepattern\" + 0.009*\"feed\" + 0.009*\"admiss\" + 0.009*\"screen\"\n"
     ]
    }
   ],
   "source": [
    "for index, score in sorted(lda_model[bow_corpus[4310]], key=lambda tup: -1*tup[1]):\n",
    "    print(\"\\nScore: {}\\t \\nTopic: {}\".format(score, lda_model.print_topic(index, 10)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance evaluation by classifying sample document using LDA TF-IDF model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Score: 0.7945289015769958\t \n",
      "Topic: 0.012*\"patient\" + 0.007*\"discharg\" + 0.006*\"hospit\" + 0.005*\"number\" + 0.005*\"histori\" + 0.005*\"blood\" + 0.004*\"namepattern\" + 0.004*\"unit\" + 0.004*\"admiss\" + 0.004*\"medic\"\n",
      "\n",
      "Score: 0.1946193277835846\t \n",
      "Topic: 0.006*\"blood\" + 0.006*\"reappear\" + 0.005*\"cultur\" + 0.005*\"tablet\" + 0.004*\"final\" + 0.004*\"analyz\" + 0.004*\"discharg\" + 0.004*\"hospit\" + 0.004*\"negat\" + 0.003*\"daili\"\n"
     ]
    }
   ],
   "source": [
    "for index, score in sorted(lda_model_tfidf[bow_corpus[4310]], key=lambda tup: -1*tup[1]):\n",
    "    print(\"\\nScore: {}\\t \\nTopic: {}\".format(score, lda_model_tfidf.print_topic(index, 10)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing model on unseen document\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "<class 'str'>\n",
      "Score: 0.5339741110801697\t Topic: 0.015*\"right\" + 0.009*\"hospit\" + 0.009*\"patient\" + 0.009*\"discharg\" + 0.008*\"head\"\n",
      "2\n",
      "<class 'str'>\n",
      "Score: 0.40144088864326477\t Topic: 0.051*\"patient\" + 0.014*\"discharg\" + 0.011*\"histori\" + 0.010*\"hospit\" + 0.008*\"medic\"\n",
      "0\n",
      "<class 'str'>\n",
      "Score: 0.05208202451467514\t Topic: 0.050*\"valv\" + 0.036*\"mild\" + 0.032*\"aortic\" + 0.027*\"mitral\" + 0.025*\"ventricular\"\n"
     ]
    }
   ],
   "source": [
    "unseen_document = \"\"\"\n",
    "Admission Date:  [**2151-7-16**]       Discharge Date:  [**2151-8-4**]\n",
    "\n",
    "\n",
    "Service:\n",
    "ADDENDUM:\n",
    "\n",
    "RADIOLOGIC STUDIES:  Radiologic studies also included a chest\n",
    "CT, which confirmed cavitary lesions in the left lung apex\n",
    "consistent with infectious process/tuberculosis.  This also\n",
    "moderate-sized left pleural effusion.\n",
    "\n",
    "HEAD CT:  Head CT showed no intracranial hemorrhage or mass\n",
    "effect, but old infarction consistent with past medical\n",
    "history.\n",
    "\n",
    "ABDOMINAL CT:  Abdominal CT showed lesions of\n",
    "T10 and sacrum most likely secondary to osteoporosis. These can\n",
    "be followed by repeat imaging as an outpatient.\n",
    "\n",
    "\n",
    "\n",
    "                            [**First Name8 (NamePattern2) **] [**First Name4 (NamePattern1) 1775**] [**Last Name (NamePattern1) **], M.D.  [**MD Number(1) 1776**]\n",
    "\n",
    "Dictated By:[**Hospital 1807**]\n",
    "MEDQUIST36\n",
    "\n",
    "D:  [**2151-8-5**]  12:11\n",
    "T:  [**2151-8-5**]  12:21\n",
    "JOB#:  [**Job Number 1808**]\n",
    "\n",
    "\"\"\"\n",
    "bow_vector = dictionary.doc2bow(preprocess(unseen_document))\n",
    "for index, score in sorted(lda_model[bow_vector], key=lambda tup: -1*tup[1]):\n",
    "    print(index)\n",
    "    print(type(lda_model.print_topic(index, 5)))\n",
    "    print(\"Score: {}\\t Topic: {}\".format(score, lda_model.print_topic(index, 5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (cse6250-project)",
   "language": "python",
   "name": "cse6250-project"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
