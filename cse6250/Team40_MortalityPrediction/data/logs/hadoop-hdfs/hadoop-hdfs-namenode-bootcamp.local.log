2018-09-12 05:05:45,559 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NameNode
STARTUP_MSG:   host = bootcamp.local/172.18.0.2
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.3
STARTUP_MSG:   classpath = /etc/hadoop/conf:/usr/lib/hadoop/lib/asm-3.2.jar:/usr/lib/hadoop/lib/jackson-jaxrs-1.9.13.jar:/usr/lib/hadoop/lib/api-asn1-api-1.0.0-M20.jar:/usr/lib/hadoop/lib/jersey-json-1.9.jar:/usr/lib/hadoop/lib/gson-2.2.4.jar:/usr/lib/hadoop/lib/commons-net-3.1.jar:/usr/lib/hadoop/lib/commons-digester-1.8.jar:/usr/lib/hadoop/lib/guava-11.0.2.jar:/usr/lib/hadoop/lib/api-util-1.0.0-M20.jar:/usr/lib/hadoop/lib/jets3t-0.9.0.jar:/usr/lib/hadoop/lib/snappy-java-1.0.4.1.jar:/usr/lib/hadoop/lib/commons-compress-1.4.1.jar:/usr/lib/hadoop/lib/activation-1.1.jar:/usr/lib/hadoop/lib/slf4j-log4j12-1.7.10.jar:/usr/lib/hadoop/lib/curator-framework-2.7.1.jar:/usr/lib/hadoop/lib/jackson-core-asl-1.9.13.jar:/usr/lib/hadoop/lib/commons-beanutils-1.7.0.jar:/usr/lib/hadoop/lib/curator-client-2.7.1.jar:/usr/lib/hadoop/lib/jsr305-3.0.0.jar:/usr/lib/hadoop/lib/avro-1.7.4.jar:/usr/lib/hadoop/lib/jackson-xc-1.9.13.jar:/usr/lib/hadoop/lib/commons-configuration-1.6.jar:/usr/lib/hadoop/lib/commons-math3-3.1.1.jar:/usr/lib/hadoop/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/lib/hadoop/lib/jaxb-api-2.2.2.jar:/usr/lib/hadoop/lib/netty-3.6.2.Final.jar:/usr/lib/hadoop/lib/curator-recipes-2.7.1.jar:/usr/lib/hadoop/lib/mockito-all-1.8.5.jar:/usr/lib/hadoop/lib/commons-codec-1.4.jar:/usr/lib/hadoop/lib/jettison-1.1.jar:/usr/lib/hadoop/lib/commons-httpclient-3.1.jar:/usr/lib/hadoop/lib/jsch-0.1.42.jar:/usr/lib/hadoop/lib/java-xmlbuilder-0.4.jar:/usr/lib/hadoop/lib/xz-1.0.jar:/usr/lib/hadoop/lib/commons-logging-1.1.3.jar:/usr/lib/hadoop/lib/log4j-1.2.17.jar:/usr/lib/hadoop/lib/zookeeper-3.4.6.jar:/usr/lib/hadoop/lib/commons-lang-2.6.jar:/usr/lib/hadoop/lib/hamcrest-core-1.3.jar:/usr/lib/hadoop/lib/httpclient-4.2.5.jar:/usr/lib/hadoop/lib/commons-cli-1.2.jar:/usr/lib/hadoop/lib/commons-io-2.4.jar:/usr/lib/hadoop/lib/apacheds-i18n-2.0.0-M15.jar:/usr/lib/hadoop/lib/jetty-util-6.1.26.jar:/usr/lib/hadoop/lib/jackson-mapper-asl-1.9.13.jar:/usr/lib/hadoop/lib/htrace-core-3.1.0-incubating.jar:/usr/lib/hadoop/lib/paranamer-2.3.jar:/usr/lib/hadoop/lib/xmlenc-0.52.jar:/usr/lib/hadoop/lib/jaxb-impl-2.2.3-1.jar:/usr/lib/hadoop/lib/commons-beanutils-core-1.8.0.jar:/usr/lib/hadoop/lib/jersey-server-1.9.jar:/usr/lib/hadoop/lib/slf4j-api-1.7.10.jar:/usr/lib/hadoop/lib/jsp-api-2.1.jar:/usr/lib/hadoop/lib/jetty-6.1.26.jar:/usr/lib/hadoop/lib/junit-4.11.jar:/usr/lib/hadoop/lib/servlet-api-2.5.jar:/usr/lib/hadoop/lib/httpcore-4.2.5.jar:/usr/lib/hadoop/lib/protobuf-java-2.5.0.jar:/usr/lib/hadoop/lib/jersey-core-1.9.jar:/usr/lib/hadoop/lib/stax-api-1.0-2.jar:/usr/lib/hadoop/lib/commons-collections-3.2.2.jar:/usr/lib/hadoop/.//hadoop-nfs.jar:/usr/lib/hadoop/.//hadoop-common.jar:/usr/lib/hadoop/.//hadoop-auth-2.7.3.jar:/usr/lib/hadoop/.//hadoop-common-2.7.3-tests.jar:/usr/lib/hadoop/.//hadoop-common-2.7.3.jar:/usr/lib/hadoop/.//hadoop-auth.jar:/usr/lib/hadoop/.//hadoop-annotations.jar:/usr/lib/hadoop/.//hadoop-annotations-2.7.3.jar:/usr/lib/hadoop/.//hadoop-nfs-2.7.3.jar:/usr/lib/hadoop-hdfs/./:/usr/lib/hadoop-hdfs/lib/asm-3.2.jar:/usr/lib/hadoop-hdfs/lib/xercesImpl-2.9.1.jar:/usr/lib/hadoop-hdfs/lib/guava-11.0.2.jar:/usr/lib/hadoop-hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/lib/hadoop-hdfs/lib/jsr305-3.0.0.jar:/usr/lib/hadoop-hdfs/lib/leveldbjni-all-1.8.jar:/usr/lib/hadoop-hdfs/lib/netty-3.6.2.Final.jar:/usr/lib/hadoop-hdfs/lib/netty-all-4.0.23.Final.jar:/usr/lib/hadoop-hdfs/lib/commons-codec-1.4.jar:/usr/lib/hadoop-hdfs/lib/xml-apis-1.3.04.jar:/usr/lib/hadoop-hdfs/lib/commons-logging-1.1.3.jar:/usr/lib/hadoop-hdfs/lib/log4j-1.2.17.jar:/usr/lib/hadoop-hdfs/lib/commons-lang-2.6.jar:/usr/lib/hadoop-hdfs/lib/commons-cli-1.2.jar:/usr/lib/hadoop-hdfs/lib/commons-io-2.4.jar:/usr/lib/hadoop-hdfs/lib/jetty-util-6.1.26.jar:/usr/lib/hadoop-hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/lib/hadoop-hdfs/lib/htrace-core-3.1.0-incubating.jar:/usr/lib/hadoop-hdfs/lib/xmlenc-0.52.jar:/usr/lib/hadoop-hdfs/lib/jersey-server-1.9.jar:/usr/lib/hadoop-hdfs/lib/jetty-6.1.26.jar:/usr/lib/hadoop-hdfs/lib/commons-daemon-1.0.13.jar:/usr/lib/hadoop-hdfs/lib/servlet-api-2.5.jar:/usr/lib/hadoop-hdfs/lib/protobuf-java-2.5.0.jar:/usr/lib/hadoop-hdfs/lib/jersey-core-1.9.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs-nfs.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs-2.7.3-tests.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs-nfs-2.7.3.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs-2.7.3.jar:/usr/lib/hadoop-yarn/lib/asm-3.2.jar:/usr/lib/hadoop-yarn/lib/jackson-jaxrs-1.9.13.jar:/usr/lib/hadoop-yarn/lib/jersey-json-1.9.jar:/usr/lib/hadoop-yarn/lib/jersey-client-1.9.jar:/usr/lib/hadoop-yarn/lib/guava-11.0.2.jar:/usr/lib/hadoop-yarn/lib/jersey-guice-1.9.jar:/usr/lib/hadoop-yarn/lib/commons-compress-1.4.1.jar:/usr/lib/hadoop-yarn/lib/activation-1.1.jar:/usr/lib/hadoop-yarn/lib/guice-servlet-3.0.jar:/usr/lib/hadoop-yarn/lib/zookeeper-3.4.6-tests.jar:/usr/lib/hadoop-yarn/lib/jackson-core-asl-1.9.13.jar:/usr/lib/hadoop-yarn/lib/jsr305-3.0.0.jar:/usr/lib/hadoop-yarn/lib/jackson-xc-1.9.13.jar:/usr/lib/hadoop-yarn/lib/leveldbjni-all-1.8.jar:/usr/lib/hadoop-yarn/lib/jaxb-api-2.2.2.jar:/usr/lib/hadoop-yarn/lib/netty-3.6.2.Final.jar:/usr/lib/hadoop-yarn/lib/javax.inject-1.jar:/usr/lib/hadoop-yarn/lib/commons-codec-1.4.jar:/usr/lib/hadoop-yarn/lib/jettison-1.1.jar:/usr/lib/hadoop-yarn/lib/guice-3.0.jar:/usr/lib/hadoop-yarn/lib/xz-1.0.jar:/usr/lib/hadoop-yarn/lib/commons-logging-1.1.3.jar:/usr/lib/hadoop-yarn/lib/log4j-1.2.17.jar:/usr/lib/hadoop-yarn/lib/zookeeper-3.4.6.jar:/usr/lib/hadoop-yarn/lib/commons-lang-2.6.jar:/usr/lib/hadoop-yarn/lib/commons-cli-1.2.jar:/usr/lib/hadoop-yarn/lib/commons-io-2.4.jar:/usr/lib/hadoop-yarn/lib/jetty-util-6.1.26.jar:/usr/lib/hadoop-yarn/lib/jackson-mapper-asl-1.9.13.jar:/usr/lib/hadoop-yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/lib/hadoop-yarn/lib/jersey-server-1.9.jar:/usr/lib/hadoop-yarn/lib/aopalliance-1.0.jar:/usr/lib/hadoop-yarn/lib/jetty-6.1.26.jar:/usr/lib/hadoop-yarn/lib/servlet-api-2.5.jar:/usr/lib/hadoop-yarn/lib/protobuf-java-2.5.0.jar:/usr/lib/hadoop-yarn/lib/jersey-core-1.9.jar:/usr/lib/hadoop-yarn/lib/stax-api-1.0-2.jar:/usr/lib/hadoop-yarn/lib/commons-collections-3.2.2.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-resourcemanager.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-resourcemanager-2.7.3.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-applicationhistoryservice-2.7.3.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-registry.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-tests.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-common.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-common-2.7.3.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-applications-distributedshell.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-client.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-common-2.7.3.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-applications-unmanaged-am-launcher.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-web-proxy.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-api.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-tests-2.7.3.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-nodemanager-2.7.3.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-api-2.7.3.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-sharedcachemanager-2.7.3.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-common.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-client-2.7.3.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-nodemanager.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-sharedcachemanager.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-registry-2.7.3.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-applications-unmanaged-am-launcher-2.7.3.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-web-proxy-2.7.3.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-applicationhistoryservice.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-applications-distributedshell-2.7.3.jar:/usr/lib/hadoop-mapreduce/lib/asm-3.2.jar:/usr/lib/hadoop-mapreduce/lib/jersey-guice-1.9.jar:/usr/lib/hadoop-mapreduce/lib/snappy-java-1.0.4.1.jar:/usr/lib/hadoop-mapreduce/lib/commons-compress-1.4.1.jar:/usr/lib/hadoop-mapreduce/lib/guice-servlet-3.0.jar:/usr/lib/hadoop-mapreduce/lib/jackson-core-asl-1.9.13.jar:/usr/lib/hadoop-mapreduce/lib/avro-1.7.4.jar:/usr/lib/hadoop-mapreduce/lib/leveldbjni-all-1.8.jar:/usr/lib/hadoop-mapreduce/lib/netty-3.6.2.Final.jar:/usr/lib/hadoop-mapreduce/lib/javax.inject-1.jar:/usr/lib/hadoop-mapreduce/lib/guice-3.0.jar:/usr/lib/hadoop-mapreduce/lib/xz-1.0.jar:/usr/lib/hadoop-mapreduce/lib/log4j-1.2.17.jar:/usr/lib/hadoop-mapreduce/lib/hamcrest-core-1.3.jar:/usr/lib/hadoop-mapreduce/lib/commons-io-2.4.jar:/usr/lib/hadoop-mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/usr/lib/hadoop-mapreduce/lib/paranamer-2.3.jar:/usr/lib/hadoop-mapreduce/lib/jersey-server-1.9.jar:/usr/lib/hadoop-mapreduce/lib/aopalliance-1.0.jar:/usr/lib/hadoop-mapreduce/lib/junit-4.11.jar:/usr/lib/hadoop-mapreduce/lib/protobuf-java-2.5.0.jar:/usr/lib/hadoop-mapreduce/lib/jersey-core-1.9.jar:/usr/lib/hadoop-mapreduce/.//jackson-core-2.2.3.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-jobclient-2.7.3-tests.jar:/usr/lib/hadoop-mapreduce/.//azure-storage-2.0.0.jar:/usr/lib/hadoop-mapreduce/.//metrics-core-3.0.1.jar:/usr/lib/hadoop-mapreduce/.//asm-3.2.jar:/usr/lib/hadoop-mapreduce/.//jackson-jaxrs-1.9.13.jar:/usr/lib/hadoop-mapreduce/.//hadoop-sls-2.7.3.jar:/usr/lib/hadoop-mapreduce/.//api-asn1-api-1.0.0-M20.jar:/usr/lib/hadoop-mapreduce/.//jersey-json-1.9.jar:/usr/lib/hadoop-mapreduce/.//gson-2.2.4.jar:/usr/lib/hadoop-mapreduce/.//commons-net-3.1.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-app-2.7.3.jar:/usr/lib/hadoop-mapreduce/.//commons-digester-1.8.jar:/usr/lib/hadoop-mapreduce/.//guava-11.0.2.jar:/usr/lib/hadoop-mapreduce/.//api-util-1.0.0-M20.jar:/usr/lib/hadoop-mapreduce/.//jets3t-0.9.0.jar:/usr/lib/hadoop-mapreduce/.//snappy-java-1.0.4.1.jar:/usr/lib/hadoop-mapreduce/.//hadoop-streaming-2.7.3.jar:/usr/lib/hadoop-mapreduce/.//commons-compress-1.4.1.jar:/usr/lib/hadoop-mapreduce/.//activation-1.1.jar:/usr/lib/hadoop-mapreduce/.//curator-framework-2.7.1.jar:/usr/lib/hadoop-mapreduce/.//hadoop-archives.jar:/usr/lib/hadoop-mapreduce/.//hadoop-aws.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-core.jar:/usr/lib/hadoop-mapreduce/.//jackson-core-asl-1.9.13.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-hs.jar:/usr/lib/hadoop-mapreduce/.//commons-beanutils-1.7.0.jar:/usr/lib/hadoop-mapreduce/.//curator-client-2.7.1.jar:/usr/lib/hadoop-mapreduce/.//hadoop-azure-2.7.3.jar:/usr/lib/hadoop-mapreduce/.//jsr305-3.0.0.jar:/usr/lib/hadoop-mapreduce/.//avro-1.7.4.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-jobclient.jar:/usr/lib/hadoop-mapreduce/.//hadoop-gridmix.jar:/usr/lib/hadoop-mapreduce/.//hadoop-distcp.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-app.jar:/usr/lib/hadoop-mapreduce/.//jackson-xc-1.9.13.jar:/usr/lib/hadoop-mapreduce/.//hadoop-auth-2.7.3.jar:/usr/lib/hadoop-mapreduce/.//commons-configuration-1.6.jar:/usr/lib/hadoop-mapreduce/.//commons-math3-3.1.1.jar:/usr/lib/hadoop-mapreduce/.//hadoop-datajoin-2.7.3.jar:/usr/lib/hadoop-mapreduce/.//apacheds-kerberos-codec-2.0.0-M15.jar:/usr/lib/hadoop-mapreduce/.//hadoop-gridmix-2.7.3.jar:/usr/lib/hadoop-mapreduce/.//hadoop-ant.jar:/usr/lib/hadoop-mapreduce/.//hadoop-auth.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-shuffle-2.7.3.jar:/usr/lib/hadoop-mapreduce/.//jaxb-api-2.2.2.jar:/usr/lib/hadoop-mapreduce/.//netty-3.6.2.Final.jar:/usr/lib/hadoop-mapreduce/.//curator-recipes-2.7.1.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-hs-plugins.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-common-2.7.3.jar:/usr/lib/hadoop-mapreduce/.//mockito-all-1.8.5.jar:/usr/lib/hadoop-mapreduce/.//joda-time-2.9.9.jar:/usr/lib/hadoop-mapreduce/.//hadoop-openstack.jar:/usr/lib/hadoop-mapreduce/.//jackson-annotations-2.2.3.jar:/usr/lib/hadoop-mapreduce/.//commons-codec-1.4.jar:/usr/lib/hadoop-mapreduce/.//hadoop-extras-2.7.3.jar:/usr/lib/hadoop-mapreduce/.//jettison-1.1.jar:/usr/lib/hadoop-mapreduce/.//hadoop-distcp-2.7.3.jar:/usr/lib/hadoop-mapreduce/.//commons-httpclient-3.1.jar:/usr/lib/hadoop-mapreduce/.//jsch-0.1.42.jar:/usr/lib/hadoop-mapreduce/.//hadoop-sls.jar:/usr/lib/hadoop-mapreduce/.//jackson-databind-2.2.3.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-hs-2.7.3.jar:/usr/lib/hadoop-mapreduce/.//java-xmlbuilder-0.4.jar:/usr/lib/hadoop-mapreduce/.//aws-java-sdk-1.7.4.jar:/usr/lib/hadoop-mapreduce/.//hadoop-aws-2.7.3.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-examples-2.7.3.jar:/usr/lib/hadoop-mapreduce/.//xz-1.0.jar:/usr/lib/hadoop-mapreduce/.//hadoop-rumen.jar:/usr/lib/hadoop-mapreduce/.//commons-logging-1.1.3.jar:/usr/lib/hadoop-mapreduce/.//log4j-1.2.17.jar:/usr/lib/hadoop-mapreduce/.//zookeeper-3.4.6.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-core-2.7.3.jar:/usr/lib/hadoop-mapreduce/.//hadoop-datajoin.jar:/usr/lib/hadoop-mapreduce/.//commons-lang-2.6.jar:/usr/lib/hadoop-mapreduce/.//commons-lang3-3.3.2.jar:/usr/lib/hadoop-mapreduce/.//hamcrest-core-1.3.jar:/usr/lib/hadoop-mapreduce/.//httpclient-4.2.5.jar:/usr/lib/hadoop-mapreduce/.//commons-cli-1.2.jar:/usr/lib/hadoop-mapreduce/.//commons-io-2.4.jar:/usr/lib/hadoop-mapreduce/.//apacheds-i18n-2.0.0-M15.jar:/usr/lib/hadoop-mapreduce/.//jetty-util-6.1.26.jar:/usr/lib/hadoop-mapreduce/.//jackson-mapper-asl-1.9.13.jar:/usr/lib/hadoop-mapreduce/.//hadoop-archives-2.7.3.jar:/usr/lib/hadoop-mapreduce/.//htrace-core-3.1.0-incubating.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-common.jar:/usr/lib/hadoop-mapreduce/.//paranamer-2.3.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-jobclient-2.7.3.jar:/usr/lib/hadoop-mapreduce/.//hadoop-extras.jar:/usr/lib/hadoop-mapreduce/.//xmlenc-0.52.jar:/usr/lib/hadoop-mapreduce/.//hadoop-openstack-2.7.3.jar:/usr/lib/hadoop-mapreduce/.//jaxb-impl-2.2.3-1.jar:/usr/lib/hadoop-mapreduce/.//commons-beanutils-core-1.8.0.jar:/usr/lib/hadoop-mapreduce/.//jersey-server-1.9.jar:/usr/lib/hadoop-mapreduce/.//jsp-api-2.1.jar:/usr/lib/hadoop-mapreduce/.//jetty-6.1.26.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-hs-plugins-2.7.3.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-examples.jar:/usr/lib/hadoop-mapreduce/.//junit-4.11.jar:/usr/lib/hadoop-mapreduce/.//hadoop-azure.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-shuffle.jar:/usr/lib/hadoop-mapreduce/.//hadoop-streaming.jar:/usr/lib/hadoop-mapreduce/.//hadoop-ant-2.7.3.jar:/usr/lib/hadoop-mapreduce/.//servlet-api-2.5.jar:/usr/lib/hadoop-mapreduce/.//httpcore-4.2.5.jar:/usr/lib/hadoop-mapreduce/.//hadoop-rumen-2.7.3.jar:/usr/lib/hadoop-mapreduce/.//protobuf-java-2.5.0.jar:/usr/lib/hadoop-mapreduce/.//jersey-core-1.9.jar:/usr/lib/hadoop-mapreduce/.//stax-api-1.0-2.jar:/usr/lib/hadoop-mapreduce/.//commons-collections-3.2.2.jar:/usr/lib/hadoop/contrib/capacity-scheduler/*.jar:/usr/lib/hadoop/contrib/capacity-scheduler/*.jar:/usr/lib/hadoop/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/bigtop.git -r 2365207dc0440bb884e41d4ffe32a37ad0d0ed28; compiled by 'jenkins' on 2017-10-05T21:00Z
STARTUP_MSG:   java = 1.8.0_181
************************************************************/
2018-09-12 05:05:45,567 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2018-09-12 05:05:45,571 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: createNameNode []
2018-09-12 05:05:45,803 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2018-09-12 05:05:45,874 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2018-09-12 05:05:45,874 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NameNode metrics system started
2018-09-12 05:05:45,877 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: fs.defaultFS is hdfs://bootcamp.local:9000
2018-09-12 05:05:45,879 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Clients are to use bootcamp.local:9000 to access this namenode/service.
2018-09-12 05:05:46,040 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for hdfs at: http://0.0.0.0:50070
2018-09-12 05:05:46,093 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2018-09-12 05:05:46,100 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2018-09-12 05:05:46,108 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.namenode is not defined
2018-09-12 05:05:46,115 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2018-09-12 05:05:46,118 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2018-09-12 05:05:46,118 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2018-09-12 05:05:46,119 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2018-09-12 05:05:46,225 INFO org.apache.hadoop.http.HttpServer2: Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2018-09-12 05:05:46,226 INFO org.apache.hadoop.http.HttpServer2: addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2018-09-12 05:05:46,238 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50070
2018-09-12 05:05:46,238 INFO org.mortbay.log: jetty-6.1.26
2018-09-12 05:05:46,357 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:50070
2018-09-12 05:05:46,380 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one image storage directory (dfs.namenode.name.dir) configured. Beware of data loss due to lack of redundant storage directories!
2018-09-12 05:05:46,381 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one namespace edits storage directory (dfs.namenode.edits.dir) configured. Beware of data loss due to lack of redundant storage directories!
2018-09-12 05:05:46,410 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: No KeyProvider found.
2018-09-12 05:05:46,411 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair:true
2018-09-12 05:05:46,455 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2018-09-12 05:05:46,456 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2018-09-12 05:05:46,458 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2018-09-12 05:05:46,459 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2018 Sep 12 05:05:46
2018-09-12 05:05:46,461 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2018-09-12 05:05:46,461 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2018-09-12 05:05:46,463 INFO org.apache.hadoop.util.GSet: 2.0% max memory 889 MB = 17.8 MB
2018-09-12 05:05:46,463 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2018-09-12 05:05:46,468 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2018-09-12 05:05:46,469 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 1
2018-09-12 05:05:46,469 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2018-09-12 05:05:46,470 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2018-09-12 05:05:46,470 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2018-09-12 05:05:46,470 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2018-09-12 05:05:46,471 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2018-09-12 05:05:46,471 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2018-09-12 05:05:46,476 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = hdfs (auth:SIMPLE)
2018-09-12 05:05:46,477 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2018-09-12 05:05:46,477 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2018-09-12 05:05:46,477 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2018-09-12 05:05:46,479 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2018-09-12 05:05:46,546 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2018-09-12 05:05:46,547 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2018-09-12 05:05:46,547 INFO org.apache.hadoop.util.GSet: 1.0% max memory 889 MB = 8.9 MB
2018-09-12 05:05:46,548 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2018-09-12 05:05:46,549 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: ACLs enabled? false
2018-09-12 05:05:46,550 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: XAttrs enabled? true
2018-09-12 05:05:46,550 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Maximum size of an xattr: 16384
2018-09-12 05:05:46,551 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times
2018-09-12 05:05:46,557 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2018-09-12 05:05:46,557 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2018-09-12 05:05:46,558 INFO org.apache.hadoop.util.GSet: 0.25% max memory 889 MB = 2.2 MB
2018-09-12 05:05:46,558 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2018-09-12 05:05:46,559 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2018-09-12 05:05:46,560 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2018-09-12 05:05:46,560 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2018-09-12 05:05:46,562 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.window.num.buckets = 10
2018-09-12 05:05:46,563 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.num.users = 10
2018-09-12 05:05:46,563 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2018-09-12 05:05:46,565 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache on namenode is enabled
2018-09-12 05:05:46,566 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2018-09-12 05:05:46,568 INFO org.apache.hadoop.util.GSet: Computing capacity for map NameNodeRetryCache
2018-09-12 05:05:46,568 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2018-09-12 05:05:46,568 INFO org.apache.hadoop.util.GSet: 0.029999999329447746% max memory 889 MB = 273.1 KB
2018-09-12 05:05:46,569 INFO org.apache.hadoop.util.GSet: capacity      = 2^15 = 32768 entries
2018-09-12 05:05:46,583 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /data/name/in_use.lock acquired by nodename 721@bootcamp.local
2018-09-12 05:05:46,627 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Recovering unfinalized segments in /data/name/current
2018-09-12 05:05:46,730 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /data/name/current/edits_inprogress_0000000000000000001 -> /data/name/current/edits_0000000000000000001-0000000000000000014
2018-09-12 05:05:46,742 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Planning to load image: FSImageFile(file=/data/name/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2018-09-12 05:05:46,762 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Loading 1 INodes.
2018-09-12 05:05:46,783 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Loaded FSImage in 0 seconds.
2018-09-12 05:05:46,783 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 0 from /data/name/current/fsimage_0000000000000000000
2018-09-12 05:05:46,784 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@2cae1042 expecting start txid #1
2018-09-12 05:05:46,784 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /data/name/current/edits_0000000000000000001-0000000000000000014
2018-09-12 05:05:46,786 INFO org.apache.hadoop.hdfs.server.namenode.EditLogInputStream: Fast-forwarding stream '/data/name/current/edits_0000000000000000001-0000000000000000014' to transaction ID 1
2018-09-12 05:05:46,799 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /data/name/current/edits_0000000000000000001-0000000000000000014 of size 1048576 edits # 14 loaded in 0 seconds
2018-09-12 05:05:46,800 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2018-09-12 05:05:46,801 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 15
2018-09-12 05:05:46,903 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2018-09-12 05:05:46,904 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Finished loading FSImage in 332 msecs
2018-09-12 05:05:47,025 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: RPC server is binding to bootcamp.local:9000
2018-09-12 05:05:47,030 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2018-09-12 05:05:47,039 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 9000
2018-09-12 05:05:47,060 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Registered FSNamesystemState MBean
2018-09-12 05:05:47,069 INFO org.apache.hadoop.hdfs.server.namenode.LeaseManager: Number of blocks under construction: 0
2018-09-12 05:05:47,069 INFO org.apache.hadoop.hdfs.server.namenode.LeaseManager: Number of blocks under construction: 0
2018-09-12 05:05:47,070 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: initializing replication queues
2018-09-12 05:05:47,070 INFO org.apache.hadoop.hdfs.StateChange: STATE* Leaving safe mode after 0 secs
2018-09-12 05:05:47,071 INFO org.apache.hadoop.hdfs.StateChange: STATE* Network topology has 0 racks and 0 datanodes
2018-09-12 05:05:47,071 INFO org.apache.hadoop.hdfs.StateChange: STATE* UnderReplicatedBlocks has 0 blocks
2018-09-12 05:05:47,077 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Number of failed storage changes from 0 to 0
2018-09-12 05:05:47,081 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Total number of blocks            = 0
2018-09-12 05:05:47,082 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of invalid blocks          = 0
2018-09-12 05:05:47,085 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of under-replicated blocks = 0
2018-09-12 05:05:47,085 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of  over-replicated blocks = 0
2018-09-12 05:05:47,085 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of blocks being written    = 0
2018-09-12 05:05:47,086 INFO org.apache.hadoop.hdfs.StateChange: STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 16 msec
2018-09-12 05:05:47,099 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2018-09-12 05:05:47,113 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 9000: starting
2018-09-12 05:05:47,117 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: NameNode RPC up at: bootcamp.local/172.18.0.2:9000
2018-09-12 05:05:47,117 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Starting services required for active state
2018-09-12 05:05:47,122 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Starting CacheReplicationMonitor with interval 30000 milliseconds
2018-09-12 05:05:56,217 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(172.18.0.2:50010, datanodeUuid=47ecd31e-43cd-4989-84ba-314b1664d0de, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-747ab8c6-1ec4-46a0-9dee-c8151846aca5;nsid=199960936;c=0) storage 47ecd31e-43cd-4989-84ba-314b1664d0de
2018-09-12 05:05:56,218 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Number of failed storage changes from 0 to 0
2018-09-12 05:05:56,219 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/172.18.0.2:50010
2018-09-12 05:05:56,280 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Number of failed storage changes from 0 to 0
2018-09-12 05:05:56,281 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Adding new storage ID DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5 for DN 172.18.0.2:50010
2018-09-12 05:05:56,320 INFO BlockStateChange: BLOCK* processReport: from storage DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5 node DatanodeRegistration(172.18.0.2:50010, datanodeUuid=47ecd31e-43cd-4989-84ba-314b1664d0de, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-747ab8c6-1ec4-46a0-9dee-c8151846aca5;nsid=199960936;c=0), blocks: 0, hasStaleStorage: false, processing time: 4 msecs
2018-09-12 05:06:21,921 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741825_1001{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /app/hbase/.tmp/hbase.version
2018-09-12 05:06:22,173 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* blk_1073741825_1001{UCState=COMMITTED, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} is not COMPLETE (ucState = COMMITTED, replication# = 0 <  minimum = 1) in file /app/hbase/.tmp/hbase.version
2018-09-12 05:06:22,178 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741825_1001{UCState=COMMITTED, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 7
2018-09-12 05:06:22,583 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /app/hbase/.tmp/hbase.version is closed by DFSClient_NONMAPREDUCE_533311914_1
2018-09-12 05:06:22,612 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741826_1002{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /app/hbase/.tmp/hbase.id
2018-09-12 05:06:22,632 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741826_1002{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 0
2018-09-12 05:06:22,636 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /app/hbase/.tmp/hbase.id is closed by DFSClient_NONMAPREDUCE_533311914_1
2018-09-12 05:06:22,746 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741827_1003{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /app/hbase/data/hbase/meta/1588230740/.regioninfo
2018-09-12 05:06:22,758 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741827_1003{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 0
2018-09-12 05:06:22,761 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /app/hbase/data/hbase/meta/1588230740/.regioninfo is closed by DFSClient_NONMAPREDUCE_533311914_1
2018-09-12 05:06:22,926 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /app/hbase/data/hbase/meta/1588230740/recovered.edits/2.seqid is closed by DFSClient_NONMAPREDUCE_533311914_1
2018-09-12 05:06:22,953 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741828_1004{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /app/hbase/data/hbase/meta/.tmp/.tableinfo.0000000001
2018-09-12 05:06:22,965 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741828_1004{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 0
2018-09-12 05:06:22,971 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /app/hbase/data/hbase/meta/.tmp/.tableinfo.0000000001 is closed by DFSClient_NONMAPREDUCE_533311914_1
2018-09-12 05:06:23,765 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741829_1005{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /app/hbase/WALs/bootcamp.local,16020,1536728777779/bootcamp.local%2C16020%2C1536728777779.default.1536728783702
2018-09-12 05:06:23,873 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* fsync: /app/hbase/WALs/bootcamp.local,16020,1536728777779/bootcamp.local%2C16020%2C1536728777779.default.1536728783702 for DFSClient_NONMAPREDUCE_-2068461939_1
2018-09-12 05:06:28,805 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741830_1006{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /app/hbase/WALs/bootcamp.local,16020,1536728777779/bootcamp.local%2C16020%2C1536728777779..meta.1536728788794.meta
2018-09-12 05:06:28,818 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* fsync: /app/hbase/WALs/bootcamp.local,16020,1536728777779/bootcamp.local%2C16020%2C1536728777779..meta.1536728788794.meta for DFSClient_NONMAPREDUCE_-2068461939_1
2018-09-12 05:06:29,437 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /app/hbase/data/hbase/meta/1588230740/recovered.edits/3.seqid is closed by DFSClient_NONMAPREDUCE_-2068461939_1
2018-09-12 05:06:29,813 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741831_1007{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /app/hbase/MasterProcWALs/state-00000000000000000001.log
2018-09-12 05:06:29,835 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* fsync: /app/hbase/MasterProcWALs/state-00000000000000000001.log for DFSClient_NONMAPREDUCE_533311914_1
2018-09-12 05:06:30,010 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741832_1008{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /app/hbase/.tmp/data/hbase/namespace/.tmp/.tableinfo.0000000001
2018-09-12 05:06:30,024 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741832_1008{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 0
2018-09-12 05:06:30,030 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /app/hbase/.tmp/data/hbase/namespace/.tmp/.tableinfo.0000000001 is closed by DFSClient_NONMAPREDUCE_533311914_1
2018-09-12 05:06:30,054 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741833_1009{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /app/hbase/.tmp/data/hbase/namespace/b7bfc7fcc5816946e33ea9db3ddeebfa/.regioninfo
2018-09-12 05:06:30,068 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741833_1009{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 0
2018-09-12 05:06:30,070 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /app/hbase/.tmp/data/hbase/namespace/b7bfc7fcc5816946e33ea9db3ddeebfa/.regioninfo is closed by DFSClient_NONMAPREDUCE_533311914_1
2018-09-12 05:06:30,492 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /app/hbase/data/hbase/namespace/b7bfc7fcc5816946e33ea9db3ddeebfa/recovered.edits/2.seqid is closed by DFSClient_NONMAPREDUCE_-2068461939_1
2018-09-12 05:11:50,566 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 90 Total time for transactions(ms): 5 Number of transactions batched in Syncs: 9 Number of syncs: 56 SyncTimes(ms): 69 
2018-09-12 05:11:50,630 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741834_1010{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /app/hbase/data/hbase/meta/1588230740/.tmp/effd8209acf94d26b0e6e055f312a485
2018-09-12 05:11:50,676 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741834_1010{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 0
2018-09-12 05:11:50,682 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /app/hbase/data/hbase/meta/1588230740/.tmp/effd8209acf94d26b0e6e055f312a485 is closed by DFSClient_NONMAPREDUCE_-2068461939_1
2018-09-12 05:21:52,803 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 97 Total time for transactions(ms): 9 Number of transactions batched in Syncs: 9 Number of syncs: 61 SyncTimes(ms): 74 
2018-09-12 05:21:52,911 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741831_1007{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 469
2018-09-12 05:21:52,919 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /app/hbase/MasterProcWALs/state-00000000000000000001.log is closed by DFSClient_NONMAPREDUCE_533311914_1
2018-09-12 05:21:52,935 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741831_1007 172.18.0.2:50010 
2018-09-12 05:21:55,855 INFO BlockStateChange: BLOCK* BlockManager: ask 172.18.0.2:50010 to delete [blk_1073741831_1007]
2018-09-12 05:22:55,968 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 103 Total time for transactions(ms): 10 Number of transactions batched in Syncs: 9 Number of syncs: 66 SyncTimes(ms): 82 
2018-09-12 05:35:23,159 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 106 Total time for transactions(ms): 10 Number of transactions batched in Syncs: 9 Number of syncs: 69 SyncTimes(ms): 85 
2018-09-12 05:36:43,553 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 110 Total time for transactions(ms): 10 Number of transactions batched in Syncs: 9 Number of syncs: 73 SyncTimes(ms): 89 
2018-09-12 05:38:15,671 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 111 Total time for transactions(ms): 11 Number of transactions batched in Syncs: 9 Number of syncs: 74 SyncTimes(ms): 117 
2018-09-12 05:38:15,712 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741835_1011{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /input/events/events.csv._COPYING_
2018-09-12 05:38:15,859 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741835_1011{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 0
2018-09-12 05:38:15,865 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /input/events/events.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_1864742537_1
2018-09-12 05:38:21,250 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741836_1012{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /input/events/mortality.csv._COPYING_
2018-09-12 05:38:21,345 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741836_1012{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 0
2018-09-12 05:38:21,348 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /input/events/mortality.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1101847840_1
2018-09-12 05:39:24,986 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 125 Total time for transactions(ms): 13 Number of transactions batched in Syncs: 9 Number of syncs: 84 SyncTimes(ms): 133 
2018-09-12 05:40:56,985 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 128 Total time for transactions(ms): 13 Number of transactions batched in Syncs: 9 Number of syncs: 87 SyncTimes(ms): 138 
2018-09-12 05:40:59,923 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741837_1013{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /input/mortality/mortality.csv._COPYING_
2018-09-12 05:41:00,037 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741837_1013{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 0
2018-09-12 05:41:00,041 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /input/mortality/mortality.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_-2048684882_1
2018-09-12 05:51:57,798 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1137ms
No GCs detected
2018-09-12 05:53:05,219 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1163ms
No GCs detected
2018-09-12 05:54:01,011 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1077ms
No GCs detected
2018-09-12 05:54:15,657 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1454ms
No GCs detected
2018-09-12 06:16:26,767 WARN org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 56790ms
No GCs detected
2018-09-12 06:16:27,521 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 137 Total time for transactions(ms): 33 Number of transactions batched in Syncs: 9 Number of syncs: 94 SyncTimes(ms): 149 
2018-09-12 06:16:27,685 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741838_1014{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /app/hbase/WALs/bootcamp.local,16020,1536728777779/bootcamp.local%2C16020%2C1536728777779.default.1536732986933
2018-09-12 06:16:27,689 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741839_1015{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /app/hbase/WALs/bootcamp.local,16020,1536728777779/bootcamp.local%2C16020%2C1536728777779..meta.1536732986915.meta
2018-09-12 06:16:27,894 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* fsync: /app/hbase/WALs/bootcamp.local,16020,1536728777779/bootcamp.local%2C16020%2C1536728777779..meta.1536732986915.meta for DFSClient_NONMAPREDUCE_-2068461939_1
2018-09-12 06:16:27,894 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* fsync: /app/hbase/WALs/bootcamp.local,16020,1536728777779/bootcamp.local%2C16020%2C1536728777779.default.1536732986933 for DFSClient_NONMAPREDUCE_-2068461939_1
2018-09-12 06:16:28,897 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741840_1016{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /app/hbase/MasterProcWALs/state-00000000000000000002.log
2018-09-12 06:16:29,070 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* blk_1073741840_1016{UCState=COMMITTED, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} is not COMPLETE (ucState = COMMITTED, replication# = 0 <  minimum = 1) in file /app/hbase/MasterProcWALs/state-00000000000000000002.log
2018-09-12 06:16:29,072 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741840_1016{UCState=COMMITTED, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 30
2018-09-12 06:16:29,476 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /app/hbase/MasterProcWALs/state-00000000000000000002.log is closed by DFSClient_NONMAPREDUCE_533311914_1
2018-09-12 06:16:29,642 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741839_1015{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 83
2018-09-12 06:16:29,646 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /app/hbase/WALs/bootcamp.local,16020,1536728777779/bootcamp.local%2C16020%2C1536728777779..meta.1536732986915.meta is closed by DFSClient_NONMAPREDUCE_-2068461939_1
2018-09-12 06:16:29,658 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741838_1014{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 83
2018-09-12 06:16:29,663 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /app/hbase/WALs/bootcamp.local,16020,1536728777779/bootcamp.local%2C16020%2C1536728777779.default.1536732986933 is closed by DFSClient_NONMAPREDUCE_-2068461939_1
2018-09-12 06:19:39,613 WARN org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 55089ms
No GCs detected
2018-09-12 06:24:09,304 WARN org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 41363ms
No GCs detected
2018-09-12 06:44:27,372 WARN org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 34528ms
No GCs detected
2018-09-12 06:58:26,007 WARN org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 31217ms
No GCs detected
2018-09-12 07:14:16,213 INFO BlockStateChange: BLOCK* processReport: from storage DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5 node DatanodeRegistration(172.18.0.2:50010, datanodeUuid=47ecd31e-43cd-4989-84ba-314b1664d0de, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-747ab8c6-1ec4-46a0-9dee-c8151846aca5;nsid=199960936;c=0), blocks: 15, hasStaleStorage: false, processing time: 26 msecs
2018-09-12 07:53:26,767 INFO org.apache.hadoop.hdfs.server.namenode.LeaseManager: [Lease.  Holder: DFSClient_NONMAPREDUCE_-2068461939_1, pendingcreates: 2] has expired hard limit
2018-09-12 07:53:26,772 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Recovering [Lease.  Holder: DFSClient_NONMAPREDUCE_-2068461939_1, pendingcreates: 2], src=/app/hbase/WALs/bootcamp.local,16020,1536728777779/bootcamp.local%2C16020%2C1536728777779.default.1536728783702
2018-09-12 07:53:26,819 INFO BlockStateChange: BLOCK* blk_1073741829_1005{UCState=UNDER_RECOVERY, truncateBlock=null, primaryNodeIndex=0, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} recovery started, primary=ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]
2018-09-12 07:53:26,820 WARN org.apache.hadoop.hdfs.StateChange: DIR* NameSystem.internalReleaseLease: File /app/hbase/WALs/bootcamp.local,16020,1536728777779/bootcamp.local%2C16020%2C1536728777779.default.1536728783702 has not been closed. Lease recovery is in progress. RecoveryId = 1017 for block blk_1073741829_1005{UCState=UNDER_RECOVERY, truncateBlock=null, primaryNodeIndex=0, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]}
2018-09-12 07:53:26,822 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Recovering [Lease.  Holder: DFSClient_NONMAPREDUCE_-2068461939_1, pendingcreates: 1], src=/app/hbase/oldWALs/bootcamp.local%2C16020%2C1536728777779..meta.1536728788794.meta
2018-09-12 07:53:26,823 INFO BlockStateChange: BLOCK* blk_1073741830_1006{UCState=UNDER_RECOVERY, truncateBlock=null, primaryNodeIndex=0, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} recovery started, primary=ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]
2018-09-12 07:53:26,824 WARN org.apache.hadoop.hdfs.StateChange: DIR* NameSystem.internalReleaseLease: File /app/hbase/oldWALs/bootcamp.local%2C16020%2C1536728777779..meta.1536728788794.meta has not been closed. Lease recovery is in progress. RecoveryId = 1018 for block blk_1073741830_1006{UCState=UNDER_RECOVERY, truncateBlock=null, primaryNodeIndex=0, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]}
2018-09-12 07:53:26,832 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 158 Total time for transactions(ms): 37 Number of transactions batched in Syncs: 10 Number of syncs: 106 SyncTimes(ms): 186 
2018-09-12 07:53:27,966 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741829_1005{UCState=UNDER_RECOVERY, truncateBlock=null, primaryNodeIndex=0, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 83
2018-09-12 07:53:28,022 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: commitBlockSynchronization(oldBlock=BP-1288371730-172.17.0.2-1536728332297:blk_1073741829_1005, newgenerationstamp=1017, newlength=575, newtargets=[172.18.0.2:50010], closeFile=true, deleteBlock=false)
2018-09-12 07:53:28,068 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: commitBlockSynchronization(oldBlock=BP-1288371730-172.17.0.2-1536728332297:blk_1073741829_1005, file=/app/hbase/WALs/bootcamp.local,16020,1536728777779/bootcamp.local%2C16020%2C1536728777779.default.1536728783702, newgenerationstamp=1017, newlength=575, newtargets=[172.18.0.2:50010]) successful
2018-09-12 07:53:28,097 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: commitBlockSynchronization(oldBlock=BP-1288371730-172.17.0.2-1536728332297:blk_1073741830_1006, newgenerationstamp=1018, newlength=1136, newtargets=[172.18.0.2:50010], closeFile=true, deleteBlock=false)
2018-09-12 07:53:28,103 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: commitBlockSynchronization(oldBlock=BP-1288371730-172.17.0.2-1536728332297:blk_1073741830_1006, file=/app/hbase/oldWALs/bootcamp.local%2C16020%2C1536728777779..meta.1536728788794.meta, newgenerationstamp=1018, newlength=1136, newtargets=[172.18.0.2:50010]) successful
2018-09-12 08:24:10,240 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1186ms
No GCs detected
2018-09-12 08:54:45,568 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1240ms
No GCs detected
2018-09-12 09:40:46,834 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1024ms
No GCs detected
2018-09-12 10:26:35,830 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1082ms
No GCs detected
2018-09-12 11:32:02,022 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1069ms
No GCs detected
2018-09-12 12:32:12,726 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1102ms
No GCs detected
2018-09-12 13:31:50,716 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1202ms
No GCs detected
2018-09-12 14:30:27,882 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1061ms
No GCs detected
2018-09-12 15:34:10,140 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1277ms
No GCs detected
2018-09-12 15:34:23,951 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1262ms
No GCs detected
2018-09-12 16:23:58,395 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1596ms
No GCs detected
2018-09-12 16:27:07,323 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1572ms
No GCs detected
2018-09-12 16:27:58,770 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1498ms
No GCs detected
2018-09-12 16:28:58,407 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1136ms
No GCs detected
2018-09-12 16:36:36,304 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1070ms
No GCs detected
2018-09-12 20:00:39,831 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1301ms
No GCs detected
2018-09-12 20:02:10,066 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1577ms
No GCs detected
2018-09-12 20:31:16,038 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1451ms
No GCs detected
2018-09-12 20:44:11,660 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1663ms
No GCs detected
2018-09-12 20:49:50,853 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1407ms
No GCs detected
2018-09-12 21:04:44,655 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1411ms
No GCs detected
2018-09-12 21:05:43,153 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1210ms
No GCs detected
2018-09-12 21:25:08,142 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1274ms
No GCs detected
2018-09-12 22:29:48,065 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1599ms
No GCs detected
2018-09-12 22:32:14,825 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1458ms
No GCs detected
2018-09-12 22:53:09,263 INFO BlockStateChange: BLOCK* processReport: from storage DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5 node DatanodeRegistration(172.18.0.2:50010, datanodeUuid=47ecd31e-43cd-4989-84ba-314b1664d0de, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-747ab8c6-1ec4-46a0-9dee-c8151846aca5;nsid=199960936;c=0), blocks: 15, hasStaleStorage: false, processing time: 0 msecs
2018-09-13 00:00:41,405 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1320ms
No GCs detected
2018-09-13 03:37:34,170 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1164ms
No GCs detected
2018-09-13 04:58:47,253 INFO BlockStateChange: BLOCK* processReport: from storage DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5 node DatanodeRegistration(172.18.0.2:50010, datanodeUuid=47ecd31e-43cd-4989-84ba-314b1664d0de, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-747ab8c6-1ec4-46a0-9dee-c8151846aca5;nsid=199960936;c=0), blocks: 15, hasStaleStorage: false, processing time: 0 msecs
2018-09-13 06:44:24,272 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1535ms
No GCs detected
2018-09-13 07:14:56,687 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1502ms
No GCs detected
2018-09-13 07:16:09,689 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1089ms
No GCs detected
2018-09-13 07:17:07,692 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1136ms
No GCs detected
2018-09-13 07:18:17,920 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1500ms
No GCs detected
2018-09-13 07:37:21,736 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1138ms
No GCs detected
2018-09-13 07:48:09,659 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1061ms
No GCs detected
2018-09-13 07:49:06,704 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1134ms
No GCs detected
2018-09-13 07:52:01,623 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1151ms
No GCs detected
2018-09-13 08:27:06,705 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1069ms
No GCs detected
2018-09-13 08:28:03,699 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1115ms
No GCs detected
2018-09-13 08:29:13,748 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1176ms
No GCs detected
2018-09-13 08:51:38,674 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1158ms
No GCs detected
2018-09-13 08:52:48,712 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1108ms
No GCs detected
2018-09-13 08:53:54,651 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1232ms
No GCs detected
2018-09-13 08:54:50,670 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1157ms
No GCs detected
2018-09-13 09:00:05,649 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1175ms
No GCs detected
2018-09-13 09:01:42,641 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1055ms
No GCs detected
2018-09-13 09:03:06,596 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1141ms
No GCs detected
2018-09-13 09:05:25,554 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1094ms
No GCs detected
2018-09-13 09:38:49,828 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1319ms
No GCs detected
2018-09-13 09:39:45,701 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1083ms
No GCs detected
2018-09-13 09:40:56,648 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1028ms
No GCs detected
2018-09-13 10:06:13,685 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1230ms
No GCs detected
2018-09-13 10:07:09,611 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1204ms
No GCs detected
2018-09-13 10:12:28,758 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 2240ms
No GCs detected
2018-09-13 10:13:24,646 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1107ms
No GCs detected
2018-09-13 10:14:22,657 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1195ms
No GCs detected
2018-09-13 10:15:30,760 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1125ms
No GCs detected
2018-09-13 10:20:37,623 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1080ms
No GCs detected
2018-09-13 10:21:45,607 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1148ms
No GCs detected
2018-09-13 10:22:41,584 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1029ms
No GCs detected
2018-09-13 10:49:01,608 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1024ms
No GCs detected
2018-09-13 10:52:22,622 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1139ms
No GCs detected
2018-09-13 11:16:54,650 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1103ms
No GCs detected
2018-09-13 11:18:54,557 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1105ms
No GCs detected
2018-09-13 11:25:30,623 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1265ms
No GCs detected
2018-09-13 11:27:54,630 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1024ms
No GCs detected
2018-09-13 11:31:53,681 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1135ms
No GCs detected
2018-09-13 11:32:50,580 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1143ms
No GCs detected
2018-09-13 11:33:56,716 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1164ms
No GCs detected
2018-09-13 12:02:18,605 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1157ms
No GCs detected
2018-09-13 12:03:14,642 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1151ms
No GCs detected
2018-09-13 12:04:17,629 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1209ms
No GCs detected
2018-09-13 12:29:53,726 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1171ms
No GCs detected
2018-09-13 12:30:50,624 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1232ms
No GCs detected
2018-09-13 12:46:21,655 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1247ms
No GCs detected
2018-09-13 12:47:17,672 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1084ms
No GCs detected
2018-09-13 12:48:15,595 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1119ms
No GCs detected
2018-09-13 12:49:15,636 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1160ms
No GCs detected
2018-09-13 13:16:31,639 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1104ms
No GCs detected
2018-09-13 13:27:41,967 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1463ms
No GCs detected
2018-09-13 13:28:39,629 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1071ms
No GCs detected
2018-09-13 13:41:09,752 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1119ms
No GCs detected
2018-09-13 13:42:05,662 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1106ms
No GCs detected
2018-09-13 13:58:43,656 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1134ms
No GCs detected
2018-09-13 13:59:39,652 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1178ms
No GCs detected
2018-09-13 14:00:37,747 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1030ms
No GCs detected
2018-09-13 14:17:31,082 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1562ms
No GCs detected
2018-09-13 14:38:56,970 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1507ms
No GCs detected
2018-09-13 14:40:00,205 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 2725ms
No GCs detected
2018-09-13 14:51:33,626 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1158ms
No GCs detected
2018-09-13 14:52:30,613 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1119ms
No GCs detected
2018-09-13 14:55:15,654 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1216ms
No GCs detected
2018-09-13 15:06:43,016 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1474ms
No GCs detected
2018-09-13 15:08:14,717 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1240ms
No GCs detected
2018-09-13 15:09:16,926 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1354ms
No GCs detected
2018-09-13 15:10:39,063 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1597ms
No GCs detected
2018-09-13 15:12:02,909 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 2518ms
No GCs detected
2018-09-13 15:14:26,200 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1680ms
No GCs detected
2018-09-13 15:16:00,293 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1802ms
No GCs detected
2018-09-13 15:17:19,090 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1268ms
No GCs detected
2018-09-13 15:18:35,000 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1559ms
No GCs detected
2018-09-13 15:19:52,143 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1630ms
No GCs detected
2018-09-13 15:22:13,392 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1738ms
No GCs detected
2018-09-13 15:23:27,130 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1675ms
No GCs detected
2018-09-13 15:27:29,025 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1565ms
No GCs detected
2018-09-13 15:30:16,057 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1242ms
No GCs detected
2018-09-13 15:31:33,244 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1305ms
No GCs detected
2018-09-13 15:36:24,095 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1320ms
No GCs detected
2018-09-13 15:38:11,111 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1334ms
No GCs detected
2018-09-13 15:40:28,064 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1257ms
No GCs detected
2018-09-13 15:54:21,003 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1576ms
No GCs detected
2018-09-13 15:55:18,025 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1556ms
No GCs detected
2018-09-13 16:05:38,035 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1592ms
No GCs detected
2018-09-13 16:06:57,112 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1303ms
No GCs detected
2018-09-13 16:07:14,246 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1599ms
No GCs detected
2018-09-13 16:10:15,607 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1331ms
No GCs detected
2018-09-13 18:02:25,059 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1203ms
No GCs detected
2018-09-13 18:07:59,002 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1426ms
No GCs detected
2018-09-13 20:08:01,477 INFO BlockStateChange: BLOCK* processReport: from storage DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5 node DatanodeRegistration(172.18.0.2:50010, datanodeUuid=47ecd31e-43cd-4989-84ba-314b1664d0de, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-747ab8c6-1ec4-46a0-9dee-c8151846aca5;nsid=199960936;c=0), blocks: 15, hasStaleStorage: false, processing time: 21 msecs
2018-09-14 02:07:33,848 INFO BlockStateChange: BLOCK* processReport: from storage DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5 node DatanodeRegistration(172.18.0.2:50010, datanodeUuid=47ecd31e-43cd-4989-84ba-314b1664d0de, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-747ab8c6-1ec4-46a0-9dee-c8151846aca5;nsid=199960936;c=0), blocks: 15, hasStaleStorage: false, processing time: 3 msecs
2018-09-14 02:22:34,468 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1350ms
No GCs detected
2018-09-14 02:24:34,521 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1377ms
No GCs detected
2018-09-14 02:37:35,968 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1418ms
No GCs detected
2018-09-14 02:40:16,766 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1211ms
No GCs detected
2018-09-14 02:41:13,663 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1181ms
No GCs detected
2018-09-14 02:43:38,598 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1133ms
No GCs detected
2018-09-14 02:46:48,838 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1115ms
No GCs detected
2018-09-14 02:47:57,596 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1055ms
No GCs detected
2018-09-14 02:49:10,739 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 2176ms
No GCs detected
2018-09-14 02:53:52,591 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1019ms
No GCs detected
2018-09-14 02:55:04,737 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1148ms
No GCs detected
2018-09-14 02:56:02,825 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 2306ms
No GCs detected
2018-09-14 03:09:45,650 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1061ms
No GCs detected
2018-09-14 03:10:44,640 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1125ms
No GCs detected
2018-09-14 03:12:43,685 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1218ms
No GCs detected
2018-09-14 03:46:14,790 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1299ms
No GCs detected
2018-09-14 06:20:10,485 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1380ms
No GCs detected
2018-09-14 06:23:34,050 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1234ms
No GCs detected
2018-09-14 06:27:46,620 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1293ms
No GCs detected
2018-09-14 06:29:30,899 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1074ms
No GCs detected
2018-09-14 06:39:26,669 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1343ms
No GCs detected
2018-09-14 06:40:23,701 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1360ms
No GCs detected
2018-09-14 06:42:22,470 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1244ms
No GCs detected
2018-09-14 06:54:08,593 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1337ms
No GCs detected
2018-09-14 06:55:21,707 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1353ms
No GCs detected
2018-09-14 06:56:19,802 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 2416ms
No GCs detected
2018-09-14 06:57:16,475 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1024ms
No GCs detected
2018-09-14 06:58:16,344 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1076ms
No GCs detected
2018-09-14 07:39:38,763 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 2474ms
No GCs detected
2018-09-14 07:40:34,674 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1384ms
No GCs detected
2018-09-14 07:42:33,786 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1287ms
No GCs detected
2018-09-14 07:43:46,531 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1214ms
No GCs detected
2018-09-14 07:44:43,546 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1303ms
No GCs detected
2018-09-14 07:54:13,748 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 2435ms
No GCs detected
2018-09-14 07:55:08,633 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1325ms
No GCs detected
2018-09-14 07:56:05,665 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1401ms
No GCs detected
2018-09-14 07:57:11,627 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1365ms
No GCs detected
2018-09-14 08:08:15,702 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1515ms
No GCs detected
2018-09-14 08:09:13,778 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1344ms
No GCs detected
2018-09-14 08:11:06,642 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1312ms
No GCs detected
2018-09-14 08:12:06,639 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1352ms
No GCs detected
2018-09-14 08:51:37,613 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1418ms
No GCs detected
2018-09-14 08:52:35,703 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1442ms
No GCs detected
2018-09-14 08:53:37,624 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1323ms
No GCs detected
2018-09-14 08:56:07,563 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1264ms
No GCs detected
2018-09-14 08:57:04,626 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 2292ms
No GCs detected
2018-09-14 08:58:03,468 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1150ms
No GCs detected
2018-09-14 09:06:57,531 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1240ms
No GCs detected
2018-09-14 09:08:22,518 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1240ms
No GCs detected
2018-09-14 09:21:10,517 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1251ms
No GCs detected
2018-09-14 09:23:17,623 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1163ms
No GCs detected
2018-09-14 09:24:49,492 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1234ms
No GCs detected
2018-09-14 10:05:55,670 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1396ms
No GCs detected
2018-09-14 10:06:55,679 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1378ms
No GCs detected
2018-09-14 10:12:59,573 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1328ms
No GCs detected
2018-09-14 10:14:06,462 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1199ms
No GCs detected
2018-09-14 10:19:42,453 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1006ms
No GCs detected
2018-09-14 10:20:39,638 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1376ms
No GCs detected
2018-09-14 10:22:40,808 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1437ms
No GCs detected
2018-09-14 10:34:07,842 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1123ms
No GCs detected
2018-09-14 10:35:10,611 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1413ms
No GCs detected
2018-09-14 10:36:07,601 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1289ms
No GCs detected
2018-09-14 10:37:24,607 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1285ms
No GCs detected
2018-09-14 10:40:39,631 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1357ms
No GCs detected
2018-09-14 11:18:11,631 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1405ms
No GCs detected
2018-09-14 11:19:27,728 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1247ms
No GCs detected
2018-09-14 11:20:26,572 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1173ms
No GCs detected
2018-09-14 11:24:20,518 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1245ms
No GCs detected
2018-09-14 11:25:20,624 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1258ms
No GCs detected
2018-09-14 11:26:22,399 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1165ms
No GCs detected
2018-09-14 11:35:12,466 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1158ms
No GCs detected
2018-09-14 11:36:10,593 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 2414ms
No GCs detected
2018-09-14 11:37:06,520 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1287ms
No GCs detected
2018-09-14 11:46:48,625 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 2342ms
No GCs detected
2018-09-14 11:48:09,468 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1252ms
No GCs detected
2018-09-14 11:49:29,481 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1181ms
No GCs detected
2018-09-14 11:52:27,520 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1229ms
No GCs detected
2018-09-14 11:53:25,443 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1367ms
No GCs detected
2018-09-14 11:54:30,405 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1196ms
No GCs detected
2018-09-14 12:32:24,548 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1258ms
No GCs detected
2018-09-14 12:33:25,503 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1231ms
No GCs detected
2018-09-14 12:36:01,544 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1275ms
No GCs detected
2018-09-14 12:46:37,505 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1376ms
No GCs detected
2018-09-14 12:48:38,466 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1213ms
No GCs detected
2018-09-14 12:58:57,506 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1268ms
No GCs detected
2018-09-14 12:59:54,435 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1224ms
No GCs detected
2018-09-14 13:01:46,433 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1197ms
No GCs detected
2018-09-14 13:03:09,390 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1157ms
No GCs detected
2018-09-14 13:07:41,577 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1365ms
No GCs detected
2018-09-14 13:46:09,552 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1286ms
No GCs detected
2018-09-14 13:50:09,513 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1306ms
No GCs detected
2018-09-14 13:51:41,492 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1278ms
No GCs detected
2018-09-14 13:52:40,483 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1264ms
No GCs detected
2018-09-14 13:57:39,689 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1191ms
No GCs detected
2018-09-14 14:10:41,497 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1311ms
No GCs detected
2018-09-14 14:11:39,571 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1182ms
No GCs detected
2018-09-14 14:18:36,534 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1347ms
No GCs detected
2018-09-14 14:21:47,724 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 2591ms
No GCs detected
2018-09-14 14:59:50,710 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 2371ms
No GCs detected
2018-09-14 15:01:15,877 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 2194ms
No GCs detected
2018-09-14 15:05:01,578 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1377ms
No GCs detected
2018-09-14 15:07:23,665 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1298ms
No GCs detected
2018-09-14 15:10:48,429 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1251ms
No GCs detected
2018-09-14 15:21:28,319 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1163ms
No GCs detected
2018-09-14 15:24:32,533 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1442ms
No GCs detected
2018-09-14 15:30:46,463 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1274ms
No GCs detected
2018-09-14 15:31:43,454 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1258ms
No GCs detected
2018-09-14 16:12:51,551 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1353ms
No GCs detected
2018-09-14 16:16:06,533 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1368ms
No GCs detected
2018-09-14 16:17:02,523 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1350ms
No GCs detected
2018-09-14 16:22:43,503 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1291ms
No GCs detected
2018-09-14 16:24:32,505 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1318ms
No GCs detected
2018-09-14 17:59:28,419 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1383ms
No GCs detected
2018-09-14 19:59:26,249 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1276ms
No GCs detected
2018-09-14 20:41:05,694 INFO BlockStateChange: BLOCK* processReport: from storage DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5 node DatanodeRegistration(172.18.0.2:50010, datanodeUuid=47ecd31e-43cd-4989-84ba-314b1664d0de, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-747ab8c6-1ec4-46a0-9dee-c8151846aca5;nsid=199960936;c=0), blocks: 15, hasStaleStorage: false, processing time: 9 msecs
2018-09-14 21:06:30,252 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1549ms
No GCs detected
2018-09-14 21:37:51,579 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1252ms
No GCs detected
2018-09-14 22:11:29,941 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1073ms
No GCs detected
2018-09-14 22:12:45,515 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1206ms
No GCs detected
2018-09-14 22:13:38,579 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1299ms
No GCs detected
2018-09-14 23:13:06,787 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1555ms
No GCs detected
2018-09-14 23:32:30,525 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1722ms
No GCs detected
2018-09-14 23:42:00,267 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1616ms
No GCs detected
2018-09-14 23:53:02,633 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1188ms
No GCs detected
2018-09-15 01:17:39,681 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1297ms
No GCs detected
2018-09-15 02:13:50,002 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1392ms
No GCs detected
2018-09-15 02:25:55,698 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1304ms
No GCs detected
2018-09-15 02:46:20,744 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1592ms
No GCs detected
2018-09-15 03:40:09,596 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1718ms
No GCs detected
2018-09-15 07:25:59,221 WARN org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 34983ms
No GCs detected
2018-09-15 09:26:01,014 WARN org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 33925ms
No GCs detected
2018-09-15 11:26:04,468 WARN org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 30301ms
No GCs detected
2018-09-15 13:26:08,170 WARN org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 34333ms
No GCs detected
2018-09-15 13:27:13,918 WARN org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 37567ms
No GCs detected
2018-09-15 16:51:35,522 WARN org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 31768ms
No GCs detected
2018-09-15 17:44:03,325 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 164 Total time for transactions(ms): 46 Number of transactions batched in Syncs: 10 Number of syncs: 109 SyncTimes(ms): 197 
2018-09-15 17:49:55,594 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 167 Total time for transactions(ms): 52 Number of transactions batched in Syncs: 10 Number of syncs: 112 SyncTimes(ms): 205 
2018-09-15 17:50:59,030 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 168 Total time for transactions(ms): 53 Number of transactions batched in Syncs: 10 Number of syncs: 113 SyncTimes(ms): 207 
2018-09-15 17:50:59,087 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741841_1019{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /input/events/events.csv._COPYING_
2018-09-15 17:51:00,237 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741842_1020{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /input/events/events.csv._COPYING_
2018-09-15 17:51:00,250 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741841_1019{UCState=COMMITTED, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 134217728
2018-09-15 17:51:00,902 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741842_1020{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 0
2018-09-15 17:51:00,911 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /input/events/events.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_-877203781_1
2018-09-15 17:51:00,925 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741835_1011 172.18.0.2:50010 
2018-09-15 17:51:03,363 INFO BlockStateChange: BLOCK* BlockManager: ask 172.18.0.2:50010 to delete [blk_1073741835_1011]
2018-09-15 17:51:12,047 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741843_1021{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /input/mortality/mortality.csv._COPYING_
2018-09-15 17:51:12,185 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741843_1021{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 0
2018-09-15 17:51:12,190 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /input/mortality/mortality.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_1291697698_1
2018-09-15 17:51:12,201 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741837_1013 172.18.0.2:50010 
2018-09-15 17:51:12,333 INFO BlockStateChange: BLOCK* BlockManager: ask 172.18.0.2:50010 to delete [blk_1073741837_1013]
2018-09-15 17:52:09,528 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 187 Total time for transactions(ms): 55 Number of transactions batched in Syncs: 10 Number of syncs: 126 SyncTimes(ms): 226 
2018-09-15 17:55:27,314 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 190 Total time for transactions(ms): 55 Number of transactions batched in Syncs: 10 Number of syncs: 129 SyncTimes(ms): 230 
2018-09-15 20:30:34,240 INFO BlockStateChange: BLOCK* processReport: from storage DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5 node DatanodeRegistration(172.18.0.2:50010, datanodeUuid=47ecd31e-43cd-4989-84ba-314b1664d0de, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-747ab8c6-1ec4-46a0-9dee-c8151846aca5;nsid=199960936;c=0), blocks: 16, hasStaleStorage: false, processing time: 1 msecs
2018-09-16 02:30:08,149 INFO BlockStateChange: BLOCK* processReport: from storage DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5 node DatanodeRegistration(172.18.0.2:50010, datanodeUuid=47ecd31e-43cd-4989-84ba-314b1664d0de, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-747ab8c6-1ec4-46a0-9dee-c8151846aca5;nsid=199960936;c=0), blocks: 16, hasStaleStorage: false, processing time: 4 msecs
2018-09-16 08:29:42,015 INFO BlockStateChange: BLOCK* processReport: from storage DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5 node DatanodeRegistration(172.18.0.2:50010, datanodeUuid=47ecd31e-43cd-4989-84ba-314b1664d0de, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-747ab8c6-1ec4-46a0-9dee-c8151846aca5;nsid=199960936;c=0), blocks: 16, hasStaleStorage: false, processing time: 3 msecs
2018-09-16 14:29:17,992 INFO BlockStateChange: BLOCK* processReport: from storage DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5 node DatanodeRegistration(172.18.0.2:50010, datanodeUuid=47ecd31e-43cd-4989-84ba-314b1664d0de, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-747ab8c6-1ec4-46a0-9dee-c8151846aca5;nsid=199960936;c=0), blocks: 16, hasStaleStorage: false, processing time: 4 msecs
2018-09-16 20:28:51,736 INFO BlockStateChange: BLOCK* processReport: from storage DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5 node DatanodeRegistration(172.18.0.2:50010, datanodeUuid=47ecd31e-43cd-4989-84ba-314b1664d0de, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-747ab8c6-1ec4-46a0-9dee-c8151846aca5;nsid=199960936;c=0), blocks: 16, hasStaleStorage: false, processing time: 21 msecs
2018-09-17 00:20:23,071 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 9000, call org.apache.hadoop.hdfs.protocol.ClientProtocol.mkdirs from 172.18.0.2:59632 Call#2 Retry#0: org.apache.hadoop.security.AccessControlException: Permission denied: user=root, access=WRITE, inode="/hw2":hdfs:supergroup:drwxr-xr-x
2018-09-17 00:20:36,136 INFO org.apache.hadoop.ipc.Server: IPC Server handler 9 on 9000, call org.apache.hadoop.hdfs.protocol.ClientProtocol.mkdirs from 172.18.0.2:59634 Call#2 Retry#0: org.apache.hadoop.security.AccessControlException: Permission denied: user=root, access=WRITE, inode="/hw2":hdfs:supergroup:drwxr-xr-x
2018-09-17 00:22:46,584 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 191 Total time for transactions(ms): 82 Number of transactions batched in Syncs: 10 Number of syncs: 130 SyncTimes(ms): 231 
2018-09-17 00:24:02,847 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 193 Total time for transactions(ms): 84 Number of transactions batched in Syncs: 10 Number of syncs: 132 SyncTimes(ms): 238 
2018-09-17 00:24:03,357 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /hw2/training/_SUCCESS._COPYING_ is closed by DFSClient_NONMAPREDUCE_-481621515_1
2018-09-17 00:24:03,459 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741844_1022{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /hw2/training/part-r-00000._COPYING_
2018-09-17 00:24:03,787 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741844_1022{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 0
2018-09-17 00:24:03,805 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /hw2/training/part-r-00000._COPYING_ is closed by DFSClient_NONMAPREDUCE_-481621515_1
2018-09-17 01:05:00,219 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 205 Total time for transactions(ms): 112 Number of transactions batched in Syncs: 10 Number of syncs: 140 SyncTimes(ms): 264 
2018-09-17 01:13:58,726 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 207 Total time for transactions(ms): 113 Number of transactions batched in Syncs: 10 Number of syncs: 142 SyncTimes(ms): 266 
2018-09-17 01:15:28,236 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 215 Total time for transactions(ms): 113 Number of transactions batched in Syncs: 10 Number of syncs: 146 SyncTimes(ms): 276 
2018-09-17 01:15:30,910 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741845_1023{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /hw2/models/_temporary/0/_temporary/attempt_local1720574909_0001_r_000000_0/part-00000
2018-09-17 01:15:31,015 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741845_1023{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 0
2018-09-17 01:15:31,021 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /hw2/models/_temporary/0/_temporary/attempt_local1720574909_0001_r_000000_0/part-00000 is closed by DFSClient_NONMAPREDUCE_1515427017_1
2018-09-17 01:15:32,971 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741846_1024{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /hw2/models/_temporary/0/_temporary/attempt_local1720574909_0001_r_000001_0/part-00001
2018-09-17 01:15:33,019 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741846_1024{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 0
2018-09-17 01:15:33,026 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /hw2/models/_temporary/0/_temporary/attempt_local1720574909_0001_r_000001_0/part-00001 is closed by DFSClient_NONMAPREDUCE_1515427017_1
2018-09-17 01:15:34,937 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741847_1025{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /hw2/models/_temporary/0/_temporary/attempt_local1720574909_0001_r_000002_0/part-00002
2018-09-17 01:15:34,969 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741847_1025{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 0
2018-09-17 01:15:34,979 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /hw2/models/_temporary/0/_temporary/attempt_local1720574909_0001_r_000002_0/part-00002 is closed by DFSClient_NONMAPREDUCE_1515427017_1
2018-09-17 01:15:36,844 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741848_1026{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /hw2/models/_temporary/0/_temporary/attempt_local1720574909_0001_r_000003_0/part-00003
2018-09-17 01:15:36,875 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741848_1026{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 0
2018-09-17 01:15:36,879 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /hw2/models/_temporary/0/_temporary/attempt_local1720574909_0001_r_000003_0/part-00003 is closed by DFSClient_NONMAPREDUCE_1515427017_1
2018-09-17 01:15:38,769 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741849_1027{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /hw2/models/_temporary/0/_temporary/attempt_local1720574909_0001_r_000004_0/part-00004
2018-09-17 01:15:38,796 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741849_1027{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 0
2018-09-17 01:15:38,800 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /hw2/models/_temporary/0/_temporary/attempt_local1720574909_0001_r_000004_0/part-00004 is closed by DFSClient_NONMAPREDUCE_1515427017_1
2018-09-17 01:15:38,900 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /hw2/models/_SUCCESS is closed by DFSClient_NONMAPREDUCE_1515427017_1
2018-09-17 01:25:41,322 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 260 Total time for transactions(ms): 127 Number of transactions batched in Syncs: 10 Number of syncs: 175 SyncTimes(ms): 313 
2018-09-17 01:25:41,339 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741845_1023 172.18.0.2:50010 
2018-09-17 01:25:41,340 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741846_1024 172.18.0.2:50010 
2018-09-17 01:25:41,341 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741847_1025 172.18.0.2:50010 
2018-09-17 01:25:41,341 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741848_1026 172.18.0.2:50010 
2018-09-17 01:25:41,342 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741849_1027 172.18.0.2:50010 
2018-09-17 01:25:43,376 INFO BlockStateChange: BLOCK* BlockManager: ask 172.18.0.2:50010 to delete [blk_1073741845_1023, blk_1073741846_1024, blk_1073741847_1025, blk_1073741848_1026, blk_1073741849_1027]
2018-09-17 01:25:49,311 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741850_1028{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /hw2/models/_temporary/0/_temporary/attempt_local237731793_0001_r_000000_0/part-00000
2018-09-17 01:25:49,420 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741850_1028{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 0
2018-09-17 01:25:49,434 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /hw2/models/_temporary/0/_temporary/attempt_local237731793_0001_r_000000_0/part-00000 is closed by DFSClient_NONMAPREDUCE_-1313828042_1
2018-09-17 01:25:51,403 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741851_1029{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /hw2/models/_temporary/0/_temporary/attempt_local237731793_0001_r_000001_0/part-00001
2018-09-17 01:25:51,445 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741851_1029{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 0
2018-09-17 01:25:51,448 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /hw2/models/_temporary/0/_temporary/attempt_local237731793_0001_r_000001_0/part-00001 is closed by DFSClient_NONMAPREDUCE_-1313828042_1
2018-09-17 01:25:53,388 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741852_1030{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /hw2/models/_temporary/0/_temporary/attempt_local237731793_0001_r_000002_0/part-00002
2018-09-17 01:25:53,416 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741852_1030{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 0
2018-09-17 01:25:53,418 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /hw2/models/_temporary/0/_temporary/attempt_local237731793_0001_r_000002_0/part-00002 is closed by DFSClient_NONMAPREDUCE_-1313828042_1
2018-09-17 01:25:55,449 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741853_1031{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /hw2/models/_temporary/0/_temporary/attempt_local237731793_0001_r_000003_0/part-00003
2018-09-17 01:25:55,506 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741853_1031{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 0
2018-09-17 01:25:55,508 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /hw2/models/_temporary/0/_temporary/attempt_local237731793_0001_r_000003_0/part-00003 is closed by DFSClient_NONMAPREDUCE_-1313828042_1
2018-09-17 01:25:57,379 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741854_1032{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /hw2/models/_temporary/0/_temporary/attempt_local237731793_0001_r_000004_0/part-00004
2018-09-17 01:25:57,418 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741854_1032{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 0
2018-09-17 01:25:57,420 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /hw2/models/_temporary/0/_temporary/attempt_local237731793_0001_r_000004_0/part-00004 is closed by DFSClient_NONMAPREDUCE_-1313828042_1
2018-09-17 01:25:57,516 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /hw2/models/_SUCCESS is closed by DFSClient_NONMAPREDUCE_-1313828042_1
2018-09-17 01:27:38,387 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 309 Total time for transactions(ms): 129 Number of transactions batched in Syncs: 10 Number of syncs: 205 SyncTimes(ms): 382 
2018-09-17 01:27:38,394 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741850_1028 172.18.0.2:50010 
2018-09-17 01:27:38,395 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741851_1029 172.18.0.2:50010 
2018-09-17 01:27:38,395 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741852_1030 172.18.0.2:50010 
2018-09-17 01:27:38,396 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741853_1031 172.18.0.2:50010 
2018-09-17 01:27:38,397 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741854_1032 172.18.0.2:50010 
2018-09-17 01:27:40,287 INFO BlockStateChange: BLOCK* BlockManager: ask 172.18.0.2:50010 to delete [blk_1073741850_1028, blk_1073741851_1029, blk_1073741852_1030, blk_1073741853_1031, blk_1073741854_1032]
2018-09-17 01:27:46,378 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741855_1033{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /hw2/models/_temporary/0/_temporary/attempt_local336829155_0001_r_000000_0/part-00000
2018-09-17 01:27:46,503 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741855_1033{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 0
2018-09-17 01:27:46,512 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /hw2/models/_temporary/0/_temporary/attempt_local336829155_0001_r_000000_0/part-00000 is closed by DFSClient_NONMAPREDUCE_407917063_1
2018-09-17 01:27:48,431 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741856_1034{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /hw2/models/_temporary/0/_temporary/attempt_local336829155_0001_r_000001_0/part-00001
2018-09-17 01:27:48,463 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741856_1034{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 0
2018-09-17 01:27:48,468 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /hw2/models/_temporary/0/_temporary/attempt_local336829155_0001_r_000001_0/part-00001 is closed by DFSClient_NONMAPREDUCE_407917063_1
2018-09-17 01:27:50,308 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741857_1035{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /hw2/models/_temporary/0/_temporary/attempt_local336829155_0001_r_000002_0/part-00002
2018-09-17 01:27:50,340 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741857_1035{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 0
2018-09-17 01:27:50,345 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /hw2/models/_temporary/0/_temporary/attempt_local336829155_0001_r_000002_0/part-00002 is closed by DFSClient_NONMAPREDUCE_407917063_1
2018-09-17 01:27:52,389 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741858_1036{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /hw2/models/_temporary/0/_temporary/attempt_local336829155_0001_r_000003_0/part-00003
2018-09-17 01:27:52,419 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741858_1036{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 0
2018-09-17 01:27:52,422 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /hw2/models/_temporary/0/_temporary/attempt_local336829155_0001_r_000003_0/part-00003 is closed by DFSClient_NONMAPREDUCE_407917063_1
2018-09-17 01:27:54,315 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741859_1037{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /hw2/models/_temporary/0/_temporary/attempt_local336829155_0001_r_000004_0/part-00004
2018-09-17 01:27:54,338 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741859_1037{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 0
2018-09-17 01:27:54,342 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /hw2/models/_temporary/0/_temporary/attempt_local336829155_0001_r_000004_0/part-00004 is closed by DFSClient_NONMAPREDUCE_407917063_1
2018-09-17 01:27:54,447 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /hw2/models/_SUCCESS is closed by DFSClient_NONMAPREDUCE_407917063_1
2018-09-17 01:28:07,184 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741855_1033 172.18.0.2:50010 
2018-09-17 01:28:07,184 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741856_1034 172.18.0.2:50010 
2018-09-17 01:28:07,185 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741857_1035 172.18.0.2:50010 
2018-09-17 01:28:07,186 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741858_1036 172.18.0.2:50010 
2018-09-17 01:28:07,186 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741859_1037 172.18.0.2:50010 
2018-09-17 01:28:07,261 INFO BlockStateChange: BLOCK* BlockManager: ask 172.18.0.2:50010 to delete [blk_1073741856_1034, blk_1073741857_1035, blk_1073741858_1036, blk_1073741859_1037, blk_1073741855_1033]
2018-09-17 01:28:14,782 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741860_1038{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /hw2/models/_temporary/0/_temporary/attempt_local108781438_0001_r_000000_0/part-00000
2018-09-17 01:28:14,872 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741860_1038{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 0
2018-09-17 01:28:14,875 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /hw2/models/_temporary/0/_temporary/attempt_local108781438_0001_r_000000_0/part-00000 is closed by DFSClient_NONMAPREDUCE_2089579986_1
2018-09-17 01:28:16,747 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741861_1039{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /hw2/models/_temporary/0/_temporary/attempt_local108781438_0001_r_000001_0/part-00001
2018-09-17 01:28:16,781 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741861_1039{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 0
2018-09-17 01:28:16,792 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /hw2/models/_temporary/0/_temporary/attempt_local108781438_0001_r_000001_0/part-00001 is closed by DFSClient_NONMAPREDUCE_2089579986_1
2018-09-17 01:28:18,779 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741862_1040{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /hw2/models/_temporary/0/_temporary/attempt_local108781438_0001_r_000002_0/part-00002
2018-09-17 01:28:18,799 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741862_1040{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 0
2018-09-17 01:28:18,801 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /hw2/models/_temporary/0/_temporary/attempt_local108781438_0001_r_000002_0/part-00002 is closed by DFSClient_NONMAPREDUCE_2089579986_1
2018-09-17 01:28:20,672 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741863_1041{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /hw2/models/_temporary/0/_temporary/attempt_local108781438_0001_r_000003_0/part-00003
2018-09-17 01:28:20,698 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741863_1041{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 0
2018-09-17 01:28:20,702 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /hw2/models/_temporary/0/_temporary/attempt_local108781438_0001_r_000003_0/part-00003 is closed by DFSClient_NONMAPREDUCE_2089579986_1
2018-09-17 01:28:22,701 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741864_1042{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /hw2/models/_temporary/0/_temporary/attempt_local108781438_0001_r_000004_0/part-00004
2018-09-17 01:28:22,739 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741864_1042{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 0
2018-09-17 01:28:22,743 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /hw2/models/_temporary/0/_temporary/attempt_local108781438_0001_r_000004_0/part-00004 is closed by DFSClient_NONMAPREDUCE_2089579986_1
2018-09-17 01:28:22,840 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /hw2/models/_SUCCESS is closed by DFSClient_NONMAPREDUCE_2089579986_1
2018-09-17 01:35:10,852 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 405 Total time for transactions(ms): 135 Number of transactions batched in Syncs: 10 Number of syncs: 265 SyncTimes(ms): 478 
2018-09-17 01:35:10,855 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741860_1038 172.18.0.2:50010 
2018-09-17 01:35:10,857 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741861_1039 172.18.0.2:50010 
2018-09-17 01:35:10,858 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741862_1040 172.18.0.2:50010 
2018-09-17 01:35:10,858 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741863_1041 172.18.0.2:50010 
2018-09-17 01:35:10,861 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741864_1042 172.18.0.2:50010 
2018-09-17 01:35:12,922 INFO BlockStateChange: BLOCK* BlockManager: ask 172.18.0.2:50010 to delete [blk_1073741860_1038, blk_1073741861_1039, blk_1073741862_1040, blk_1073741863_1041, blk_1073741864_1042]
2018-09-17 01:35:27,016 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741865_1043{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /hw2/models/_temporary/0/_temporary/attempt_local1468832563_0001_r_000000_0/part-00000
2018-09-17 01:35:27,118 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741865_1043{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 0
2018-09-17 01:35:27,125 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /hw2/models/_temporary/0/_temporary/attempt_local1468832563_0001_r_000000_0/part-00000 is closed by DFSClient_NONMAPREDUCE_118569176_1
2018-09-17 01:35:28,932 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741866_1044{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /hw2/models/_temporary/0/_temporary/attempt_local1468832563_0001_r_000001_0/part-00001
2018-09-17 01:35:28,967 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741866_1044{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 0
2018-09-17 01:35:28,972 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /hw2/models/_temporary/0/_temporary/attempt_local1468832563_0001_r_000001_0/part-00001 is closed by DFSClient_NONMAPREDUCE_118569176_1
2018-09-17 01:35:30,839 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741867_1045{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /hw2/models/_temporary/0/_temporary/attempt_local1468832563_0001_r_000002_0/part-00002
2018-09-17 01:35:30,864 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741867_1045{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 0
2018-09-17 01:35:30,870 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /hw2/models/_temporary/0/_temporary/attempt_local1468832563_0001_r_000002_0/part-00002 is closed by DFSClient_NONMAPREDUCE_118569176_1
2018-09-17 01:35:32,543 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741868_1046{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /hw2/models/_temporary/0/_temporary/attempt_local1468832563_0001_r_000003_0/part-00003
2018-09-17 01:35:32,593 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741868_1046{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 0
2018-09-17 01:35:32,603 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /hw2/models/_temporary/0/_temporary/attempt_local1468832563_0001_r_000003_0/part-00003 is closed by DFSClient_NONMAPREDUCE_118569176_1
2018-09-17 01:35:34,551 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741869_1047{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /hw2/models/_temporary/0/_temporary/attempt_local1468832563_0001_r_000004_0/part-00004
2018-09-17 01:35:34,622 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741869_1047{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 0
2018-09-17 01:35:34,627 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /hw2/models/_temporary/0/_temporary/attempt_local1468832563_0001_r_000004_0/part-00004 is closed by DFSClient_NONMAPREDUCE_118569176_1
2018-09-17 01:35:34,774 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /hw2/models/_SUCCESS is closed by DFSClient_NONMAPREDUCE_118569176_1
2018-09-17 01:39:02,777 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 453 Total time for transactions(ms): 151 Number of transactions batched in Syncs: 10 Number of syncs: 295 SyncTimes(ms): 569 
2018-09-17 01:41:30,865 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 458 Total time for transactions(ms): 152 Number of transactions batched in Syncs: 10 Number of syncs: 297 SyncTimes(ms): 570 
2018-09-17 01:44:54,241 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 461 Total time for transactions(ms): 152 Number of transactions batched in Syncs: 10 Number of syncs: 300 SyncTimes(ms): 573 
2018-09-17 02:20:03,663 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1241ms
No GCs detected
2018-09-17 02:20:28,947 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1202ms
No GCs detected
2018-09-17 07:20:01,528 WARN org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 61318ms
No GCs detected
2018-09-17 09:20:03,044 WARN org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 47383ms
No GCs detected
2018-09-17 11:20:02,343 WARN org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 35342ms
No GCs detected
2018-09-17 11:21:06,176 WARN org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 35669ms
No GCs detected
2018-09-17 13:54:03,632 WARN org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 36972ms
No GCs detected
2018-09-17 13:57:14,790 INFO BlockStateChange: BLOCK* processReport: from storage DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5 node DatanodeRegistration(172.18.0.2:50010, datanodeUuid=47ecd31e-43cd-4989-84ba-314b1664d0de, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-747ab8c6-1ec4-46a0-9dee-c8151846aca5;nsid=199960936;c=0), blocks: 22, hasStaleStorage: false, processing time: 43 msecs
2018-09-17 14:56:57,126 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1413ms
No GCs detected
2018-09-17 15:35:01,186 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1058ms
No GCs detected
2018-09-17 16:28:29,344 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1352ms
No GCs detected
2018-09-17 20:54:37,241 INFO BlockStateChange: BLOCK* processReport: from storage DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5 node DatanodeRegistration(172.18.0.2:50010, datanodeUuid=47ecd31e-43cd-4989-84ba-314b1664d0de, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-747ab8c6-1ec4-46a0-9dee-c8151846aca5;nsid=199960936;c=0), blocks: 22, hasStaleStorage: false, processing time: 1 msecs
2018-09-17 21:02:54,873 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1376ms
No GCs detected
2018-09-17 21:04:42,230 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1514ms
No GCs detected
2018-09-17 22:01:21,999 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1358ms
No GCs detected
2018-09-17 22:01:55,398 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1088ms
No GCs detected
2018-09-17 23:12:21,995 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1143ms
No GCs detected
2018-09-18 00:02:30,900 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1309ms
No GCs detected
2018-09-18 01:35:45,002 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1167ms
No GCs detected
2018-09-18 01:36:26,696 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 2498ms
No GCs detected
2018-09-18 01:38:27,958 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1083ms
No GCs detected
2018-09-18 01:49:50,360 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1516ms
No GCs detected
2018-09-18 01:58:57,358 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1398ms
No GCs detected
2018-09-18 02:04:47,148 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1214ms
No GCs detected
2018-09-18 02:06:16,753 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 2395ms
No GCs detected
2018-09-18 02:19:08,538 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1189ms
No GCs detected
2018-09-18 03:12:49,343 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1147ms
No GCs detected
2018-09-18 03:34:53,460 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1035ms
No GCs detected
2018-09-18 04:20:19,156 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 2460ms
No GCs detected
2018-09-18 05:35:15,646 INFO BlockStateChange: BLOCK* processReport: from storage DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5 node DatanodeRegistration(172.18.0.2:50010, datanodeUuid=47ecd31e-43cd-4989-84ba-314b1664d0de, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-747ab8c6-1ec4-46a0-9dee-c8151846aca5;nsid=199960936;c=0), blocks: 22, hasStaleStorage: false, processing time: 0 msecs
2018-09-18 06:55:47,907 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1310ms
No GCs detected
2018-09-18 07:26:17,648 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1132ms
No GCs detected
2018-09-18 07:36:46,039 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1207ms
No GCs detected
2018-09-18 08:14:15,027 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1155ms
No GCs detected
2018-09-18 08:48:02,051 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1057ms
No GCs detected
2018-09-18 09:26:39,022 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1140ms
No GCs detected
2018-09-18 10:25:14,949 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1073ms
No GCs detected
2018-09-18 12:25:36,032 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1376ms
No GCs detected
2018-09-18 13:29:47,741 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1251ms
No GCs detected
2018-09-18 15:23:33,973 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1108ms
No GCs detected
2018-09-18 15:58:55,732 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1343ms
No GCs detected
2018-09-18 16:32:29,798 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1331ms
No GCs detected
2018-09-18 16:33:40,011 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1227ms
No GCs detected
2018-09-18 17:21:08,448 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1326ms
No GCs detected
2018-09-18 17:36:12,806 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1420ms
No GCs detected
2018-09-18 17:46:03,958 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1095ms
No GCs detected
2018-09-18 17:49:28,879 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1131ms
No GCs detected
2018-09-18 17:50:41,857 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1034ms
No GCs detected
2018-09-18 17:52:09,902 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1094ms
No GCs detected
2018-09-18 18:03:22,839 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1323ms
No GCs detected
2018-09-18 18:52:31,150 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1239ms
No GCs detected
2018-09-18 19:34:59,073 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1229ms
No GCs detected
2018-09-18 20:59:57,542 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1168ms
No GCs detected
2018-09-18 21:39:16,819 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 2296ms
No GCs detected
2018-09-18 22:22:53,317 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1273ms
No GCs detected
2018-09-18 23:52:44,271 INFO BlockStateChange: BLOCK* processReport: from storage DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5 node DatanodeRegistration(172.18.0.2:50010, datanodeUuid=47ecd31e-43cd-4989-84ba-314b1664d0de, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-747ab8c6-1ec4-46a0-9dee-c8151846aca5;nsid=199960936;c=0), blocks: 22, hasStaleStorage: false, processing time: 1 msecs
2018-09-18 23:57:16,150 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1469ms
No GCs detected
2018-09-18 23:58:19,778 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1329ms
No GCs detected
2018-09-19 02:15:50,030 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1414ms
No GCs detected
2018-09-19 02:48:24,107 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1326ms
No GCs detected
2018-09-19 02:59:50,849 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1645ms
No GCs detected
2018-09-19 07:15:45,478 WARN org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 52478ms
No GCs detected
2018-09-19 07:16:29,576 WARN org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 32553ms
No GCs detected
2018-09-19 09:16:13,800 WARN org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 26178ms
No GCs detected
2018-09-19 10:15:21,245 WARN org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 36322ms
No GCs detected
2018-09-19 12:51:53,385 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1415ms
No GCs detected
2018-09-19 13:57:54,688 INFO BlockStateChange: BLOCK* processReport: from storage DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5 node DatanodeRegistration(172.18.0.2:50010, datanodeUuid=47ecd31e-43cd-4989-84ba-314b1664d0de, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-747ab8c6-1ec4-46a0-9dee-c8151846aca5;nsid=199960936;c=0), blocks: 22, hasStaleStorage: false, processing time: 14 msecs
2018-09-19 15:21:07,112 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1274ms
No GCs detected
2018-09-19 15:33:15,024 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1495ms
GC pool 'PS Scavenge' had collection(s): count=1 time=1825ms
2018-09-19 15:39:34,786 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1479ms
No GCs detected
2018-09-19 15:49:41,842 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1115ms
No GCs detected
2018-09-19 20:35:03,452 INFO BlockStateChange: BLOCK* processReport: from storage DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5 node DatanodeRegistration(172.18.0.2:50010, datanodeUuid=47ecd31e-43cd-4989-84ba-314b1664d0de, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-747ab8c6-1ec4-46a0-9dee-c8151846aca5;nsid=199960936;c=0), blocks: 22, hasStaleStorage: false, processing time: 0 msecs
2018-09-19 23:20:47,700 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1560ms
No GCs detected
2018-09-20 00:49:03,204 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1513ms
No GCs detected
2018-09-20 03:22:02,907 INFO BlockStateChange: BLOCK* processReport: from storage DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5 node DatanodeRegistration(172.18.0.2:50010, datanodeUuid=47ecd31e-43cd-4989-84ba-314b1664d0de, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-747ab8c6-1ec4-46a0-9dee-c8151846aca5;nsid=199960936;c=0), blocks: 22, hasStaleStorage: false, processing time: 1 msecs
2018-09-20 03:27:14,356 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1386ms
No GCs detected
2018-09-20 03:27:57,165 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1144ms
No GCs detected
2018-09-20 04:40:08,542 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1502ms
No GCs detected
2018-09-20 08:31:02,582 WARN org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 53160ms
No GCs detected
2018-09-20 10:31:05,223 WARN org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 48184ms
No GCs detected
2018-09-20 10:31:50,625 WARN org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 29015ms
No GCs detected
2018-09-20 13:45:50,403 WARN org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 28738ms
No GCs detected
2018-09-20 13:46:46,962 WARN org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 34424ms
No GCs detected
2018-09-20 13:47:16,565 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1024ms
No GCs detected
2018-09-20 13:47:29,108 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1392ms
No GCs detected
2018-09-20 14:56:34,603 WARN org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 27163ms
No GCs detected
2018-09-20 15:10:06,395 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 3388ms
No GCs detected
2018-09-20 16:39:50,275 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1393ms
No GCs detected
2018-09-20 17:00:08,585 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1206ms
No GCs detected
2018-09-20 17:36:17,691 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1294ms
No GCs detected
2018-09-20 18:00:39,111 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1575ms
No GCs detected
2018-09-20 18:01:37,052 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1196ms
No GCs detected
2018-09-20 19:06:56,423 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1318ms
No GCs detected
2018-09-20 21:36:02,792 INFO BlockStateChange: BLOCK* processReport: from storage DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5 node DatanodeRegistration(172.18.0.2:50010, datanodeUuid=47ecd31e-43cd-4989-84ba-314b1664d0de, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-747ab8c6-1ec4-46a0-9dee-c8151846aca5;nsid=199960936;c=0), blocks: 22, hasStaleStorage: false, processing time: 19 msecs
2018-09-20 21:45:20,091 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1480ms
No GCs detected
2018-09-20 21:52:33,928 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1489ms
No GCs detected
2018-09-20 23:40:21,913 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1231ms
No GCs detected
2018-09-21 01:25:13,317 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1267ms
No GCs detected
2018-09-21 03:07:41,625 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1186ms
No GCs detected
2018-09-21 03:39:59,303 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1448ms
No GCs detected
2018-09-21 05:39:48,815 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1164ms
No GCs detected
2018-09-21 06:09:40,009 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1473ms
No GCs detected
2018-09-21 06:50:55,016 WARN org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 40912ms
No GCs detected
2018-09-21 06:51:32,968 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1222ms
No GCs detected
2018-09-21 06:52:06,678 WARN org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 22655ms
No GCs detected
2018-09-21 07:27:49,947 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1534ms
No GCs detected
2018-09-21 08:03:25,266 WARN org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 20060ms
No GCs detected
2018-09-21 08:04:04,189 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1445ms
No GCs detected
2018-09-21 08:19:51,081 WARN org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 15069ms
No GCs detected
2018-09-21 08:40:34,071 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 2642ms
No GCs detected
2018-09-21 08:41:03,433 WARN org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 19322ms
No GCs detected
2018-09-21 09:16:54,975 WARN org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 11434ms
No GCs detected
2018-09-21 13:16:16,376 WARN org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 16644ms
No GCs detected
2018-09-21 13:34:31,333 WARN org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 19800ms
No GCs detected
2018-09-21 13:35:36,428 WARN org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 27493ms
No GCs detected
2018-09-21 16:01:08,602 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1497ms
No GCs detected
2018-09-21 16:16:07,612 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1345ms
No GCs detected
2018-09-21 16:17:33,334 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1361ms
No GCs detected
2018-09-21 17:31:51,103 INFO BlockStateChange: BLOCK* processReport: from storage DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5 node DatanodeRegistration(172.18.0.2:50010, datanodeUuid=47ecd31e-43cd-4989-84ba-314b1664d0de, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-747ab8c6-1ec4-46a0-9dee-c8151846aca5;nsid=199960936;c=0), blocks: 22, hasStaleStorage: false, processing time: 30 msecs
2018-09-21 21:00:29,517 WARN org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 45073ms
No GCs detected
2018-09-21 21:04:54,317 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1113ms
No GCs detected
2018-09-21 21:13:17,548 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1337ms
No GCs detected
2018-09-21 23:13:07,816 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1290ms
No GCs detected
2018-09-22 02:13:10,899 WARN org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 37467ms
No GCs detected
2018-09-22 04:12:57,272 WARN org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 29793ms
No GCs detected
2018-09-22 04:13:37,889 WARN org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 28529ms
No GCs detected
2018-09-22 06:13:25,635 WARN org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 27720ms
No GCs detected
2018-09-22 08:13:10,248 WARN org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 24612ms
No GCs detected
2018-09-23 02:17:10,243 WARN org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 25217ms
No GCs detected
2018-09-23 02:19:16,079 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1038ms
No GCs detected
2018-09-23 02:24:57,377 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1147ms
No GCs detected
2018-09-23 04:08:12,611 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 2689ms
No GCs detected
2018-09-23 04:10:09,320 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1133ms
No GCs detected
2018-09-23 06:04:11,634 INFO BlockStateChange: BLOCK* processReport: from storage DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5 node DatanodeRegistration(172.18.0.2:50010, datanodeUuid=47ecd31e-43cd-4989-84ba-314b1664d0de, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-747ab8c6-1ec4-46a0-9dee-c8151846aca5;nsid=199960936;c=0), blocks: 22, hasStaleStorage: false, processing time: 32 msecs
2018-09-23 06:09:06,824 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1442ms
No GCs detected
2018-09-23 06:39:31,549 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1194ms
No GCs detected
2018-09-23 06:45:40,154 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1341ms
No GCs detected
2018-09-23 08:27:37,769 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1058ms
No GCs detected
2018-09-23 08:43:58,518 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1126ms
No GCs detected
2018-09-23 10:24:29,713 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1005ms
No GCs detected
2018-09-23 11:21:23,677 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1243ms
No GCs detected
2018-09-23 14:20:55,870 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1186ms
No GCs detected
2018-09-23 15:20:39,122 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1041ms
No GCs detected
2018-09-23 19:56:47,712 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1233ms
No GCs detected
2018-09-23 20:10:06,534 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1239ms
No GCs detected
2018-09-24 01:09:56,753 WARN org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 45377ms
No GCs detected
2018-09-24 02:47:26,357 WARN org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 29671ms
No GCs detected
2018-09-24 04:32:18,139 INFO BlockStateChange: BLOCK* processReport: from storage DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5 node DatanodeRegistration(172.18.0.2:50010, datanodeUuid=47ecd31e-43cd-4989-84ba-314b1664d0de, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-747ab8c6-1ec4-46a0-9dee-c8151846aca5;nsid=199960936;c=0), blocks: 22, hasStaleStorage: false, processing time: 9 msecs
2018-09-24 10:31:53,597 INFO BlockStateChange: BLOCK* processReport: from storage DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5 node DatanodeRegistration(172.18.0.2:50010, datanodeUuid=47ecd31e-43cd-4989-84ba-314b1664d0de, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-747ab8c6-1ec4-46a0-9dee-c8151846aca5;nsid=199960936;c=0), blocks: 22, hasStaleStorage: false, processing time: 0 msecs
2018-09-24 13:32:39,128 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1263ms
No GCs detected
2018-09-24 13:52:54,655 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1345ms
No GCs detected
2018-09-24 16:53:23,928 INFO BlockStateChange: BLOCK* processReport: from storage DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5 node DatanodeRegistration(172.18.0.2:50010, datanodeUuid=47ecd31e-43cd-4989-84ba-314b1664d0de, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-747ab8c6-1ec4-46a0-9dee-c8151846aca5;nsid=199960936;c=0), blocks: 22, hasStaleStorage: false, processing time: 8 msecs
2018-09-24 20:19:19,370 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1246ms
No GCs detected
2018-09-24 23:07:07,595 INFO BlockStateChange: BLOCK* processReport: from storage DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5 node DatanodeRegistration(172.18.0.2:50010, datanodeUuid=47ecd31e-43cd-4989-84ba-314b1664d0de, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-747ab8c6-1ec4-46a0-9dee-c8151846aca5;nsid=199960936;c=0), blocks: 22, hasStaleStorage: false, processing time: 0 msecs
2018-09-25 01:17:41,899 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1150ms
No GCs detected
2018-09-25 04:51:51,054 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1399ms
No GCs detected
2018-09-25 05:12:17,431 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1415ms
No GCs detected
2018-09-25 05:33:11,525 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1523ms
No GCs detected
2018-09-25 06:54:07,898 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1009ms
No GCs detected
2018-09-25 07:59:27,380 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1303ms
No GCs detected
2018-09-25 08:55:18,377 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1393ms
No GCs detected
2018-09-25 09:48:59,053 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1108ms
No GCs detected
2018-09-25 11:50:30,065 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1118ms
No GCs detected
2018-09-25 12:54:15,024 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1348ms
No GCs detected
2018-09-25 13:42:16,708 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1294ms
No GCs detected
2018-09-25 13:47:02,480 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1253ms
No GCs detected
2018-09-25 14:41:14,165 INFO BlockStateChange: BLOCK* processReport: from storage DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5 node DatanodeRegistration(172.18.0.2:50010, datanodeUuid=47ecd31e-43cd-4989-84ba-314b1664d0de, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-747ab8c6-1ec4-46a0-9dee-c8151846aca5;nsid=199960936;c=0), blocks: 22, hasStaleStorage: false, processing time: 3 msecs
2018-09-25 18:58:52,926 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1509ms
No GCs detected
2018-09-25 21:13:51,192 INFO BlockStateChange: BLOCK* processReport: from storage DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5 node DatanodeRegistration(172.18.0.2:50010, datanodeUuid=47ecd31e-43cd-4989-84ba-314b1664d0de, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-747ab8c6-1ec4-46a0-9dee-c8151846aca5;nsid=199960936;c=0), blocks: 22, hasStaleStorage: false, processing time: 3 msecs
2018-09-25 23:00:49,316 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1278ms
No GCs detected
2018-09-25 23:02:35,188 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1084ms
No GCs detected
2018-09-25 23:57:07,067 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1302ms
No GCs detected
2018-09-26 00:20:38,117 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1076ms
No GCs detected
2018-09-26 00:32:05,307 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1264ms
No GCs detected
2018-09-26 00:38:15,181 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1124ms
No GCs detected
2018-09-26 00:44:24,066 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1035ms
No GCs detected
2018-09-26 02:59:32,296 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1201ms
No GCs detected
2018-09-26 03:29:31,293 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1225ms
No GCs detected
2018-09-26 03:37:22,946 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1381ms
No GCs detected
2018-09-26 04:44:52,256 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1051ms
No GCs detected
2018-09-26 05:38:42,207 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1343ms
No GCs detected
2018-09-26 06:32:22,155 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1325ms
No GCs detected
2018-09-26 07:06:53,876 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1128ms
No GCs detected
2018-09-26 07:52:21,113 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1282ms
No GCs detected
2018-09-26 08:46:17,000 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1064ms
No GCs detected
2018-09-26 09:39:43,729 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1018ms
No GCs detected
2018-09-26 09:45:04,746 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1348ms
No GCs detected
2018-09-26 10:38:45,178 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1370ms
No GCs detected
2018-09-26 10:44:07,230 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1422ms
No GCs detected
2018-09-26 12:31:27,792 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1108ms
No GCs detected
2018-09-26 13:25:08,227 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1057ms
No GCs detected
2018-09-26 13:47:49,385 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1140ms
No GCs detected
2018-09-26 14:06:38,242 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1067ms
No GCs detected
2018-09-26 14:23:44,870 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1080ms
No GCs detected
2018-09-26 15:39:14,553 INFO BlockStateChange: BLOCK* processReport: from storage DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5 node DatanodeRegistration(172.18.0.2:50010, datanodeUuid=47ecd31e-43cd-4989-84ba-314b1664d0de, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-747ab8c6-1ec4-46a0-9dee-c8151846aca5;nsid=199960936;c=0), blocks: 22, hasStaleStorage: false, processing time: 10 msecs
2018-09-26 16:39:10,823 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1228ms
No GCs detected
2018-09-26 16:57:11,532 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1439ms
No GCs detected
2018-09-26 21:15:29,377 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1307ms
No GCs detected
2018-09-26 23:15:22,225 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1131ms
No GCs detected
2018-09-27 02:15:09,555 WARN org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 44372ms
No GCs detected
2018-09-27 04:14:50,990 WARN org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 28672ms
No GCs detected
2018-09-27 06:14:32,232 WARN org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 28298ms
No GCs detected
2018-09-27 08:14:18,103 WARN org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 27616ms
No GCs detected
2018-09-27 09:15:58,070 WARN org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 26002ms
No GCs detected
2018-09-27 13:33:53,016 WARN org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 23600ms
No GCs detected
2018-09-27 14:14:50,952 INFO BlockStateChange: BLOCK* processReport: from storage DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5 node DatanodeRegistration(172.18.0.2:50010, datanodeUuid=47ecd31e-43cd-4989-84ba-314b1664d0de, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-747ab8c6-1ec4-46a0-9dee-c8151846aca5;nsid=199960936;c=0), blocks: 22, hasStaleStorage: false, processing time: 7 msecs
2018-09-27 20:14:23,826 INFO BlockStateChange: BLOCK* processReport: from storage DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5 node DatanodeRegistration(172.18.0.2:50010, datanodeUuid=47ecd31e-43cd-4989-84ba-314b1664d0de, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-747ab8c6-1ec4-46a0-9dee-c8151846aca5;nsid=199960936;c=0), blocks: 22, hasStaleStorage: false, processing time: 1 msecs
2018-09-27 22:08:41,900 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1067ms
GC pool 'PS Scavenge' had collection(s): count=1 time=1350ms
2018-09-28 00:22:13,086 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1518ms
No GCs detected
2018-09-28 03:36:39,239 INFO BlockStateChange: BLOCK* processReport: from storage DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5 node DatanodeRegistration(172.18.0.2:50010, datanodeUuid=47ecd31e-43cd-4989-84ba-314b1664d0de, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-747ab8c6-1ec4-46a0-9dee-c8151846aca5;nsid=199960936;c=0), blocks: 22, hasStaleStorage: false, processing time: 6 msecs
2018-09-28 04:48:25,156 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1403ms
No GCs detected
2018-09-28 04:55:08,323 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1021ms
No GCs detected
2018-09-28 07:25:09,388 WARN org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 59703ms
No GCs detected
2018-09-28 09:24:52,907 WARN org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 38097ms
No GCs detected
2018-09-28 11:24:41,553 WARN org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 28902ms
No GCs detected
2018-09-28 11:25:33,069 WARN org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 28882ms
No GCs detected
2018-09-28 12:35:18,162 WARN org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 41026ms
No GCs detected
2018-09-28 12:43:27,978 WARN org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 36349ms
No GCs detected
2018-09-28 12:44:29,160 WARN org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 26973ms
No GCs detected
2018-09-28 14:05:13,031 WARN org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 29637ms
No GCs detected
2018-09-28 16:46:21,648 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1472ms
No GCs detected
2018-09-28 19:42:46,974 WARN org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 22022ms
No GCs detected
2018-09-28 19:53:28,154 INFO BlockStateChange: BLOCK* processReport: from storage DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5 node DatanodeRegistration(172.18.0.2:50010, datanodeUuid=47ecd31e-43cd-4989-84ba-314b1664d0de, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-747ab8c6-1ec4-46a0-9dee-c8151846aca5;nsid=199960936;c=0), blocks: 22, hasStaleStorage: false, processing time: 21 msecs
2018-09-28 21:03:23,008 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1409ms
No GCs detected
2018-09-28 21:07:52,743 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1335ms
No GCs detected
2018-09-28 21:50:01,394 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1222ms
No GCs detected
2018-09-28 22:09:43,423 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1344ms
No GCs detected
2018-09-29 00:09:24,203 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1639ms
No GCs detected
2018-09-29 02:18:31,877 WARN org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 53387ms
No GCs detected
2018-09-29 04:00:15,300 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1307ms
No GCs detected
2018-09-29 04:20:39,001 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1472ms
No GCs detected
2018-09-29 04:33:18,666 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1143ms
No GCs detected
2018-09-29 04:54:10,428 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1231ms
No GCs detected
2018-09-29 05:04:40,355 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1169ms
No GCs detected
2018-09-29 05:34:32,285 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1127ms
No GCs detected
2018-09-29 06:26:25,198 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1194ms
No GCs detected
2018-09-29 07:25:37,301 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 2347ms
No GCs detected
2018-09-29 07:33:24,178 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1112ms
No GCs detected
2018-09-29 07:54:46,429 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1010ms
No GCs detected
2018-09-29 08:22:01,210 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1389ms
No GCs detected
2018-09-29 09:23:02,160 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1153ms
No GCs detected
2018-09-29 10:29:26,160 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1326ms
No GCs detected
2018-09-29 11:22:17,404 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1377ms
No GCs detected
2018-09-29 13:26:29,059 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1249ms
No GCs detected
2018-09-29 14:07:53,179 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1234ms
No GCs detected
2018-09-29 15:23:54,078 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1093ms
No GCs detected
2018-09-29 16:24:28,029 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1018ms
No GCs detected
2018-09-29 17:27:28,068 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1156ms
No GCs detected
2018-09-29 17:41:53,502 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1022ms
No GCs detected
2018-09-29 17:54:37,006 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1063ms
No GCs detected
2018-09-29 18:06:56,087 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1209ms
No GCs detected
2018-09-29 18:17:52,728 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1257ms
No GCs detected
2018-09-29 18:25:55,028 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1153ms
No GCs detected
2018-09-29 18:32:49,203 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1274ms
No GCs detected
2018-09-29 18:46:14,104 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1213ms
No GCs detected
2018-09-29 18:53:15,052 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1183ms
No GCs detected
2018-09-29 19:07:04,005 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1059ms
No GCs detected
2018-09-29 19:20:08,021 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1092ms
No GCs detected
2018-09-29 19:27:50,160 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1346ms
No GCs detected
2018-09-29 19:34:09,939 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1126ms
No GCs detected
2018-09-29 19:46:28,986 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1106ms
No GCs detected
2018-09-29 21:49:24,010 INFO BlockStateChange: BLOCK* processReport: from storage DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5 node DatanodeRegistration(172.18.0.2:50010, datanodeUuid=47ecd31e-43cd-4989-84ba-314b1664d0de, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-747ab8c6-1ec4-46a0-9dee-c8151846aca5;nsid=199960936;c=0), blocks: 22, hasStaleStorage: false, processing time: 6 msecs
2018-09-30 03:48:57,664 INFO BlockStateChange: BLOCK* processReport: from storage DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5 node DatanodeRegistration(172.18.0.2:50010, datanodeUuid=47ecd31e-43cd-4989-84ba-314b1664d0de, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-747ab8c6-1ec4-46a0-9dee-c8151846aca5;nsid=199960936;c=0), blocks: 22, hasStaleStorage: false, processing time: 3 msecs
2018-09-30 04:59:07,304 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1010ms
No GCs detected
2018-09-30 06:09:53,726 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1029ms
No GCs detected
2018-09-30 06:21:15,633 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1474ms
No GCs detected
2018-09-30 06:41:56,098 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1357ms
No GCs detected
2018-09-30 07:02:35,464 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1105ms
No GCs detected
2018-09-30 07:23:13,490 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1239ms
No GCs detected
2018-09-30 07:43:52,679 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1311ms
No GCs detected
2018-09-30 08:04:31,488 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1125ms
No GCs detected
2018-09-30 08:25:09,386 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1467ms
No GCs detected
2018-09-30 09:18:33,590 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1315ms
No GCs detected
2018-09-30 11:21:05,071 WARN org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 41727ms
No GCs detected
2018-09-30 11:21:48,854 WARN org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 30980ms
No GCs detected
2018-09-30 15:20:29,703 WARN org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 28895ms
No GCs detected
2018-09-30 15:21:38,637 WARN org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 25617ms
No GCs detected
2018-09-30 15:34:17,488 WARN org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 24208ms
No GCs detected
2018-09-30 15:35:35,608 WARN org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 24156ms
No GCs detected
2018-09-30 15:49:24,654 WARN org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 29339ms
No GCs detected
2018-09-30 16:02:31,798 WARN org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 28130ms
No GCs detected
2018-09-30 16:03:10,663 WARN org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 27537ms
No GCs detected
2018-09-30 16:28:44,624 WARN org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 26249ms
No GCs detected
2018-09-30 16:29:23,486 WARN org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 26147ms
No GCs detected
2018-09-30 16:54:58,773 WARN org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 24824ms
No GCs detected
2018-09-30 17:08:05,816 WARN org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 25984ms
No GCs detected
2018-09-30 17:08:44,972 WARN org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 26583ms
No GCs detected
2018-09-30 17:21:48,706 WARN org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 24872ms
No GCs detected
2018-09-30 17:34:58,052 WARN org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 27363ms
No GCs detected
2018-09-30 18:00:33,628 WARN org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 25066ms
No GCs detected
2018-09-30 18:21:42,746 WARN org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 32294ms
No GCs detected
2018-09-30 20:03:42,157 WARN org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 31144ms
No GCs detected
2018-09-30 23:14:30,311 INFO BlockStateChange: BLOCK* processReport: from storage DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5 node DatanodeRegistration(172.18.0.2:50010, datanodeUuid=47ecd31e-43cd-4989-84ba-314b1664d0de, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-747ab8c6-1ec4-46a0-9dee-c8151846aca5;nsid=199960936;c=0), blocks: 22, hasStaleStorage: false, processing time: 17 msecs
2018-10-01 04:12:19,360 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1328ms
No GCs detected
2018-10-01 05:51:14,765 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1109ms
No GCs detected
2018-10-01 08:31:10,407 WARN org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 54502ms
No GCs detected
2018-10-01 10:30:56,638 WARN org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 27817ms
No GCs detected
2018-10-01 12:17:01,031 WARN org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 18781ms
No GCs detected
2018-10-01 12:20:14,557 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1496ms
No GCs detected
2018-10-01 13:18:13,099 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1089ms
No GCs detected
2018-10-01 13:30:51,340 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1018ms
No GCs detected
2018-10-01 15:21:05,585 WARN org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 20131ms
No GCs detected
2018-10-01 17:20:16,973 WARN org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 16741ms
No GCs detected
2018-10-01 19:20:06,192 WARN org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 21244ms
No GCs detected
2018-10-01 21:56:21,558 WARN org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 18452ms
No GCs detected
2018-10-01 22:49:10,187 INFO BlockStateChange: BLOCK* processReport: from storage DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5 node DatanodeRegistration(172.18.0.2:50010, datanodeUuid=47ecd31e-43cd-4989-84ba-314b1664d0de, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-747ab8c6-1ec4-46a0-9dee-c8151846aca5;nsid=199960936;c=0), blocks: 22, hasStaleStorage: false, processing time: 3 msecs
2018-10-02 00:28:03,491 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1390ms
No GCs detected
2018-10-02 03:21:40,010 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1209ms
No GCs detected
2018-10-02 04:04:33,326 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1239ms
No GCs detected
2018-10-02 05:18:43,761 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1173ms
No GCs detected
2018-10-02 05:49:45,578 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1023ms
No GCs detected
2018-10-02 06:22:35,773 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1247ms
No GCs detected
2018-10-02 07:01:26,221 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1196ms
No GCs detected
2018-10-02 08:03:02,848 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1076ms
No GCs detected
2018-10-02 08:14:06,531 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1012ms
No GCs detected
2018-10-02 10:00:17,522 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1022ms
No GCs detected
2018-10-02 11:06:05,700 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1046ms
No GCs detected
2018-10-02 14:02:35,623 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1088ms
No GCs detected
2018-10-02 16:29:19,366 INFO BlockStateChange: BLOCK* processReport: from storage DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5 node DatanodeRegistration(172.18.0.2:50010, datanodeUuid=47ecd31e-43cd-4989-84ba-314b1664d0de, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-747ab8c6-1ec4-46a0-9dee-c8151846aca5;nsid=199960936;c=0), blocks: 22, hasStaleStorage: false, processing time: 0 msecs
2018-10-02 22:28:53,335 INFO BlockStateChange: BLOCK* processReport: from storage DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5 node DatanodeRegistration(172.18.0.2:50010, datanodeUuid=47ecd31e-43cd-4989-84ba-314b1664d0de, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-747ab8c6-1ec4-46a0-9dee-c8151846aca5;nsid=199960936;c=0), blocks: 22, hasStaleStorage: false, processing time: 0 msecs
2018-10-03 04:28:27,987 INFO BlockStateChange: BLOCK* processReport: from storage DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5 node DatanodeRegistration(172.18.0.2:50010, datanodeUuid=47ecd31e-43cd-4989-84ba-314b1664d0de, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-747ab8c6-1ec4-46a0-9dee-c8151846aca5;nsid=199960936;c=0), blocks: 22, hasStaleStorage: false, processing time: 0 msecs
2018-10-03 04:53:20,898 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1355ms
No GCs detected
2018-10-03 06:06:22,054 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1190ms
No GCs detected
2018-10-03 07:07:58,487 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1306ms
No GCs detected
2018-10-03 08:02:43,249 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1108ms
No GCs detected
2018-10-03 08:56:25,299 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1149ms
No GCs detected
2018-10-03 10:00:06,238 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1333ms
No GCs detected
2018-10-03 11:04:48,407 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1183ms
No GCs detected
2018-10-03 12:02:53,227 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1050ms
No GCs detected
2018-10-03 14:01:01,879 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1232ms
No GCs detected
2018-10-03 15:08:39,247 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1140ms
No GCs detected
2018-10-03 15:51:48,763 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1061ms
No GCs detected
2018-10-03 17:51:49,570 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1461ms
No GCs detected
2018-10-03 20:51:34,077 WARN org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 43624ms
No GCs detected
2018-10-03 20:52:15,427 WARN org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 27209ms
No GCs detected
2018-10-03 22:51:43,117 WARN org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 19356ms
No GCs detected
2018-10-04 01:58:58,020 WARN org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 21545ms
No GCs detected
2018-10-04 04:42:47,276 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1287ms
No GCs detected
2018-10-04 05:19:19,096 WARN org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 44182ms
No GCs detected
2018-10-04 05:20:35,724 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1329ms
No GCs detected
2018-10-04 05:21:08,704 WARN org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 20826ms
No GCs detected
2018-10-04 09:34:12,915 WARN org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 27123ms
No GCs detected
2018-10-04 11:33:47,613 WARN org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 22680ms
No GCs detected
2018-10-04 13:33:23,506 WARN org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 19119ms
No GCs detected
2018-10-04 15:32:58,736 WARN org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 22729ms
No GCs detected
2018-10-04 17:21:00,701 WARN org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 22747ms
No GCs detected
2018-10-04 22:25:23,009 WARN org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 26962ms
No GCs detected
2018-10-04 22:38:54,730 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1284ms
No GCs detected
2018-10-04 23:00:27,424 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1150ms
No GCs detected
2018-10-04 23:09:09,409 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1665ms
No GCs detected
2018-10-04 23:15:01,322 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 2281ms
No GCs detected
2018-10-04 23:27:25,047 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1056ms
No GCs detected
2018-10-05 00:04:53,026 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1196ms
No GCs detected
2018-10-05 00:52:37,564 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 2492ms
No GCs detected
2018-10-05 01:24:42,707 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1052ms
No GCs detected
2018-10-05 02:02:48,027 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1165ms
No GCs detected
2018-10-05 02:39:58,037 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1082ms
No GCs detected
2018-10-05 03:27:20,926 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1135ms
No GCs detected
2018-10-05 05:01:14,974 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1130ms
No GCs detected
2018-10-05 05:21:36,966 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1163ms
No GCs detected
2018-10-05 05:31:44,073 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1101ms
No GCs detected
2018-10-05 07:33:56,546 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1290ms
No GCs detected
2018-10-05 08:27:34,241 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1277ms
No GCs detected
2018-10-05 09:32:16,825 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1017ms
No GCs detected
2018-10-05 10:34:24,118 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1197ms
No GCs detected
2018-10-05 11:35:43,067 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1125ms
No GCs detected
2018-10-05 13:35:41,014 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1118ms
No GCs detected
2018-10-05 13:55:45,088 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1166ms
No GCs detected
2018-10-05 13:55:56,753 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1111ms
No GCs detected
2018-10-05 18:54:29,377 WARN org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 40071ms
No GCs detected
2018-10-05 20:54:04,566 WARN org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 28833ms
No GCs detected
2018-10-05 20:54:50,710 WARN org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 30342ms
No GCs detected
2018-10-05 22:54:25,472 WARN org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 25765ms
No GCs detected
2018-10-06 01:56:01,677 WARN org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 22988ms
No GCs detected
2018-10-06 01:56:37,222 WARN org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 21476ms
No GCs detected
2018-10-06 20:49:19,207 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1300ms
No GCs detected
2018-10-06 21:02:00,292 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1200ms
No GCs detected
2018-10-06 21:44:18,604 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1163ms
No GCs detected
2018-10-06 22:04:57,315 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1003ms
No GCs detected
2018-10-06 22:32:13,562 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1259ms
No GCs detected
2018-10-07 00:31:57,504 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1296ms
No GCs detected
2018-10-07 02:15:54,823 WARN org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 37938ms
No GCs detected
2018-10-07 02:57:58,017 WARN org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 30368ms
No GCs detected
2018-10-07 03:52:49,170 INFO BlockStateChange: BLOCK* processReport: from storage DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5 node DatanodeRegistration(172.18.0.2:50010, datanodeUuid=47ecd31e-43cd-4989-84ba-314b1664d0de, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-747ab8c6-1ec4-46a0-9dee-c8151846aca5;nsid=199960936;c=0), blocks: 22, hasStaleStorage: false, processing time: 8 msecs
2018-10-07 09:52:23,825 INFO BlockStateChange: BLOCK* processReport: from storage DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5 node DatanodeRegistration(172.18.0.2:50010, datanodeUuid=47ecd31e-43cd-4989-84ba-314b1664d0de, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-747ab8c6-1ec4-46a0-9dee-c8151846aca5;nsid=199960936;c=0), blocks: 22, hasStaleStorage: false, processing time: 0 msecs
2018-10-07 15:51:56,511 INFO BlockStateChange: BLOCK* processReport: from storage DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5 node DatanodeRegistration(172.18.0.2:50010, datanodeUuid=47ecd31e-43cd-4989-84ba-314b1664d0de, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-747ab8c6-1ec4-46a0-9dee-c8151846aca5;nsid=199960936;c=0), blocks: 22, hasStaleStorage: false, processing time: 0 msecs
2018-10-07 18:52:53,061 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1050ms
No GCs detected
2018-10-07 19:23:04,116 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1340ms
No GCs detected
2018-10-07 19:37:56,484 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1309ms
No GCs detected
2018-10-07 20:48:39,208 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1102ms
No GCs detected
2018-10-07 22:05:05,199 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1153ms
No GCs detected
2018-10-07 22:54:44,826 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1321ms
No GCs detected
2018-10-07 23:01:26,627 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 2492ms
No GCs detected
2018-10-08 00:02:05,529 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1271ms
No GCs detected
2018-10-08 01:09:01,450 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1146ms
No GCs detected
2018-10-08 02:09:03,571 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1332ms
No GCs detected
2018-10-08 02:59:37,526 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1427ms
No GCs detected
2018-10-08 05:25:33,659 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1336ms
No GCs detected
2018-10-08 08:16:37,094 WARN org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 44770ms
No GCs detected
2018-10-08 08:17:13,178 WARN org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 24521ms
No GCs detected
2018-10-08 10:16:47,606 WARN org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 20418ms
No GCs detected
2018-10-08 13:28:36,492 WARN org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 22777ms
No GCs detected
2018-10-08 13:59:10,259 INFO BlockStateChange: BLOCK* processReport: from storage DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5 node DatanodeRegistration(172.18.0.2:50010, datanodeUuid=47ecd31e-43cd-4989-84ba-314b1664d0de, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-747ab8c6-1ec4-46a0-9dee-c8151846aca5;nsid=199960936;c=0), blocks: 22, hasStaleStorage: false, processing time: 3 msecs
2018-10-08 14:57:53,174 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1356ms
No GCs detected
2018-10-08 15:53:57,654 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1417ms
No GCs detected
2018-10-08 15:56:17,354 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1202ms
No GCs detected
2018-10-08 16:03:20,827 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 2700ms
No GCs detected
2018-10-08 16:19:47,114 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 2056ms
No GCs detected
2018-10-08 17:13:12,950 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1213ms
No GCs detected
2018-10-08 18:03:48,005 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1190ms
No GCs detected
2018-10-08 18:06:13,522 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1068ms
No GCs detected
2018-10-08 18:59:31,598 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1232ms
No GCs detected
2018-10-08 20:03:40,000 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1168ms
No GCs detected
2018-10-08 20:05:26,068 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1329ms
No GCs detected
2018-10-08 20:29:38,195 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1268ms
No GCs detected
2018-10-08 20:36:14,894 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1319ms
No GCs detected
2018-10-08 21:01:59,142 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1531ms
No GCs detected
2018-10-08 21:02:48,551 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1105ms
No GCs detected
2018-10-08 21:04:15,993 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1058ms
No GCs detected
2018-10-08 22:24:29,966 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1359ms
No GCs detected
2018-10-08 22:45:07,918 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1072ms
No GCs detected
2018-10-08 22:51:34,959 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1106ms
No GCs detected
2018-10-08 23:38:52,592 INFO BlockStateChange: BLOCK* processReport: from storage DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5 node DatanodeRegistration(172.18.0.2:50010, datanodeUuid=47ecd31e-43cd-4989-84ba-314b1664d0de, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-747ab8c6-1ec4-46a0-9dee-c8151846aca5;nsid=199960936;c=0), blocks: 22, hasStaleStorage: false, processing time: 1 msecs
2018-10-08 23:42:09,593 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1393ms
No GCs detected
2018-10-08 23:47:03,713 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1055ms
No GCs detected
2018-10-09 01:42:13,460 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1492ms
No GCs detected
2018-10-09 02:12:24,769 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1205ms
No GCs detected
2018-10-09 02:19:23,200 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1186ms
No GCs detected
2018-10-09 02:20:18,946 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1017ms
No GCs detected
2018-10-09 02:21:15,909 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1004ms
No GCs detected
2018-10-09 03:18:57,044 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1996ms
No GCs detected
2018-10-09 03:32:04,007 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1152ms
No GCs detected
2018-10-09 04:15:19,973 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1143ms
No GCs detected
2018-10-09 04:41:44,114 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1029ms
No GCs detected
2018-10-09 04:42:40,975 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1309ms
No GCs detected
2018-10-09 04:45:00,899 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1032ms
No GCs detected
2018-10-09 05:00:19,232 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1301ms
No GCs detected
2018-10-09 05:47:27,041 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1002ms
No GCs detected
2018-10-09 05:58:02,936 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1061ms
No GCs detected
2018-10-09 07:01:12,027 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1037ms
No GCs detected
2018-10-09 07:09:09,931 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1033ms
No GCs detected
2018-10-09 08:18:54,971 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1127ms
No GCs detected
2018-10-09 09:01:05,971 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1053ms
No GCs detected
2018-10-09 09:29:56,858 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1010ms
No GCs detected
2018-10-09 10:18:01,058 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1160ms
No GCs detected
2018-10-09 10:39:18,075 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1118ms
No GCs detected
2018-10-09 10:41:22,095 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1291ms
No GCs detected
2018-10-09 10:42:45,004 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1147ms
No GCs detected
2018-10-09 10:43:40,999 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1058ms
No GCs detected
2018-10-09 11:08:40,099 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1241ms
No GCs detected
2018-10-09 11:51:06,018 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1104ms
No GCs detected
2018-10-09 11:53:22,968 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1119ms
No GCs detected
2018-10-09 11:54:23,007 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1016ms
No GCs detected
2018-10-09 11:58:09,947 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1075ms
No GCs detected
2018-10-09 13:03:42,979 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1052ms
No GCs detected
2018-10-09 13:04:40,000 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1089ms
No GCs detected
2018-10-09 13:05:35,950 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1061ms
No GCs detected
2018-10-09 13:07:06,944 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1098ms
No GCs detected
2018-10-09 13:08:02,894 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1011ms
No GCs detected
2018-10-09 13:09:29,695 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1325ms
No GCs detected
2018-10-09 14:14:45,987 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1106ms
No GCs detected
2018-10-09 14:16:54,033 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1207ms
No GCs detected
2018-10-09 14:19:39,041 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1246ms
No GCs detected
2018-10-09 14:20:39,909 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1068ms
No GCs detected
2018-10-09 14:22:04,902 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1075ms
No GCs detected
2018-10-09 15:12:48,043 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1221ms
No GCs detected
2018-10-09 15:26:52,019 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1116ms
No GCs detected
2018-10-09 15:27:48,954 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1157ms
No GCs detected
2018-10-09 15:33:20,962 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1125ms
No GCs detected
2018-10-09 18:03:31,703 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1344ms
No GCs detected
2018-10-09 19:38:31,061 INFO BlockStateChange: BLOCK* processReport: from storage DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5 node DatanodeRegistration(172.18.0.2:50010, datanodeUuid=47ecd31e-43cd-4989-84ba-314b1664d0de, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-747ab8c6-1ec4-46a0-9dee-c8151846aca5;nsid=199960936;c=0), blocks: 22, hasStaleStorage: false, processing time: 0 msecs
2018-10-09 20:54:42,223 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1235ms
No GCs detected
2018-10-09 21:00:42,823 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1395ms
No GCs detected
2018-10-18 02:20:26,311 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NameNode
STARTUP_MSG:   host = bootcamp.local/172.18.0.2
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.3
STARTUP_MSG:   classpath = /etc/hadoop/conf:/usr/lib/hadoop/lib/asm-3.2.jar:/usr/lib/hadoop/lib/jackson-jaxrs-1.9.13.jar:/usr/lib/hadoop/lib/api-asn1-api-1.0.0-M20.jar:/usr/lib/hadoop/lib/jersey-json-1.9.jar:/usr/lib/hadoop/lib/gson-2.2.4.jar:/usr/lib/hadoop/lib/commons-net-3.1.jar:/usr/lib/hadoop/lib/commons-digester-1.8.jar:/usr/lib/hadoop/lib/guava-11.0.2.jar:/usr/lib/hadoop/lib/api-util-1.0.0-M20.jar:/usr/lib/hadoop/lib/jets3t-0.9.0.jar:/usr/lib/hadoop/lib/snappy-java-1.0.4.1.jar:/usr/lib/hadoop/lib/commons-compress-1.4.1.jar:/usr/lib/hadoop/lib/activation-1.1.jar:/usr/lib/hadoop/lib/slf4j-log4j12-1.7.10.jar:/usr/lib/hadoop/lib/curator-framework-2.7.1.jar:/usr/lib/hadoop/lib/jackson-core-asl-1.9.13.jar:/usr/lib/hadoop/lib/commons-beanutils-1.7.0.jar:/usr/lib/hadoop/lib/curator-client-2.7.1.jar:/usr/lib/hadoop/lib/jsr305-3.0.0.jar:/usr/lib/hadoop/lib/avro-1.7.4.jar:/usr/lib/hadoop/lib/jackson-xc-1.9.13.jar:/usr/lib/hadoop/lib/commons-configuration-1.6.jar:/usr/lib/hadoop/lib/commons-math3-3.1.1.jar:/usr/lib/hadoop/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/lib/hadoop/lib/jaxb-api-2.2.2.jar:/usr/lib/hadoop/lib/netty-3.6.2.Final.jar:/usr/lib/hadoop/lib/curator-recipes-2.7.1.jar:/usr/lib/hadoop/lib/mockito-all-1.8.5.jar:/usr/lib/hadoop/lib/commons-codec-1.4.jar:/usr/lib/hadoop/lib/jettison-1.1.jar:/usr/lib/hadoop/lib/commons-httpclient-3.1.jar:/usr/lib/hadoop/lib/jsch-0.1.42.jar:/usr/lib/hadoop/lib/java-xmlbuilder-0.4.jar:/usr/lib/hadoop/lib/xz-1.0.jar:/usr/lib/hadoop/lib/commons-logging-1.1.3.jar:/usr/lib/hadoop/lib/log4j-1.2.17.jar:/usr/lib/hadoop/lib/zookeeper-3.4.6.jar:/usr/lib/hadoop/lib/commons-lang-2.6.jar:/usr/lib/hadoop/lib/hamcrest-core-1.3.jar:/usr/lib/hadoop/lib/httpclient-4.2.5.jar:/usr/lib/hadoop/lib/commons-cli-1.2.jar:/usr/lib/hadoop/lib/commons-io-2.4.jar:/usr/lib/hadoop/lib/apacheds-i18n-2.0.0-M15.jar:/usr/lib/hadoop/lib/jetty-util-6.1.26.jar:/usr/lib/hadoop/lib/jackson-mapper-asl-1.9.13.jar:/usr/lib/hadoop/lib/htrace-core-3.1.0-incubating.jar:/usr/lib/hadoop/lib/paranamer-2.3.jar:/usr/lib/hadoop/lib/xmlenc-0.52.jar:/usr/lib/hadoop/lib/jaxb-impl-2.2.3-1.jar:/usr/lib/hadoop/lib/commons-beanutils-core-1.8.0.jar:/usr/lib/hadoop/lib/jersey-server-1.9.jar:/usr/lib/hadoop/lib/slf4j-api-1.7.10.jar:/usr/lib/hadoop/lib/jsp-api-2.1.jar:/usr/lib/hadoop/lib/jetty-6.1.26.jar:/usr/lib/hadoop/lib/junit-4.11.jar:/usr/lib/hadoop/lib/servlet-api-2.5.jar:/usr/lib/hadoop/lib/httpcore-4.2.5.jar:/usr/lib/hadoop/lib/protobuf-java-2.5.0.jar:/usr/lib/hadoop/lib/jersey-core-1.9.jar:/usr/lib/hadoop/lib/stax-api-1.0-2.jar:/usr/lib/hadoop/lib/commons-collections-3.2.2.jar:/usr/lib/hadoop/.//hadoop-nfs.jar:/usr/lib/hadoop/.//hadoop-common.jar:/usr/lib/hadoop/.//hadoop-auth-2.7.3.jar:/usr/lib/hadoop/.//hadoop-common-2.7.3-tests.jar:/usr/lib/hadoop/.//hadoop-common-2.7.3.jar:/usr/lib/hadoop/.//hadoop-auth.jar:/usr/lib/hadoop/.//hadoop-annotations.jar:/usr/lib/hadoop/.//hadoop-annotations-2.7.3.jar:/usr/lib/hadoop/.//hadoop-nfs-2.7.3.jar:/usr/lib/hadoop-hdfs/./:/usr/lib/hadoop-hdfs/lib/asm-3.2.jar:/usr/lib/hadoop-hdfs/lib/xercesImpl-2.9.1.jar:/usr/lib/hadoop-hdfs/lib/guava-11.0.2.jar:/usr/lib/hadoop-hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/lib/hadoop-hdfs/lib/jsr305-3.0.0.jar:/usr/lib/hadoop-hdfs/lib/leveldbjni-all-1.8.jar:/usr/lib/hadoop-hdfs/lib/netty-3.6.2.Final.jar:/usr/lib/hadoop-hdfs/lib/netty-all-4.0.23.Final.jar:/usr/lib/hadoop-hdfs/lib/commons-codec-1.4.jar:/usr/lib/hadoop-hdfs/lib/xml-apis-1.3.04.jar:/usr/lib/hadoop-hdfs/lib/commons-logging-1.1.3.jar:/usr/lib/hadoop-hdfs/lib/log4j-1.2.17.jar:/usr/lib/hadoop-hdfs/lib/commons-lang-2.6.jar:/usr/lib/hadoop-hdfs/lib/commons-cli-1.2.jar:/usr/lib/hadoop-hdfs/lib/commons-io-2.4.jar:/usr/lib/hadoop-hdfs/lib/jetty-util-6.1.26.jar:/usr/lib/hadoop-hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/lib/hadoop-hdfs/lib/htrace-core-3.1.0-incubating.jar:/usr/lib/hadoop-hdfs/lib/xmlenc-0.52.jar:/usr/lib/hadoop-hdfs/lib/jersey-server-1.9.jar:/usr/lib/hadoop-hdfs/lib/jetty-6.1.26.jar:/usr/lib/hadoop-hdfs/lib/commons-daemon-1.0.13.jar:/usr/lib/hadoop-hdfs/lib/servlet-api-2.5.jar:/usr/lib/hadoop-hdfs/lib/protobuf-java-2.5.0.jar:/usr/lib/hadoop-hdfs/lib/jersey-core-1.9.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs-nfs.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs-2.7.3-tests.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs-nfs-2.7.3.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs-2.7.3.jar:/usr/lib/hadoop-yarn/lib/asm-3.2.jar:/usr/lib/hadoop-yarn/lib/jackson-jaxrs-1.9.13.jar:/usr/lib/hadoop-yarn/lib/jersey-json-1.9.jar:/usr/lib/hadoop-yarn/lib/jersey-client-1.9.jar:/usr/lib/hadoop-yarn/lib/guava-11.0.2.jar:/usr/lib/hadoop-yarn/lib/jersey-guice-1.9.jar:/usr/lib/hadoop-yarn/lib/commons-compress-1.4.1.jar:/usr/lib/hadoop-yarn/lib/activation-1.1.jar:/usr/lib/hadoop-yarn/lib/guice-servlet-3.0.jar:/usr/lib/hadoop-yarn/lib/zookeeper-3.4.6-tests.jar:/usr/lib/hadoop-yarn/lib/jackson-core-asl-1.9.13.jar:/usr/lib/hadoop-yarn/lib/jsr305-3.0.0.jar:/usr/lib/hadoop-yarn/lib/jackson-xc-1.9.13.jar:/usr/lib/hadoop-yarn/lib/leveldbjni-all-1.8.jar:/usr/lib/hadoop-yarn/lib/jaxb-api-2.2.2.jar:/usr/lib/hadoop-yarn/lib/netty-3.6.2.Final.jar:/usr/lib/hadoop-yarn/lib/javax.inject-1.jar:/usr/lib/hadoop-yarn/lib/commons-codec-1.4.jar:/usr/lib/hadoop-yarn/lib/jettison-1.1.jar:/usr/lib/hadoop-yarn/lib/guice-3.0.jar:/usr/lib/hadoop-yarn/lib/xz-1.0.jar:/usr/lib/hadoop-yarn/lib/commons-logging-1.1.3.jar:/usr/lib/hadoop-yarn/lib/log4j-1.2.17.jar:/usr/lib/hadoop-yarn/lib/zookeeper-3.4.6.jar:/usr/lib/hadoop-yarn/lib/commons-lang-2.6.jar:/usr/lib/hadoop-yarn/lib/commons-cli-1.2.jar:/usr/lib/hadoop-yarn/lib/commons-io-2.4.jar:/usr/lib/hadoop-yarn/lib/jetty-util-6.1.26.jar:/usr/lib/hadoop-yarn/lib/jackson-mapper-asl-1.9.13.jar:/usr/lib/hadoop-yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/lib/hadoop-yarn/lib/jersey-server-1.9.jar:/usr/lib/hadoop-yarn/lib/aopalliance-1.0.jar:/usr/lib/hadoop-yarn/lib/jetty-6.1.26.jar:/usr/lib/hadoop-yarn/lib/servlet-api-2.5.jar:/usr/lib/hadoop-yarn/lib/protobuf-java-2.5.0.jar:/usr/lib/hadoop-yarn/lib/jersey-core-1.9.jar:/usr/lib/hadoop-yarn/lib/stax-api-1.0-2.jar:/usr/lib/hadoop-yarn/lib/commons-collections-3.2.2.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-resourcemanager.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-resourcemanager-2.7.3.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-applicationhistoryservice-2.7.3.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-registry.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-tests.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-common.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-common-2.7.3.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-applications-distributedshell.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-client.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-common-2.7.3.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-applications-unmanaged-am-launcher.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-web-proxy.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-api.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-tests-2.7.3.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-nodemanager-2.7.3.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-api-2.7.3.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-sharedcachemanager-2.7.3.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-common.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-client-2.7.3.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-nodemanager.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-sharedcachemanager.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-registry-2.7.3.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-applications-unmanaged-am-launcher-2.7.3.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-web-proxy-2.7.3.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-applicationhistoryservice.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-applications-distributedshell-2.7.3.jar:/usr/lib/hadoop-mapreduce/lib/asm-3.2.jar:/usr/lib/hadoop-mapreduce/lib/jersey-guice-1.9.jar:/usr/lib/hadoop-mapreduce/lib/snappy-java-1.0.4.1.jar:/usr/lib/hadoop-mapreduce/lib/commons-compress-1.4.1.jar:/usr/lib/hadoop-mapreduce/lib/guice-servlet-3.0.jar:/usr/lib/hadoop-mapreduce/lib/jackson-core-asl-1.9.13.jar:/usr/lib/hadoop-mapreduce/lib/avro-1.7.4.jar:/usr/lib/hadoop-mapreduce/lib/leveldbjni-all-1.8.jar:/usr/lib/hadoop-mapreduce/lib/netty-3.6.2.Final.jar:/usr/lib/hadoop-mapreduce/lib/javax.inject-1.jar:/usr/lib/hadoop-mapreduce/lib/guice-3.0.jar:/usr/lib/hadoop-mapreduce/lib/xz-1.0.jar:/usr/lib/hadoop-mapreduce/lib/log4j-1.2.17.jar:/usr/lib/hadoop-mapreduce/lib/hamcrest-core-1.3.jar:/usr/lib/hadoop-mapreduce/lib/commons-io-2.4.jar:/usr/lib/hadoop-mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/usr/lib/hadoop-mapreduce/lib/paranamer-2.3.jar:/usr/lib/hadoop-mapreduce/lib/jersey-server-1.9.jar:/usr/lib/hadoop-mapreduce/lib/aopalliance-1.0.jar:/usr/lib/hadoop-mapreduce/lib/junit-4.11.jar:/usr/lib/hadoop-mapreduce/lib/protobuf-java-2.5.0.jar:/usr/lib/hadoop-mapreduce/lib/jersey-core-1.9.jar:/usr/lib/hadoop-mapreduce/.//jackson-core-2.2.3.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-jobclient-2.7.3-tests.jar:/usr/lib/hadoop-mapreduce/.//azure-storage-2.0.0.jar:/usr/lib/hadoop-mapreduce/.//metrics-core-3.0.1.jar:/usr/lib/hadoop-mapreduce/.//asm-3.2.jar:/usr/lib/hadoop-mapreduce/.//jackson-jaxrs-1.9.13.jar:/usr/lib/hadoop-mapreduce/.//hadoop-sls-2.7.3.jar:/usr/lib/hadoop-mapreduce/.//api-asn1-api-1.0.0-M20.jar:/usr/lib/hadoop-mapreduce/.//jersey-json-1.9.jar:/usr/lib/hadoop-mapreduce/.//gson-2.2.4.jar:/usr/lib/hadoop-mapreduce/.//commons-net-3.1.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-app-2.7.3.jar:/usr/lib/hadoop-mapreduce/.//commons-digester-1.8.jar:/usr/lib/hadoop-mapreduce/.//guava-11.0.2.jar:/usr/lib/hadoop-mapreduce/.//api-util-1.0.0-M20.jar:/usr/lib/hadoop-mapreduce/.//jets3t-0.9.0.jar:/usr/lib/hadoop-mapreduce/.//snappy-java-1.0.4.1.jar:/usr/lib/hadoop-mapreduce/.//hadoop-streaming-2.7.3.jar:/usr/lib/hadoop-mapreduce/.//commons-compress-1.4.1.jar:/usr/lib/hadoop-mapreduce/.//activation-1.1.jar:/usr/lib/hadoop-mapreduce/.//curator-framework-2.7.1.jar:/usr/lib/hadoop-mapreduce/.//hadoop-archives.jar:/usr/lib/hadoop-mapreduce/.//hadoop-aws.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-core.jar:/usr/lib/hadoop-mapreduce/.//jackson-core-asl-1.9.13.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-hs.jar:/usr/lib/hadoop-mapreduce/.//commons-beanutils-1.7.0.jar:/usr/lib/hadoop-mapreduce/.//curator-client-2.7.1.jar:/usr/lib/hadoop-mapreduce/.//hadoop-azure-2.7.3.jar:/usr/lib/hadoop-mapreduce/.//jsr305-3.0.0.jar:/usr/lib/hadoop-mapreduce/.//avro-1.7.4.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-jobclient.jar:/usr/lib/hadoop-mapreduce/.//hadoop-gridmix.jar:/usr/lib/hadoop-mapreduce/.//hadoop-distcp.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-app.jar:/usr/lib/hadoop-mapreduce/.//jackson-xc-1.9.13.jar:/usr/lib/hadoop-mapreduce/.//hadoop-auth-2.7.3.jar:/usr/lib/hadoop-mapreduce/.//commons-configuration-1.6.jar:/usr/lib/hadoop-mapreduce/.//commons-math3-3.1.1.jar:/usr/lib/hadoop-mapreduce/.//hadoop-datajoin-2.7.3.jar:/usr/lib/hadoop-mapreduce/.//apacheds-kerberos-codec-2.0.0-M15.jar:/usr/lib/hadoop-mapreduce/.//hadoop-gridmix-2.7.3.jar:/usr/lib/hadoop-mapreduce/.//hadoop-ant.jar:/usr/lib/hadoop-mapreduce/.//hadoop-auth.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-shuffle-2.7.3.jar:/usr/lib/hadoop-mapreduce/.//jaxb-api-2.2.2.jar:/usr/lib/hadoop-mapreduce/.//netty-3.6.2.Final.jar:/usr/lib/hadoop-mapreduce/.//curator-recipes-2.7.1.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-hs-plugins.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-common-2.7.3.jar:/usr/lib/hadoop-mapreduce/.//mockito-all-1.8.5.jar:/usr/lib/hadoop-mapreduce/.//joda-time-2.9.9.jar:/usr/lib/hadoop-mapreduce/.//hadoop-openstack.jar:/usr/lib/hadoop-mapreduce/.//jackson-annotations-2.2.3.jar:/usr/lib/hadoop-mapreduce/.//commons-codec-1.4.jar:/usr/lib/hadoop-mapreduce/.//hadoop-extras-2.7.3.jar:/usr/lib/hadoop-mapreduce/.//jettison-1.1.jar:/usr/lib/hadoop-mapreduce/.//hadoop-distcp-2.7.3.jar:/usr/lib/hadoop-mapreduce/.//commons-httpclient-3.1.jar:/usr/lib/hadoop-mapreduce/.//jsch-0.1.42.jar:/usr/lib/hadoop-mapreduce/.//hadoop-sls.jar:/usr/lib/hadoop-mapreduce/.//jackson-databind-2.2.3.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-hs-2.7.3.jar:/usr/lib/hadoop-mapreduce/.//java-xmlbuilder-0.4.jar:/usr/lib/hadoop-mapreduce/.//aws-java-sdk-1.7.4.jar:/usr/lib/hadoop-mapreduce/.//hadoop-aws-2.7.3.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-examples-2.7.3.jar:/usr/lib/hadoop-mapreduce/.//xz-1.0.jar:/usr/lib/hadoop-mapreduce/.//hadoop-rumen.jar:/usr/lib/hadoop-mapreduce/.//commons-logging-1.1.3.jar:/usr/lib/hadoop-mapreduce/.//log4j-1.2.17.jar:/usr/lib/hadoop-mapreduce/.//zookeeper-3.4.6.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-core-2.7.3.jar:/usr/lib/hadoop-mapreduce/.//hadoop-datajoin.jar:/usr/lib/hadoop-mapreduce/.//commons-lang-2.6.jar:/usr/lib/hadoop-mapreduce/.//commons-lang3-3.3.2.jar:/usr/lib/hadoop-mapreduce/.//hamcrest-core-1.3.jar:/usr/lib/hadoop-mapreduce/.//httpclient-4.2.5.jar:/usr/lib/hadoop-mapreduce/.//commons-cli-1.2.jar:/usr/lib/hadoop-mapreduce/.//commons-io-2.4.jar:/usr/lib/hadoop-mapreduce/.//apacheds-i18n-2.0.0-M15.jar:/usr/lib/hadoop-mapreduce/.//jetty-util-6.1.26.jar:/usr/lib/hadoop-mapreduce/.//jackson-mapper-asl-1.9.13.jar:/usr/lib/hadoop-mapreduce/.//hadoop-archives-2.7.3.jar:/usr/lib/hadoop-mapreduce/.//htrace-core-3.1.0-incubating.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-common.jar:/usr/lib/hadoop-mapreduce/.//paranamer-2.3.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-jobclient-2.7.3.jar:/usr/lib/hadoop-mapreduce/.//hadoop-extras.jar:/usr/lib/hadoop-mapreduce/.//xmlenc-0.52.jar:/usr/lib/hadoop-mapreduce/.//hadoop-openstack-2.7.3.jar:/usr/lib/hadoop-mapreduce/.//jaxb-impl-2.2.3-1.jar:/usr/lib/hadoop-mapreduce/.//commons-beanutils-core-1.8.0.jar:/usr/lib/hadoop-mapreduce/.//jersey-server-1.9.jar:/usr/lib/hadoop-mapreduce/.//jsp-api-2.1.jar:/usr/lib/hadoop-mapreduce/.//jetty-6.1.26.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-hs-plugins-2.7.3.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-examples.jar:/usr/lib/hadoop-mapreduce/.//junit-4.11.jar:/usr/lib/hadoop-mapreduce/.//hadoop-azure.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-shuffle.jar:/usr/lib/hadoop-mapreduce/.//hadoop-streaming.jar:/usr/lib/hadoop-mapreduce/.//hadoop-ant-2.7.3.jar:/usr/lib/hadoop-mapreduce/.//servlet-api-2.5.jar:/usr/lib/hadoop-mapreduce/.//httpcore-4.2.5.jar:/usr/lib/hadoop-mapreduce/.//hadoop-rumen-2.7.3.jar:/usr/lib/hadoop-mapreduce/.//protobuf-java-2.5.0.jar:/usr/lib/hadoop-mapreduce/.//jersey-core-1.9.jar:/usr/lib/hadoop-mapreduce/.//stax-api-1.0-2.jar:/usr/lib/hadoop-mapreduce/.//commons-collections-3.2.2.jar:/usr/lib/hadoop/contrib/capacity-scheduler/*.jar:/usr/lib/hadoop/contrib/capacity-scheduler/*.jar:/usr/lib/hadoop/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/bigtop.git -r 2365207dc0440bb884e41d4ffe32a37ad0d0ed28; compiled by 'jenkins' on 2017-10-05T21:00Z
STARTUP_MSG:   java = 1.8.0_181
************************************************************/
2018-10-18 02:20:26,324 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2018-10-18 02:20:26,333 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: createNameNode []
2018-10-18 02:20:26,749 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2018-10-18 02:20:26,890 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2018-10-18 02:20:26,891 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NameNode metrics system started
2018-10-18 02:20:26,894 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: fs.defaultFS is hdfs://bootcamp.local:9000
2018-10-18 02:20:26,896 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Clients are to use bootcamp.local:9000 to access this namenode/service.
2018-10-18 02:20:27,100 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for hdfs at: http://0.0.0.0:50070
2018-10-18 02:20:27,205 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2018-10-18 02:20:27,217 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2018-10-18 02:20:27,227 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.namenode is not defined
2018-10-18 02:20:27,236 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2018-10-18 02:20:27,240 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2018-10-18 02:20:27,240 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2018-10-18 02:20:27,241 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2018-10-18 02:20:27,472 INFO org.apache.hadoop.http.HttpServer2: Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2018-10-18 02:20:27,475 INFO org.apache.hadoop.http.HttpServer2: addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2018-10-18 02:20:27,502 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50070
2018-10-18 02:20:27,503 INFO org.mortbay.log: jetty-6.1.26
2018-10-18 02:20:27,695 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:50070
2018-10-18 02:20:27,756 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one image storage directory (dfs.namenode.name.dir) configured. Beware of data loss due to lack of redundant storage directories!
2018-10-18 02:20:27,756 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one namespace edits storage directory (dfs.namenode.edits.dir) configured. Beware of data loss due to lack of redundant storage directories!
2018-10-18 02:20:27,832 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: No KeyProvider found.
2018-10-18 02:20:27,832 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair:true
2018-10-18 02:20:27,925 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2018-10-18 02:20:27,926 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2018-10-18 02:20:27,928 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2018-10-18 02:20:27,929 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2018 Oct 18 02:20:27
2018-10-18 02:20:27,932 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2018-10-18 02:20:27,932 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2018-10-18 02:20:27,936 INFO org.apache.hadoop.util.GSet: 2.0% max memory 889 MB = 17.8 MB
2018-10-18 02:20:27,936 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2018-10-18 02:20:27,945 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2018-10-18 02:20:27,946 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 1
2018-10-18 02:20:27,946 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2018-10-18 02:20:27,947 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2018-10-18 02:20:27,947 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2018-10-18 02:20:27,947 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2018-10-18 02:20:27,948 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2018-10-18 02:20:27,948 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2018-10-18 02:20:27,960 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = hdfs (auth:SIMPLE)
2018-10-18 02:20:27,960 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2018-10-18 02:20:27,960 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2018-10-18 02:20:27,961 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2018-10-18 02:20:27,964 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2018-10-18 02:20:28,123 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2018-10-18 02:20:28,123 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2018-10-18 02:20:28,124 INFO org.apache.hadoop.util.GSet: 1.0% max memory 889 MB = 8.9 MB
2018-10-18 02:20:28,125 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2018-10-18 02:20:28,126 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: ACLs enabled? false
2018-10-18 02:20:28,126 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: XAttrs enabled? true
2018-10-18 02:20:28,127 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Maximum size of an xattr: 16384
2018-10-18 02:20:28,127 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times
2018-10-18 02:20:28,136 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2018-10-18 02:20:28,137 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2018-10-18 02:20:28,138 INFO org.apache.hadoop.util.GSet: 0.25% max memory 889 MB = 2.2 MB
2018-10-18 02:20:28,138 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2018-10-18 02:20:28,140 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2018-10-18 02:20:28,140 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2018-10-18 02:20:28,141 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2018-10-18 02:20:28,145 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.window.num.buckets = 10
2018-10-18 02:20:28,145 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.num.users = 10
2018-10-18 02:20:28,146 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2018-10-18 02:20:28,148 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache on namenode is enabled
2018-10-18 02:20:28,148 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2018-10-18 02:20:28,152 INFO org.apache.hadoop.util.GSet: Computing capacity for map NameNodeRetryCache
2018-10-18 02:20:28,152 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2018-10-18 02:20:28,153 INFO org.apache.hadoop.util.GSet: 0.029999999329447746% max memory 889 MB = 273.1 KB
2018-10-18 02:20:28,153 INFO org.apache.hadoop.util.GSet: capacity      = 2^15 = 32768 entries
2018-10-18 02:20:28,173 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /data/name/in_use.lock acquired by nodename 739@bootcamp.local
2018-10-18 02:20:28,225 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Recovering unfinalized segments in /data/name/current
2018-10-18 02:20:28,437 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /data/name/current/edits_inprogress_0000000000000000015 -> /data/name/current/edits_0000000000000000015-0000000000000000475
2018-10-18 02:20:28,448 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Planning to load image: FSImageFile(file=/data/name/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2018-10-18 02:20:28,487 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Loading 1 INodes.
2018-10-18 02:20:28,525 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Loaded FSImage in 0 seconds.
2018-10-18 02:20:28,526 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 0 from /data/name/current/fsimage_0000000000000000000
2018-10-18 02:20:28,527 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@2fc0cc3 expecting start txid #1
2018-10-18 02:20:28,528 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /data/name/current/edits_0000000000000000001-0000000000000000014
2018-10-18 02:20:28,530 INFO org.apache.hadoop.hdfs.server.namenode.EditLogInputStream: Fast-forwarding stream '/data/name/current/edits_0000000000000000001-0000000000000000014' to transaction ID 1
2018-10-18 02:20:28,561 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /data/name/current/edits_0000000000000000001-0000000000000000014 of size 1048576 edits # 14 loaded in 0 seconds
2018-10-18 02:20:28,562 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@328cf0e1 expecting start txid #15
2018-10-18 02:20:28,562 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /data/name/current/edits_0000000000000000015-0000000000000000475
2018-10-18 02:20:28,562 INFO org.apache.hadoop.hdfs.server.namenode.EditLogInputStream: Fast-forwarding stream '/data/name/current/edits_0000000000000000015-0000000000000000475' to transaction ID 1
2018-10-18 02:20:28,651 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /data/name/current/edits_0000000000000000015-0000000000000000475 of size 1048576 edits # 461 loaded in 0 seconds
2018-10-18 02:20:28,653 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Need to save fs image? true (staleImage=true, haEnabled=false, isRollingUpgrade=false)
2018-10-18 02:20:28,653 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Save namespace ...
2018-10-18 02:20:28,663 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /data/name/current/fsimage.ckpt_0000000000000000475 using no compression
2018-10-18 02:20:28,718 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /data/name/current/fsimage.ckpt_0000000000000000475 of size 5246 bytes saved in 0 seconds.
2018-10-18 02:20:28,725 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 0
2018-10-18 02:20:28,734 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 476
2018-10-18 02:20:28,841 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2018-10-18 02:20:28,842 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Finished loading FSImage in 685 msecs
2018-10-18 02:20:29,157 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: RPC server is binding to bootcamp.local:9000
2018-10-18 02:20:29,167 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2018-10-18 02:20:29,183 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 9000
2018-10-18 02:20:29,217 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Registered FSNamesystemState MBean
2018-10-18 02:20:29,232 INFO org.apache.hadoop.hdfs.server.namenode.LeaseManager: Number of blocks under construction: 0
2018-10-18 02:20:29,233 INFO org.apache.hadoop.hdfs.server.namenode.LeaseManager: Number of blocks under construction: 0
2018-10-18 02:20:29,233 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode ON. 
The reported blocks 0 needs additional 22 blocks to reach the threshold 0.9990 of total blocks 22.
The number of live datanodes 0 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached.
2018-10-18 02:20:29,241 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Number of failed storage changes from 0 to 0
2018-10-18 02:20:29,278 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2018-10-18 02:20:29,278 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 9000: starting
2018-10-18 02:20:29,285 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: NameNode RPC up at: bootcamp.local/172.18.0.2:9000
2018-10-18 02:20:29,285 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Starting services required for active state
2018-10-18 02:20:29,292 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Starting CacheReplicationMonitor with interval 30000 milliseconds
2018-10-18 02:20:38,089 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(172.18.0.2:50010, datanodeUuid=47ecd31e-43cd-4989-84ba-314b1664d0de, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-747ab8c6-1ec4-46a0-9dee-c8151846aca5;nsid=199960936;c=0) storage 47ecd31e-43cd-4989-84ba-314b1664d0de
2018-10-18 02:20:38,090 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Number of failed storage changes from 0 to 0
2018-10-18 02:20:38,091 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/172.18.0.2:50010
2018-10-18 02:20:38,212 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Number of failed storage changes from 0 to 0
2018-10-18 02:20:38,212 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Adding new storage ID DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5 for DN 172.18.0.2:50010
2018-10-18 02:20:38,286 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode extension entered. 
The reported blocks 21 has reached the threshold 0.9990 of total blocks 22. The number of live datanodes 1 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 29 seconds.
2018-10-18 02:20:38,286 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: initializing replication queues
2018-10-18 02:20:38,289 INFO BlockStateChange: BLOCK* processReport: from storage DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5 node DatanodeRegistration(172.18.0.2:50010, datanodeUuid=47ecd31e-43cd-4989-84ba-314b1664d0de, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-747ab8c6-1ec4-46a0-9dee-c8151846aca5;nsid=199960936;c=0), blocks: 22, hasStaleStorage: false, processing time: 11 msecs
2018-10-18 02:20:38,291 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Total number of blocks            = 22
2018-10-18 02:20:38,292 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of invalid blocks          = 0
2018-10-18 02:20:38,292 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of under-replicated blocks = 0
2018-10-18 02:20:38,293 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of  over-replicated blocks = 0
2018-10-18 02:20:38,293 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of blocks being written    = 0
2018-10-18 02:20:38,294 INFO org.apache.hadoop.hdfs.StateChange: STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 6 msec
2018-10-18 02:20:58,311 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode ON, in safe mode extension. 
The reported blocks 22 has reached the threshold 0.9990 of total blocks 22. The number of live datanodes 1 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 9 seconds.
2018-10-18 02:21:08,284 INFO org.apache.hadoop.hdfs.StateChange: STATE* Leaving safe mode after 40 secs
2018-10-18 02:21:08,286 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode is OFF
2018-10-18 02:21:08,287 INFO org.apache.hadoop.hdfs.StateChange: STATE* Network topology has 1 racks and 1 datanodes
2018-10-18 02:21:08,287 INFO org.apache.hadoop.hdfs.StateChange: STATE* UnderReplicatedBlocks has 0 blocks
2018-10-18 02:21:17,635 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741870_1048{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /app/hbase/WALs/bootcamp.local,16020,1539829260266/bootcamp.local%2C16020%2C1539829260266.default.1539829277522
2018-10-18 02:21:17,887 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* fsync: /app/hbase/WALs/bootcamp.local,16020,1539829260266/bootcamp.local%2C16020%2C1539829260266.default.1539829277522 for DFSClient_NONMAPREDUCE_-299579267_1
2018-10-18 02:21:20,305 INFO org.apache.hadoop.hdfs.server.namenode.EditLogFileOutputStream: Nothing to flush
2018-10-18 02:21:20,436 INFO org.apache.hadoop.ipc.Server: IPC Server handler 4 on 9000, call org.apache.hadoop.hdfs.protocol.ClientProtocol.delete from 172.18.0.2:50054 Call#53 Retry#0
org.apache.hadoop.fs.PathIsNotEmptyDirectoryException: `/app/hbase/WALs/bootcamp.local,16020,1536728777779-splitting is non empty': Directory is not empty
	at org.apache.hadoop.hdfs.server.namenode.FSDirDeleteOp.delete(FSDirDeleteOp.java:85)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:3714)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.delete(NameNodeRpcServer.java:953)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.delete(ClientNamenodeProtocolServerSideTranslatorPB.java:611)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2049)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2045)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2045)
2018-10-18 02:21:20,572 INFO org.apache.hadoop.ipc.Server: IPC Server handler 3 on 9000, call org.apache.hadoop.hdfs.protocol.ClientProtocol.delete from 172.18.0.2:50054 Call#60 Retry#0
org.apache.hadoop.fs.PathIsNotEmptyDirectoryException: `/app/hbase/WALs/bootcamp.local,16020,1536728777779-splitting is non empty': Directory is not empty
	at org.apache.hadoop.hdfs.server.namenode.FSDirDeleteOp.delete(FSDirDeleteOp.java:85)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:3714)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.delete(NameNodeRpcServer.java:953)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.delete(ClientNamenodeProtocolServerSideTranslatorPB.java:611)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2049)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2045)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2045)
2018-10-18 02:21:20,688 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741871_1049{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /app/hbase/WALs/bootcamp.local,16020,1539829260266/bootcamp.local%2C16020%2C1539829260266..meta.1539829280675.meta
2018-10-18 02:21:20,703 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* fsync: /app/hbase/WALs/bootcamp.local,16020,1539829260266/bootcamp.local%2C16020%2C1539829260266..meta.1539829280675.meta for DFSClient_NONMAPREDUCE_-299579267_1
2018-10-18 02:21:21,192 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /app/hbase/data/hbase/meta/1588230740/recovered.edits/10.seqid is closed by DFSClient_NONMAPREDUCE_-299579267_1
2018-10-18 02:21:21,615 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741872_1050{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /app/hbase/data/hbase/namespace/b7bfc7fcc5816946e33ea9db3ddeebfa/recovered.edits/0000000000000000003.temp
2018-10-18 02:21:21,635 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741872_1050{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 0
2018-10-18 02:21:21,638 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /app/hbase/data/hbase/namespace/b7bfc7fcc5816946e33ea9db3ddeebfa/recovered.edits/0000000000000000003.temp is closed by DFSClient_NONMAPREDUCE_-299579267_1
2018-10-18 02:21:22,447 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741873_1051{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /app/hbase/data/hbase/namespace/b7bfc7fcc5816946e33ea9db3ddeebfa/.tmp/9c47608605f44ceea33e7d91e5404413
2018-10-18 02:21:22,465 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741873_1051{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 0
2018-10-18 02:21:22,469 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /app/hbase/data/hbase/namespace/b7bfc7fcc5816946e33ea9db3ddeebfa/.tmp/9c47608605f44ceea33e7d91e5404413 is closed by DFSClient_NONMAPREDUCE_-299579267_1
2018-10-18 02:21:22,543 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741872_1050 172.18.0.2:50010 
2018-10-18 02:21:22,560 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /app/hbase/data/hbase/namespace/b7bfc7fcc5816946e33ea9db3ddeebfa/recovered.edits/8.seqid is closed by DFSClient_NONMAPREDUCE_-299579267_1
2018-10-18 02:21:23,183 INFO BlockStateChange: BLOCK* BlockManager: ask 172.18.0.2:50010 to delete [blk_1073741872_1050]
2018-10-18 02:22:15,561 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 56 Total time for transactions(ms): 10 Number of transactions batched in Syncs: 12 Number of syncs: 41 SyncTimes(ms): 52 
2018-10-18 02:22:15,563 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741830_1018 172.18.0.2:50010 
2018-10-18 02:22:17,124 INFO BlockStateChange: BLOCK* BlockManager: ask 172.18.0.2:50010 to delete [blk_1073741830_1018]
2018-10-18 02:26:42,350 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 57 Total time for transactions(ms): 11 Number of transactions batched in Syncs: 12 Number of syncs: 42 SyncTimes(ms): 52 
2018-10-18 02:26:42,361 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741874_1052{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /app/hbase/data/hbase/meta/1588230740/.tmp/ddf896ac9df34b91b4fe639f1e82bccf
2018-10-18 02:26:42,377 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741874_1052{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 0
2018-10-18 02:26:42,380 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /app/hbase/data/hbase/meta/1588230740/.tmp/ddf896ac9df34b91b4fe639f1e82bccf is closed by DFSClient_NONMAPREDUCE_-299579267_1
2018-10-18 02:32:14,834 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 64 Total time for transactions(ms): 12 Number of transactions batched in Syncs: 12 Number of syncs: 47 SyncTimes(ms): 56 
2018-10-18 02:32:14,844 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741839_1015 172.18.0.2:50010 
2018-10-18 02:32:14,851 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741829_1017 172.18.0.2:50010 
2018-10-18 02:32:14,857 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741838_1014 172.18.0.2:50010 
2018-10-18 02:32:16,608 INFO BlockStateChange: BLOCK* BlockManager: ask 172.18.0.2:50010 to delete [blk_1073741829_1017, blk_1073741838_1014, blk_1073741839_1015]
2018-10-18 03:21:04,258 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 67 Total time for transactions(ms): 18 Number of transactions batched in Syncs: 12 Number of syncs: 50 SyncTimes(ms): 59 
2018-10-18 03:21:04,310 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741875_1053{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /app/hbase/WALs/bootcamp.local,16020,1539829260266/bootcamp.local%2C16020%2C1539829260266.default.1539832864184
2018-10-18 03:21:04,350 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* fsync: /app/hbase/WALs/bootcamp.local,16020,1539829260266/bootcamp.local%2C16020%2C1539829260266.default.1539832864184 for DFSClient_NONMAPREDUCE_-299579267_1
2018-10-18 03:21:04,374 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741870_1048{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 83
2018-10-18 03:21:04,380 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /app/hbase/WALs/bootcamp.local,16020,1539829260266/bootcamp.local%2C16020%2C1539829260266.default.1539829277522 is closed by DFSClient_NONMAPREDUCE_-299579267_1
2018-10-18 03:21:26,871 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741876_1054{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /app/hbase/WALs/bootcamp.local,16020,1539829260266/bootcamp.local%2C16020%2C1539829260266..meta.1539832886855.meta
2018-10-18 03:21:26,885 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* fsync: /app/hbase/WALs/bootcamp.local,16020,1539829260266/bootcamp.local%2C16020%2C1539829260266..meta.1539832886855.meta for DFSClient_NONMAPREDUCE_-299579267_1
2018-10-18 03:21:26,897 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741871_1049{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 83
2018-10-18 03:21:26,902 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /app/hbase/WALs/bootcamp.local,16020,1539829260266/bootcamp.local%2C16020%2C1539829260266..meta.1539829280675.meta is closed by DFSClient_NONMAPREDUCE_-299579267_1
2018-10-18 03:31:10,652 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 83 Total time for transactions(ms): 19 Number of transactions batched in Syncs: 12 Number of syncs: 62 SyncTimes(ms): 77 
2018-10-18 03:31:10,668 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741870_1048 172.18.0.2:50010 
2018-10-18 03:31:10,815 INFO BlockStateChange: BLOCK* BlockManager: ask 172.18.0.2:50010 to delete [blk_1073741870_1048]
2018-10-18 03:32:10,576 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741871_1049 172.18.0.2:50010 
2018-10-18 03:32:10,785 INFO BlockStateChange: BLOCK* BlockManager: ask 172.18.0.2:50010 to delete [blk_1073741871_1049]
2018-10-18 03:54:12,263 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 2459ms
No GCs detected
2018-10-18 03:55:00,051 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 2566ms
No GCs detected
2018-10-18 05:55:00,000 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1414ms
No GCs detected
2018-10-18 05:55:02,033 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741877_1055{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /app/hbase/MasterProcWALs/state-00000000000000000003.log
2018-10-18 05:55:02,035 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 87 Total time for transactions(ms): 19 Number of transactions batched in Syncs: 12 Number of syncs: 64 SyncTimes(ms): 79 
2018-10-18 05:55:02,241 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741876_1054{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 83
2018-10-18 05:55:02,275 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /app/hbase/WALs/bootcamp.local,16020,1539829260266/bootcamp.local%2C16020%2C1539829260266..meta.1539832886855.meta is closed by DFSClient_NONMAPREDUCE_-299579267_1
2018-10-18 05:55:02,285 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741875_1053{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 83
2018-10-18 05:55:02,291 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /app/hbase/WALs/bootcamp.local,16020,1539829260266/bootcamp.local%2C16020%2C1539829260266.default.1539832864184 is closed by DFSClient_NONMAPREDUCE_-299579267_1
2018-10-18 05:55:02,366 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741877_1055{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 0
2018-10-18 05:55:02,374 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /app/hbase/MasterProcWALs/state-00000000000000000003.log is closed by DFSClient_NONMAPREDUCE_-1876757645_1
2018-10-18 07:35:37,646 WARN org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 54238ms
No GCs detected
2018-10-18 08:27:08,059 WARN org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 51254ms
No GCs detected
2018-10-18 09:27:58,058 WARN org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 36878ms
No GCs detected
2018-10-18 09:29:15,673 WARN org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 40925ms
No GCs detected
2018-10-18 10:50:25,275 WARN org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 28617ms
No GCs detected
2018-10-18 11:59:43,110 WARN org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 34804ms
No GCs detected
2018-10-18 12:07:02,582 WARN org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 35782ms
No GCs detected
2018-10-18 13:40:05,275 WARN org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 35427ms
No GCs detected
2018-10-18 13:41:14,156 WARN org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 32999ms
No GCs detected
2018-10-18 15:31:14,857 WARN org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 32785ms
No GCs detected
2018-10-18 15:54:29,041 WARN org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 39094ms
No GCs detected
2018-10-18 16:24:55,894 WARN org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 33565ms
No GCs detected
2018-10-18 16:29:08,263 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1248ms
No GCs detected
2018-10-18 20:37:26,775 INFO BlockStateChange: BLOCK* processReport: from storage DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5 node DatanodeRegistration(172.18.0.2:50010, datanodeUuid=47ecd31e-43cd-4989-84ba-314b1664d0de, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-747ab8c6-1ec4-46a0-9dee-c8151846aca5;nsid=199960936;c=0), blocks: 23, hasStaleStorage: false, processing time: 33 msecs
2018-10-19 02:16:23,476 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1541ms
No GCs detected
2018-10-19 02:39:57,556 INFO BlockStateChange: BLOCK* processReport: from storage DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5 node DatanodeRegistration(172.18.0.2:50010, datanodeUuid=47ecd31e-43cd-4989-84ba-314b1664d0de, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-747ab8c6-1ec4-46a0-9dee-c8151846aca5;nsid=199960936;c=0), blocks: 23, hasStaleStorage: false, processing time: 2 msecs
2018-10-19 03:09:58,387 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1370ms
No GCs detected
2018-10-19 03:13:32,772 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1262ms
No GCs detected
2018-10-19 05:02:03,907 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1167ms
No GCs detected
2018-10-19 05:11:40,057 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1106ms
No GCs detected
2018-10-19 05:18:06,525 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1617ms
No GCs detected
2018-10-19 05:37:27,674 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1301ms
No GCs detected
2018-10-19 05:41:27,705 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1376ms
No GCs detected
2018-10-19 09:21:19,311 WARN org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 52052ms
No GCs detected
2018-10-19 11:21:33,741 WARN org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 39199ms
No GCs detected
2018-10-19 11:22:29,609 WARN org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 34669ms
No GCs detected
2018-10-19 15:15:37,781 WARN org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 32652ms
No GCs detected
2018-10-19 15:16:55,561 WARN org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 39992ms
No GCs detected
2018-10-19 15:21:39,478 WARN org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 38125ms
No GCs detected
2018-10-19 16:17:29,560 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1377ms
No GCs detected
2018-10-19 16:22:38,403 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1170ms
No GCs detected
2018-10-19 18:23:38,438 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1426ms
No GCs detected
2018-10-19 19:31:40,169 INFO BlockStateChange: BLOCK* processReport: from storage DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5 node DatanodeRegistration(172.18.0.2:50010, datanodeUuid=47ecd31e-43cd-4989-84ba-314b1664d0de, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-747ab8c6-1ec4-46a0-9dee-c8151846aca5;nsid=199960936;c=0), blocks: 23, hasStaleStorage: false, processing time: 9 msecs
2018-10-19 20:01:48,880 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1375ms
No GCs detected
2018-10-19 20:55:50,420 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1246ms
No GCs detected
2018-10-19 20:57:23,647 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1113ms
No GCs detected
2018-10-19 20:59:16,581 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1105ms
No GCs detected
2018-10-21 17:45:18,537 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NameNode
STARTUP_MSG:   host = bootcamp.local/172.18.0.2
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.3
STARTUP_MSG:   classpath = /etc/hadoop/conf:/usr/lib/hadoop/lib/asm-3.2.jar:/usr/lib/hadoop/lib/jackson-jaxrs-1.9.13.jar:/usr/lib/hadoop/lib/api-asn1-api-1.0.0-M20.jar:/usr/lib/hadoop/lib/jersey-json-1.9.jar:/usr/lib/hadoop/lib/gson-2.2.4.jar:/usr/lib/hadoop/lib/commons-net-3.1.jar:/usr/lib/hadoop/lib/commons-digester-1.8.jar:/usr/lib/hadoop/lib/guava-11.0.2.jar:/usr/lib/hadoop/lib/api-util-1.0.0-M20.jar:/usr/lib/hadoop/lib/jets3t-0.9.0.jar:/usr/lib/hadoop/lib/snappy-java-1.0.4.1.jar:/usr/lib/hadoop/lib/commons-compress-1.4.1.jar:/usr/lib/hadoop/lib/activation-1.1.jar:/usr/lib/hadoop/lib/slf4j-log4j12-1.7.10.jar:/usr/lib/hadoop/lib/curator-framework-2.7.1.jar:/usr/lib/hadoop/lib/jackson-core-asl-1.9.13.jar:/usr/lib/hadoop/lib/commons-beanutils-1.7.0.jar:/usr/lib/hadoop/lib/curator-client-2.7.1.jar:/usr/lib/hadoop/lib/jsr305-3.0.0.jar:/usr/lib/hadoop/lib/avro-1.7.4.jar:/usr/lib/hadoop/lib/jackson-xc-1.9.13.jar:/usr/lib/hadoop/lib/commons-configuration-1.6.jar:/usr/lib/hadoop/lib/commons-math3-3.1.1.jar:/usr/lib/hadoop/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/lib/hadoop/lib/jaxb-api-2.2.2.jar:/usr/lib/hadoop/lib/netty-3.6.2.Final.jar:/usr/lib/hadoop/lib/curator-recipes-2.7.1.jar:/usr/lib/hadoop/lib/mockito-all-1.8.5.jar:/usr/lib/hadoop/lib/commons-codec-1.4.jar:/usr/lib/hadoop/lib/jettison-1.1.jar:/usr/lib/hadoop/lib/commons-httpclient-3.1.jar:/usr/lib/hadoop/lib/jsch-0.1.42.jar:/usr/lib/hadoop/lib/java-xmlbuilder-0.4.jar:/usr/lib/hadoop/lib/xz-1.0.jar:/usr/lib/hadoop/lib/commons-logging-1.1.3.jar:/usr/lib/hadoop/lib/log4j-1.2.17.jar:/usr/lib/hadoop/lib/zookeeper-3.4.6.jar:/usr/lib/hadoop/lib/commons-lang-2.6.jar:/usr/lib/hadoop/lib/hamcrest-core-1.3.jar:/usr/lib/hadoop/lib/httpclient-4.2.5.jar:/usr/lib/hadoop/lib/commons-cli-1.2.jar:/usr/lib/hadoop/lib/commons-io-2.4.jar:/usr/lib/hadoop/lib/apacheds-i18n-2.0.0-M15.jar:/usr/lib/hadoop/lib/jetty-util-6.1.26.jar:/usr/lib/hadoop/lib/jackson-mapper-asl-1.9.13.jar:/usr/lib/hadoop/lib/htrace-core-3.1.0-incubating.jar:/usr/lib/hadoop/lib/paranamer-2.3.jar:/usr/lib/hadoop/lib/xmlenc-0.52.jar:/usr/lib/hadoop/lib/jaxb-impl-2.2.3-1.jar:/usr/lib/hadoop/lib/commons-beanutils-core-1.8.0.jar:/usr/lib/hadoop/lib/jersey-server-1.9.jar:/usr/lib/hadoop/lib/slf4j-api-1.7.10.jar:/usr/lib/hadoop/lib/jsp-api-2.1.jar:/usr/lib/hadoop/lib/jetty-6.1.26.jar:/usr/lib/hadoop/lib/junit-4.11.jar:/usr/lib/hadoop/lib/servlet-api-2.5.jar:/usr/lib/hadoop/lib/httpcore-4.2.5.jar:/usr/lib/hadoop/lib/protobuf-java-2.5.0.jar:/usr/lib/hadoop/lib/jersey-core-1.9.jar:/usr/lib/hadoop/lib/stax-api-1.0-2.jar:/usr/lib/hadoop/lib/commons-collections-3.2.2.jar:/usr/lib/hadoop/.//hadoop-nfs.jar:/usr/lib/hadoop/.//hadoop-common.jar:/usr/lib/hadoop/.//hadoop-auth-2.7.3.jar:/usr/lib/hadoop/.//hadoop-common-2.7.3-tests.jar:/usr/lib/hadoop/.//hadoop-common-2.7.3.jar:/usr/lib/hadoop/.//hadoop-auth.jar:/usr/lib/hadoop/.//hadoop-annotations.jar:/usr/lib/hadoop/.//hadoop-annotations-2.7.3.jar:/usr/lib/hadoop/.//hadoop-nfs-2.7.3.jar:/usr/lib/hadoop-hdfs/./:/usr/lib/hadoop-hdfs/lib/asm-3.2.jar:/usr/lib/hadoop-hdfs/lib/xercesImpl-2.9.1.jar:/usr/lib/hadoop-hdfs/lib/guava-11.0.2.jar:/usr/lib/hadoop-hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/lib/hadoop-hdfs/lib/jsr305-3.0.0.jar:/usr/lib/hadoop-hdfs/lib/leveldbjni-all-1.8.jar:/usr/lib/hadoop-hdfs/lib/netty-3.6.2.Final.jar:/usr/lib/hadoop-hdfs/lib/netty-all-4.0.23.Final.jar:/usr/lib/hadoop-hdfs/lib/commons-codec-1.4.jar:/usr/lib/hadoop-hdfs/lib/xml-apis-1.3.04.jar:/usr/lib/hadoop-hdfs/lib/commons-logging-1.1.3.jar:/usr/lib/hadoop-hdfs/lib/log4j-1.2.17.jar:/usr/lib/hadoop-hdfs/lib/commons-lang-2.6.jar:/usr/lib/hadoop-hdfs/lib/commons-cli-1.2.jar:/usr/lib/hadoop-hdfs/lib/commons-io-2.4.jar:/usr/lib/hadoop-hdfs/lib/jetty-util-6.1.26.jar:/usr/lib/hadoop-hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/lib/hadoop-hdfs/lib/htrace-core-3.1.0-incubating.jar:/usr/lib/hadoop-hdfs/lib/xmlenc-0.52.jar:/usr/lib/hadoop-hdfs/lib/jersey-server-1.9.jar:/usr/lib/hadoop-hdfs/lib/jetty-6.1.26.jar:/usr/lib/hadoop-hdfs/lib/commons-daemon-1.0.13.jar:/usr/lib/hadoop-hdfs/lib/servlet-api-2.5.jar:/usr/lib/hadoop-hdfs/lib/protobuf-java-2.5.0.jar:/usr/lib/hadoop-hdfs/lib/jersey-core-1.9.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs-nfs.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs-2.7.3-tests.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs-nfs-2.7.3.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs-2.7.3.jar:/usr/lib/hadoop-yarn/lib/asm-3.2.jar:/usr/lib/hadoop-yarn/lib/jackson-jaxrs-1.9.13.jar:/usr/lib/hadoop-yarn/lib/jersey-json-1.9.jar:/usr/lib/hadoop-yarn/lib/jersey-client-1.9.jar:/usr/lib/hadoop-yarn/lib/guava-11.0.2.jar:/usr/lib/hadoop-yarn/lib/jersey-guice-1.9.jar:/usr/lib/hadoop-yarn/lib/commons-compress-1.4.1.jar:/usr/lib/hadoop-yarn/lib/activation-1.1.jar:/usr/lib/hadoop-yarn/lib/guice-servlet-3.0.jar:/usr/lib/hadoop-yarn/lib/zookeeper-3.4.6-tests.jar:/usr/lib/hadoop-yarn/lib/jackson-core-asl-1.9.13.jar:/usr/lib/hadoop-yarn/lib/jsr305-3.0.0.jar:/usr/lib/hadoop-yarn/lib/jackson-xc-1.9.13.jar:/usr/lib/hadoop-yarn/lib/leveldbjni-all-1.8.jar:/usr/lib/hadoop-yarn/lib/jaxb-api-2.2.2.jar:/usr/lib/hadoop-yarn/lib/netty-3.6.2.Final.jar:/usr/lib/hadoop-yarn/lib/javax.inject-1.jar:/usr/lib/hadoop-yarn/lib/commons-codec-1.4.jar:/usr/lib/hadoop-yarn/lib/jettison-1.1.jar:/usr/lib/hadoop-yarn/lib/guice-3.0.jar:/usr/lib/hadoop-yarn/lib/xz-1.0.jar:/usr/lib/hadoop-yarn/lib/commons-logging-1.1.3.jar:/usr/lib/hadoop-yarn/lib/log4j-1.2.17.jar:/usr/lib/hadoop-yarn/lib/zookeeper-3.4.6.jar:/usr/lib/hadoop-yarn/lib/commons-lang-2.6.jar:/usr/lib/hadoop-yarn/lib/commons-cli-1.2.jar:/usr/lib/hadoop-yarn/lib/commons-io-2.4.jar:/usr/lib/hadoop-yarn/lib/jetty-util-6.1.26.jar:/usr/lib/hadoop-yarn/lib/jackson-mapper-asl-1.9.13.jar:/usr/lib/hadoop-yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/lib/hadoop-yarn/lib/jersey-server-1.9.jar:/usr/lib/hadoop-yarn/lib/aopalliance-1.0.jar:/usr/lib/hadoop-yarn/lib/jetty-6.1.26.jar:/usr/lib/hadoop-yarn/lib/servlet-api-2.5.jar:/usr/lib/hadoop-yarn/lib/protobuf-java-2.5.0.jar:/usr/lib/hadoop-yarn/lib/jersey-core-1.9.jar:/usr/lib/hadoop-yarn/lib/stax-api-1.0-2.jar:/usr/lib/hadoop-yarn/lib/commons-collections-3.2.2.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-resourcemanager.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-resourcemanager-2.7.3.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-applicationhistoryservice-2.7.3.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-registry.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-tests.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-common.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-common-2.7.3.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-applications-distributedshell.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-client.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-common-2.7.3.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-applications-unmanaged-am-launcher.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-web-proxy.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-api.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-tests-2.7.3.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-nodemanager-2.7.3.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-api-2.7.3.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-sharedcachemanager-2.7.3.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-common.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-client-2.7.3.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-nodemanager.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-sharedcachemanager.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-registry-2.7.3.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-applications-unmanaged-am-launcher-2.7.3.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-web-proxy-2.7.3.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-applicationhistoryservice.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-applications-distributedshell-2.7.3.jar:/usr/lib/hadoop-mapreduce/lib/asm-3.2.jar:/usr/lib/hadoop-mapreduce/lib/jersey-guice-1.9.jar:/usr/lib/hadoop-mapreduce/lib/snappy-java-1.0.4.1.jar:/usr/lib/hadoop-mapreduce/lib/commons-compress-1.4.1.jar:/usr/lib/hadoop-mapreduce/lib/guice-servlet-3.0.jar:/usr/lib/hadoop-mapreduce/lib/jackson-core-asl-1.9.13.jar:/usr/lib/hadoop-mapreduce/lib/avro-1.7.4.jar:/usr/lib/hadoop-mapreduce/lib/leveldbjni-all-1.8.jar:/usr/lib/hadoop-mapreduce/lib/netty-3.6.2.Final.jar:/usr/lib/hadoop-mapreduce/lib/javax.inject-1.jar:/usr/lib/hadoop-mapreduce/lib/guice-3.0.jar:/usr/lib/hadoop-mapreduce/lib/xz-1.0.jar:/usr/lib/hadoop-mapreduce/lib/log4j-1.2.17.jar:/usr/lib/hadoop-mapreduce/lib/hamcrest-core-1.3.jar:/usr/lib/hadoop-mapreduce/lib/commons-io-2.4.jar:/usr/lib/hadoop-mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/usr/lib/hadoop-mapreduce/lib/paranamer-2.3.jar:/usr/lib/hadoop-mapreduce/lib/jersey-server-1.9.jar:/usr/lib/hadoop-mapreduce/lib/aopalliance-1.0.jar:/usr/lib/hadoop-mapreduce/lib/junit-4.11.jar:/usr/lib/hadoop-mapreduce/lib/protobuf-java-2.5.0.jar:/usr/lib/hadoop-mapreduce/lib/jersey-core-1.9.jar:/usr/lib/hadoop-mapreduce/.//jackson-core-2.2.3.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-jobclient-2.7.3-tests.jar:/usr/lib/hadoop-mapreduce/.//azure-storage-2.0.0.jar:/usr/lib/hadoop-mapreduce/.//metrics-core-3.0.1.jar:/usr/lib/hadoop-mapreduce/.//asm-3.2.jar:/usr/lib/hadoop-mapreduce/.//jackson-jaxrs-1.9.13.jar:/usr/lib/hadoop-mapreduce/.//hadoop-sls-2.7.3.jar:/usr/lib/hadoop-mapreduce/.//api-asn1-api-1.0.0-M20.jar:/usr/lib/hadoop-mapreduce/.//jersey-json-1.9.jar:/usr/lib/hadoop-mapreduce/.//gson-2.2.4.jar:/usr/lib/hadoop-mapreduce/.//commons-net-3.1.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-app-2.7.3.jar:/usr/lib/hadoop-mapreduce/.//commons-digester-1.8.jar:/usr/lib/hadoop-mapreduce/.//guava-11.0.2.jar:/usr/lib/hadoop-mapreduce/.//api-util-1.0.0-M20.jar:/usr/lib/hadoop-mapreduce/.//jets3t-0.9.0.jar:/usr/lib/hadoop-mapreduce/.//snappy-java-1.0.4.1.jar:/usr/lib/hadoop-mapreduce/.//hadoop-streaming-2.7.3.jar:/usr/lib/hadoop-mapreduce/.//commons-compress-1.4.1.jar:/usr/lib/hadoop-mapreduce/.//activation-1.1.jar:/usr/lib/hadoop-mapreduce/.//curator-framework-2.7.1.jar:/usr/lib/hadoop-mapreduce/.//hadoop-archives.jar:/usr/lib/hadoop-mapreduce/.//hadoop-aws.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-core.jar:/usr/lib/hadoop-mapreduce/.//jackson-core-asl-1.9.13.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-hs.jar:/usr/lib/hadoop-mapreduce/.//commons-beanutils-1.7.0.jar:/usr/lib/hadoop-mapreduce/.//curator-client-2.7.1.jar:/usr/lib/hadoop-mapreduce/.//hadoop-azure-2.7.3.jar:/usr/lib/hadoop-mapreduce/.//jsr305-3.0.0.jar:/usr/lib/hadoop-mapreduce/.//avro-1.7.4.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-jobclient.jar:/usr/lib/hadoop-mapreduce/.//hadoop-gridmix.jar:/usr/lib/hadoop-mapreduce/.//hadoop-distcp.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-app.jar:/usr/lib/hadoop-mapreduce/.//jackson-xc-1.9.13.jar:/usr/lib/hadoop-mapreduce/.//hadoop-auth-2.7.3.jar:/usr/lib/hadoop-mapreduce/.//commons-configuration-1.6.jar:/usr/lib/hadoop-mapreduce/.//commons-math3-3.1.1.jar:/usr/lib/hadoop-mapreduce/.//hadoop-datajoin-2.7.3.jar:/usr/lib/hadoop-mapreduce/.//apacheds-kerberos-codec-2.0.0-M15.jar:/usr/lib/hadoop-mapreduce/.//hadoop-gridmix-2.7.3.jar:/usr/lib/hadoop-mapreduce/.//hadoop-ant.jar:/usr/lib/hadoop-mapreduce/.//hadoop-auth.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-shuffle-2.7.3.jar:/usr/lib/hadoop-mapreduce/.//jaxb-api-2.2.2.jar:/usr/lib/hadoop-mapreduce/.//netty-3.6.2.Final.jar:/usr/lib/hadoop-mapreduce/.//curator-recipes-2.7.1.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-hs-plugins.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-common-2.7.3.jar:/usr/lib/hadoop-mapreduce/.//mockito-all-1.8.5.jar:/usr/lib/hadoop-mapreduce/.//joda-time-2.9.9.jar:/usr/lib/hadoop-mapreduce/.//hadoop-openstack.jar:/usr/lib/hadoop-mapreduce/.//jackson-annotations-2.2.3.jar:/usr/lib/hadoop-mapreduce/.//commons-codec-1.4.jar:/usr/lib/hadoop-mapreduce/.//hadoop-extras-2.7.3.jar:/usr/lib/hadoop-mapreduce/.//jettison-1.1.jar:/usr/lib/hadoop-mapreduce/.//hadoop-distcp-2.7.3.jar:/usr/lib/hadoop-mapreduce/.//commons-httpclient-3.1.jar:/usr/lib/hadoop-mapreduce/.//jsch-0.1.42.jar:/usr/lib/hadoop-mapreduce/.//hadoop-sls.jar:/usr/lib/hadoop-mapreduce/.//jackson-databind-2.2.3.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-hs-2.7.3.jar:/usr/lib/hadoop-mapreduce/.//java-xmlbuilder-0.4.jar:/usr/lib/hadoop-mapreduce/.//aws-java-sdk-1.7.4.jar:/usr/lib/hadoop-mapreduce/.//hadoop-aws-2.7.3.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-examples-2.7.3.jar:/usr/lib/hadoop-mapreduce/.//xz-1.0.jar:/usr/lib/hadoop-mapreduce/.//hadoop-rumen.jar:/usr/lib/hadoop-mapreduce/.//commons-logging-1.1.3.jar:/usr/lib/hadoop-mapreduce/.//log4j-1.2.17.jar:/usr/lib/hadoop-mapreduce/.//zookeeper-3.4.6.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-core-2.7.3.jar:/usr/lib/hadoop-mapreduce/.//hadoop-datajoin.jar:/usr/lib/hadoop-mapreduce/.//commons-lang-2.6.jar:/usr/lib/hadoop-mapreduce/.//commons-lang3-3.3.2.jar:/usr/lib/hadoop-mapreduce/.//hamcrest-core-1.3.jar:/usr/lib/hadoop-mapreduce/.//httpclient-4.2.5.jar:/usr/lib/hadoop-mapreduce/.//commons-cli-1.2.jar:/usr/lib/hadoop-mapreduce/.//commons-io-2.4.jar:/usr/lib/hadoop-mapreduce/.//apacheds-i18n-2.0.0-M15.jar:/usr/lib/hadoop-mapreduce/.//jetty-util-6.1.26.jar:/usr/lib/hadoop-mapreduce/.//jackson-mapper-asl-1.9.13.jar:/usr/lib/hadoop-mapreduce/.//hadoop-archives-2.7.3.jar:/usr/lib/hadoop-mapreduce/.//htrace-core-3.1.0-incubating.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-common.jar:/usr/lib/hadoop-mapreduce/.//paranamer-2.3.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-jobclient-2.7.3.jar:/usr/lib/hadoop-mapreduce/.//hadoop-extras.jar:/usr/lib/hadoop-mapreduce/.//xmlenc-0.52.jar:/usr/lib/hadoop-mapreduce/.//hadoop-openstack-2.7.3.jar:/usr/lib/hadoop-mapreduce/.//jaxb-impl-2.2.3-1.jar:/usr/lib/hadoop-mapreduce/.//commons-beanutils-core-1.8.0.jar:/usr/lib/hadoop-mapreduce/.//jersey-server-1.9.jar:/usr/lib/hadoop-mapreduce/.//jsp-api-2.1.jar:/usr/lib/hadoop-mapreduce/.//jetty-6.1.26.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-hs-plugins-2.7.3.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-examples.jar:/usr/lib/hadoop-mapreduce/.//junit-4.11.jar:/usr/lib/hadoop-mapreduce/.//hadoop-azure.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-shuffle.jar:/usr/lib/hadoop-mapreduce/.//hadoop-streaming.jar:/usr/lib/hadoop-mapreduce/.//hadoop-ant-2.7.3.jar:/usr/lib/hadoop-mapreduce/.//servlet-api-2.5.jar:/usr/lib/hadoop-mapreduce/.//httpcore-4.2.5.jar:/usr/lib/hadoop-mapreduce/.//hadoop-rumen-2.7.3.jar:/usr/lib/hadoop-mapreduce/.//protobuf-java-2.5.0.jar:/usr/lib/hadoop-mapreduce/.//jersey-core-1.9.jar:/usr/lib/hadoop-mapreduce/.//stax-api-1.0-2.jar:/usr/lib/hadoop-mapreduce/.//commons-collections-3.2.2.jar:/usr/lib/hadoop/contrib/capacity-scheduler/*.jar:/usr/lib/hadoop/contrib/capacity-scheduler/*.jar:/usr/lib/hadoop/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/bigtop.git -r 2365207dc0440bb884e41d4ffe32a37ad0d0ed28; compiled by 'jenkins' on 2017-10-05T21:00Z
STARTUP_MSG:   java = 1.8.0_181
************************************************************/
2018-10-21 17:45:18,547 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2018-10-21 17:45:18,552 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: createNameNode []
2018-10-21 17:45:18,825 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2018-10-21 17:45:18,903 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2018-10-21 17:45:18,904 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NameNode metrics system started
2018-10-21 17:45:18,907 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: fs.defaultFS is hdfs://bootcamp.local:9000
2018-10-21 17:45:18,908 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Clients are to use bootcamp.local:9000 to access this namenode/service.
2018-10-21 17:45:19,067 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for hdfs at: http://0.0.0.0:50070
2018-10-21 17:45:19,144 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2018-10-21 17:45:19,151 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2018-10-21 17:45:19,157 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.namenode is not defined
2018-10-21 17:45:19,165 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2018-10-21 17:45:19,167 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2018-10-21 17:45:19,168 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2018-10-21 17:45:19,168 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2018-10-21 17:45:19,314 INFO org.apache.hadoop.http.HttpServer2: Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2018-10-21 17:45:19,317 INFO org.apache.hadoop.http.HttpServer2: addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2018-10-21 17:45:19,335 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50070
2018-10-21 17:45:19,335 INFO org.mortbay.log: jetty-6.1.26
2018-10-21 17:45:19,491 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:50070
2018-10-21 17:45:19,536 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one image storage directory (dfs.namenode.name.dir) configured. Beware of data loss due to lack of redundant storage directories!
2018-10-21 17:45:19,536 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one namespace edits storage directory (dfs.namenode.edits.dir) configured. Beware of data loss due to lack of redundant storage directories!
2018-10-21 17:45:19,591 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: No KeyProvider found.
2018-10-21 17:45:19,591 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair:true
2018-10-21 17:45:19,675 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2018-10-21 17:45:19,676 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2018-10-21 17:45:19,677 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2018-10-21 17:45:19,677 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2018 Oct 21 17:45:19
2018-10-21 17:45:19,679 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2018-10-21 17:45:19,679 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2018-10-21 17:45:19,682 INFO org.apache.hadoop.util.GSet: 2.0% max memory 889 MB = 17.8 MB
2018-10-21 17:45:19,682 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2018-10-21 17:45:19,688 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2018-10-21 17:45:19,689 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 1
2018-10-21 17:45:19,689 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2018-10-21 17:45:19,690 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2018-10-21 17:45:19,690 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2018-10-21 17:45:19,690 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2018-10-21 17:45:19,691 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2018-10-21 17:45:19,691 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2018-10-21 17:45:19,698 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = hdfs (auth:SIMPLE)
2018-10-21 17:45:19,698 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2018-10-21 17:45:19,699 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2018-10-21 17:45:19,699 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2018-10-21 17:45:19,700 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2018-10-21 17:45:19,766 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2018-10-21 17:45:19,766 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2018-10-21 17:45:19,767 INFO org.apache.hadoop.util.GSet: 1.0% max memory 889 MB = 8.9 MB
2018-10-21 17:45:19,767 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2018-10-21 17:45:19,768 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: ACLs enabled? false
2018-10-21 17:45:19,769 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: XAttrs enabled? true
2018-10-21 17:45:19,769 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Maximum size of an xattr: 16384
2018-10-21 17:45:19,770 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times
2018-10-21 17:45:19,777 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2018-10-21 17:45:19,777 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2018-10-21 17:45:19,777 INFO org.apache.hadoop.util.GSet: 0.25% max memory 889 MB = 2.2 MB
2018-10-21 17:45:19,778 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2018-10-21 17:45:19,779 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2018-10-21 17:45:19,780 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2018-10-21 17:45:19,780 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2018-10-21 17:45:19,783 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.window.num.buckets = 10
2018-10-21 17:45:19,784 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.num.users = 10
2018-10-21 17:45:19,784 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2018-10-21 17:45:19,785 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache on namenode is enabled
2018-10-21 17:45:19,786 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2018-10-21 17:45:19,788 INFO org.apache.hadoop.util.GSet: Computing capacity for map NameNodeRetryCache
2018-10-21 17:45:19,789 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2018-10-21 17:45:19,789 INFO org.apache.hadoop.util.GSet: 0.029999999329447746% max memory 889 MB = 273.1 KB
2018-10-21 17:45:19,789 INFO org.apache.hadoop.util.GSet: capacity      = 2^15 = 32768 entries
2018-10-21 17:45:19,803 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /data/name/in_use.lock acquired by nodename 744@bootcamp.local
2018-10-21 17:45:19,842 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Recovering unfinalized segments in /data/name/current
2018-10-21 17:45:20,010 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /data/name/current/edits_inprogress_0000000000000000476 -> /data/name/current/edits_0000000000000000476-0000000000000000565
2018-10-21 17:45:20,018 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Planning to load image: FSImageFile(file=/data/name/current/fsimage_0000000000000000475, cpktTxId=0000000000000000475)
2018-10-21 17:45:20,049 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Loading 70 INodes.
2018-10-21 17:45:20,088 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Loaded FSImage in 0 seconds.
2018-10-21 17:45:20,089 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 475 from /data/name/current/fsimage_0000000000000000475
2018-10-21 17:45:20,089 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@2262b621 expecting start txid #476
2018-10-21 17:45:20,090 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /data/name/current/edits_0000000000000000476-0000000000000000565
2018-10-21 17:45:20,092 INFO org.apache.hadoop.hdfs.server.namenode.EditLogInputStream: Fast-forwarding stream '/data/name/current/edits_0000000000000000476-0000000000000000565' to transaction ID 476
2018-10-21 17:45:20,134 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /data/name/current/edits_0000000000000000476-0000000000000000565 of size 1048576 edits # 90 loaded in 0 seconds
2018-10-21 17:45:20,135 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Need to save fs image? true (staleImage=true, haEnabled=false, isRollingUpgrade=false)
2018-10-21 17:45:20,136 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Save namespace ...
2018-10-21 17:45:20,142 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /data/name/current/fsimage.ckpt_0000000000000000565 using no compression
2018-10-21 17:45:20,183 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /data/name/current/fsimage.ckpt_0000000000000000565 of size 5209 bytes saved in 0 seconds.
2018-10-21 17:45:20,189 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 475
2018-10-21 17:45:20,190 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/data/name/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2018-10-21 17:45:20,201 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 566
2018-10-21 17:45:20,306 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2018-10-21 17:45:20,307 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Finished loading FSImage in 515 msecs
2018-10-21 17:45:20,540 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: RPC server is binding to bootcamp.local:9000
2018-10-21 17:45:20,546 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2018-10-21 17:45:20,556 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 9000
2018-10-21 17:45:20,578 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Registered FSNamesystemState MBean
2018-10-21 17:45:20,588 INFO org.apache.hadoop.hdfs.server.namenode.LeaseManager: Number of blocks under construction: 0
2018-10-21 17:45:20,588 INFO org.apache.hadoop.hdfs.server.namenode.LeaseManager: Number of blocks under construction: 0
2018-10-21 17:45:20,589 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode ON. 
The reported blocks 0 needs additional 23 blocks to reach the threshold 0.9990 of total blocks 23.
The number of live datanodes 0 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached.
2018-10-21 17:45:20,594 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Number of failed storage changes from 0 to 0
2018-10-21 17:45:20,622 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2018-10-21 17:45:20,623 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 9000: starting
2018-10-21 17:45:20,628 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: NameNode RPC up at: bootcamp.local/172.18.0.2:9000
2018-10-21 17:45:20,628 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Starting services required for active state
2018-10-21 17:45:20,635 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Starting CacheReplicationMonitor with interval 30000 milliseconds
2018-10-21 17:45:29,596 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(172.18.0.2:50010, datanodeUuid=47ecd31e-43cd-4989-84ba-314b1664d0de, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-747ab8c6-1ec4-46a0-9dee-c8151846aca5;nsid=199960936;c=0) storage 47ecd31e-43cd-4989-84ba-314b1664d0de
2018-10-21 17:45:29,597 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Number of failed storage changes from 0 to 0
2018-10-21 17:45:29,598 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/172.18.0.2:50010
2018-10-21 17:45:29,691 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Number of failed storage changes from 0 to 0
2018-10-21 17:45:29,692 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Adding new storage ID DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5 for DN 172.18.0.2:50010
2018-10-21 17:45:29,744 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode extension entered. 
The reported blocks 22 has reached the threshold 0.9990 of total blocks 23. The number of live datanodes 1 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 29 seconds.
2018-10-21 17:45:29,744 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: initializing replication queues
2018-10-21 17:45:29,746 INFO BlockStateChange: BLOCK* processReport: from storage DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5 node DatanodeRegistration(172.18.0.2:50010, datanodeUuid=47ecd31e-43cd-4989-84ba-314b1664d0de, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-747ab8c6-1ec4-46a0-9dee-c8151846aca5;nsid=199960936;c=0), blocks: 23, hasStaleStorage: false, processing time: 8 msecs
2018-10-21 17:45:29,750 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Total number of blocks            = 23
2018-10-21 17:45:29,750 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of invalid blocks          = 0
2018-10-21 17:45:29,751 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of under-replicated blocks = 0
2018-10-21 17:45:29,751 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of  over-replicated blocks = 0
2018-10-21 17:45:29,751 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of blocks being written    = 0
2018-10-21 17:45:29,752 INFO org.apache.hadoop.hdfs.StateChange: STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 7 msec
2018-10-21 17:45:50,736 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode ON, in safe mode extension. 
The reported blocks 23 has reached the threshold 0.9990 of total blocks 23. The number of live datanodes 1 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 8 seconds.
2018-10-21 17:45:59,748 INFO org.apache.hadoop.hdfs.StateChange: STATE* Leaving safe mode after 40 secs
2018-10-21 17:45:59,751 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode is OFF
2018-10-21 17:45:59,751 INFO org.apache.hadoop.hdfs.StateChange: STATE* Network topology has 1 racks and 1 datanodes
2018-10-21 17:45:59,752 INFO org.apache.hadoop.hdfs.StateChange: STATE* UnderReplicatedBlocks has 0 blocks
2018-10-21 17:46:07,499 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741878_1056{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /app/hbase/WALs/bootcamp.local,16020,1540143951274/bootcamp.local%2C16020%2C1540143951274.default.1540143967424
2018-10-21 17:46:07,652 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* fsync: /app/hbase/WALs/bootcamp.local,16020,1540143951274/bootcamp.local%2C16020%2C1540143951274.default.1540143967424 for DFSClient_NONMAPREDUCE_187792693_1
2018-10-21 17:46:10,245 INFO org.apache.hadoop.ipc.Server: IPC Server handler 3 on 9000, call org.apache.hadoop.hdfs.protocol.ClientProtocol.delete from 172.18.0.2:48244 Call#53 Retry#0
org.apache.hadoop.fs.PathIsNotEmptyDirectoryException: `/app/hbase/WALs/bootcamp.local,16020,1539829260266-splitting is non empty': Directory is not empty
	at org.apache.hadoop.hdfs.server.namenode.FSDirDeleteOp.delete(FSDirDeleteOp.java:85)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:3714)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.delete(NameNodeRpcServer.java:953)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.delete(ClientNamenodeProtocolServerSideTranslatorPB.java:611)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2049)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2045)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2045)
2018-10-21 17:46:10,348 INFO org.apache.hadoop.ipc.Server: IPC Server handler 5 on 9000, call org.apache.hadoop.hdfs.protocol.ClientProtocol.delete from 172.18.0.2:48244 Call#60 Retry#0
org.apache.hadoop.fs.PathIsNotEmptyDirectoryException: `/app/hbase/WALs/bootcamp.local,16020,1539829260266-splitting is non empty': Directory is not empty
	at org.apache.hadoop.hdfs.server.namenode.FSDirDeleteOp.delete(FSDirDeleteOp.java:85)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:3714)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.delete(NameNodeRpcServer.java:953)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.delete(ClientNamenodeProtocolServerSideTranslatorPB.java:611)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2049)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2045)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2045)
2018-10-21 17:46:10,439 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741879_1057{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /app/hbase/WALs/bootcamp.local,16020,1540143951274/bootcamp.local%2C16020%2C1540143951274..meta.1540143970423.meta
2018-10-21 17:46:10,458 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* fsync: /app/hbase/WALs/bootcamp.local,16020,1540143951274/bootcamp.local%2C16020%2C1540143951274..meta.1540143970423.meta for DFSClient_NONMAPREDUCE_187792693_1
2018-10-21 17:46:10,785 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /app/hbase/data/hbase/meta/1588230740/recovered.edits/15.seqid is closed by DFSClient_NONMAPREDUCE_187792693_1
2018-10-21 17:46:11,183 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /app/hbase/data/hbase/namespace/b7bfc7fcc5816946e33ea9db3ddeebfa/recovered.edits/9.seqid is closed by DFSClient_NONMAPREDUCE_187792693_1
2018-10-21 17:46:17,730 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741880_1058{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /app/hbase/data/hbase/meta/1588230740/.tmp/dcf576e74c6042c0addec480cdedb545
2018-10-21 17:46:17,747 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741880_1058{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 0
2018-10-21 17:46:17,749 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /app/hbase/data/hbase/meta/1588230740/.tmp/dcf576e74c6042c0addec480cdedb545 is closed by DFSClient_NONMAPREDUCE_187792693_1
2018-10-21 17:51:33,342 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 57 Total time for transactions(ms): 5 Number of transactions batched in Syncs: 10 Number of syncs: 38 SyncTimes(ms): 50 
2018-10-21 17:51:33,351 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741881_1059{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /app/hbase/data/hbase/meta/1588230740/.tmp/6f0c741b6a374c6fa6dffe28730b4823
2018-10-21 17:51:33,362 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741881_1059{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 0
2018-10-21 17:51:33,364 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /app/hbase/data/hbase/meta/1588230740/.tmp/6f0c741b6a374c6fa6dffe28730b4823 is closed by DFSClient_NONMAPREDUCE_187792693_1
2018-10-21 17:52:05,252 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741874_1052 172.18.0.2:50010 
2018-10-21 17:52:05,256 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741834_1010 172.18.0.2:50010 
2018-10-21 17:52:05,429 INFO BlockStateChange: BLOCK* BlockManager: ask 172.18.0.2:50010 to delete [blk_1073741874_1052, blk_1073741834_1010]
2018-10-21 17:57:05,027 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 70 Total time for transactions(ms): 5 Number of transactions batched in Syncs: 10 Number of syncs: 49 SyncTimes(ms): 58 
2018-10-21 17:57:05,033 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741876_1054 172.18.0.2:50010 
2018-10-21 17:57:05,042 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741875_1053 172.18.0.2:50010 
2018-10-21 17:57:05,311 INFO BlockStateChange: BLOCK* BlockManager: ask 172.18.0.2:50010 to delete [blk_1073741875_1053, blk_1073741876_1054]
2018-10-21 18:20:17,281 INFO BlockStateChange: BLOCK* processReport: from storage DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5 node DatanodeRegistration(172.18.0.2:50010, datanodeUuid=47ecd31e-43cd-4989-84ba-314b1664d0de, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-747ab8c6-1ec4-46a0-9dee-c8151846aca5;nsid=199960936;c=0), blocks: 23, hasStaleStorage: false, processing time: 74 msecs
2018-10-21 18:45:55,386 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 72 Total time for transactions(ms): 8 Number of transactions batched in Syncs: 10 Number of syncs: 51 SyncTimes(ms): 61 
2018-10-21 18:45:55,407 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741882_1060{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /app/hbase/WALs/bootcamp.local,16020,1540143951274/bootcamp.local%2C16020%2C1540143951274.default.1540147555360
2018-10-21 18:45:55,510 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* fsync: /app/hbase/WALs/bootcamp.local,16020,1540143951274/bootcamp.local%2C16020%2C1540143951274.default.1540147555360 for DFSClient_NONMAPREDUCE_187792693_1
2018-10-21 18:45:55,549 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741878_1056{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 83
2018-10-21 18:45:55,554 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /app/hbase/WALs/bootcamp.local,16020,1540143951274/bootcamp.local%2C16020%2C1540143951274.default.1540143967424 is closed by DFSClient_NONMAPREDUCE_187792693_1
2018-10-21 18:46:18,066 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741883_1061{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /app/hbase/WALs/bootcamp.local,16020,1540143951274/bootcamp.local%2C16020%2C1540143951274..meta.1540147578052.meta
2018-10-21 18:46:18,098 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* fsync: /app/hbase/WALs/bootcamp.local,16020,1540143951274/bootcamp.local%2C16020%2C1540143951274..meta.1540147578052.meta for DFSClient_NONMAPREDUCE_187792693_1
2018-10-21 18:46:18,114 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741879_1057{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 83
2018-10-21 18:46:18,116 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /app/hbase/WALs/bootcamp.local,16020,1540143951274/bootcamp.local%2C16020%2C1540143951274..meta.1540143970423.meta is closed by DFSClient_NONMAPREDUCE_187792693_1
2018-10-21 18:56:02,391 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 88 Total time for transactions(ms): 14 Number of transactions batched in Syncs: 10 Number of syncs: 63 SyncTimes(ms): 87 
2018-10-21 18:56:02,404 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741878_1056 172.18.0.2:50010 
2018-10-21 18:56:04,492 INFO BlockStateChange: BLOCK* BlockManager: ask 172.18.0.2:50010 to delete [blk_1073741878_1056]
2018-10-21 18:57:02,334 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741879_1057 172.18.0.2:50010 
2018-10-21 18:57:04,466 INFO BlockStateChange: BLOCK* BlockManager: ask 172.18.0.2:50010 to delete [blk_1073741879_1057]
2018-10-21 19:46:03,307 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 90 Total time for transactions(ms): 19 Number of transactions batched in Syncs: 10 Number of syncs: 65 SyncTimes(ms): 91 
2018-10-21 19:46:03,361 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741884_1062{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /app/hbase/WALs/bootcamp.local,16020,1540143951274/bootcamp.local%2C16020%2C1540143951274.default.1540151163247
2018-10-21 19:46:03,406 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* fsync: /app/hbase/WALs/bootcamp.local,16020,1540143951274/bootcamp.local%2C16020%2C1540143951274.default.1540151163247 for DFSClient_NONMAPREDUCE_187792693_1
2018-10-21 19:46:03,431 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* blk_1073741882_1060{UCState=COMMITTED, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} is not COMPLETE (ucState = COMMITTED, replication# = 0 <  minimum = 1) in file /app/hbase/WALs/bootcamp.local,16020,1540143951274/bootcamp.local%2C16020%2C1540143951274.default.1540147555360
2018-10-21 19:46:03,432 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741882_1060{UCState=COMMITTED, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 91
2018-10-21 19:46:03,841 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /app/hbase/WALs/bootcamp.local,16020,1540143951274/bootcamp.local%2C16020%2C1540143951274.default.1540147555360 is closed by DFSClient_NONMAPREDUCE_187792693_1
2018-10-21 19:46:25,863 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741885_1063{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /app/hbase/WALs/bootcamp.local,16020,1540143951274/bootcamp.local%2C16020%2C1540143951274..meta.1540151185834.meta
2018-10-21 19:46:25,910 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* fsync: /app/hbase/WALs/bootcamp.local,16020,1540143951274/bootcamp.local%2C16020%2C1540143951274..meta.1540151185834.meta for DFSClient_NONMAPREDUCE_187792693_1
2018-10-21 19:46:25,919 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741883_1061{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 83
2018-10-21 19:46:25,921 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /app/hbase/WALs/bootcamp.local,16020,1540143951274/bootcamp.local%2C16020%2C1540143951274..meta.1540147578052.meta is closed by DFSClient_NONMAPREDUCE_187792693_1
2018-10-21 19:56:59,676 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 106 Total time for transactions(ms): 21 Number of transactions batched in Syncs: 11 Number of syncs: 77 SyncTimes(ms): 109 
2018-10-21 19:56:59,684 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741883_1061 172.18.0.2:50010 
2018-10-21 19:56:59,690 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741882_1060 172.18.0.2:50010 
2018-10-21 19:56:59,859 INFO BlockStateChange: BLOCK* BlockManager: ask 172.18.0.2:50010 to delete [blk_1073741882_1060, blk_1073741883_1061]
2018-10-21 20:46:11,693 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 108 Total time for transactions(ms): 24 Number of transactions batched in Syncs: 11 Number of syncs: 79 SyncTimes(ms): 112 
2018-10-21 20:46:11,738 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741886_1064{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /app/hbase/WALs/bootcamp.local,16020,1540143951274/bootcamp.local%2C16020%2C1540143951274.default.1540154771641
2018-10-21 20:46:11,871 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* fsync: /app/hbase/WALs/bootcamp.local,16020,1540143951274/bootcamp.local%2C16020%2C1540143951274.default.1540154771641 for DFSClient_NONMAPREDUCE_187792693_1
2018-10-21 20:46:11,918 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* blk_1073741884_1062{UCState=COMMITTED, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} is not COMPLETE (ucState = COMMITTED, replication# = 0 <  minimum = 1) in file /app/hbase/WALs/bootcamp.local,16020,1540143951274/bootcamp.local%2C16020%2C1540143951274.default.1540151163247
2018-10-21 20:46:11,934 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741884_1062{UCState=COMMITTED, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 91
2018-10-21 20:46:12,327 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /app/hbase/WALs/bootcamp.local,16020,1540143951274/bootcamp.local%2C16020%2C1540143951274.default.1540151163247 is closed by DFSClient_NONMAPREDUCE_187792693_1
2018-10-21 20:46:33,647 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741887_1065{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /app/hbase/WALs/bootcamp.local,16020,1540143951274/bootcamp.local%2C16020%2C1540143951274..meta.1540154793614.meta
2018-10-21 20:46:33,669 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* fsync: /app/hbase/WALs/bootcamp.local,16020,1540143951274/bootcamp.local%2C16020%2C1540143951274..meta.1540154793614.meta for DFSClient_NONMAPREDUCE_187792693_1
2018-10-21 20:46:33,690 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741885_1063{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 83
2018-10-21 20:46:33,722 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /app/hbase/WALs/bootcamp.local,16020,1540143951274/bootcamp.local%2C16020%2C1540143951274..meta.1540151185834.meta is closed by DFSClient_NONMAPREDUCE_187792693_1
2018-10-21 20:56:56,984 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 124 Total time for transactions(ms): 27 Number of transactions batched in Syncs: 12 Number of syncs: 91 SyncTimes(ms): 138 
2018-10-21 20:56:56,989 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741885_1063 172.18.0.2:50010 
2018-10-21 20:56:56,994 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741884_1062 172.18.0.2:50010 
2018-10-21 20:56:58,462 INFO BlockStateChange: BLOCK* BlockManager: ask 172.18.0.2:50010 to delete [blk_1073741884_1062, blk_1073741885_1063]
2018-10-21 21:02:33,571 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 2405ms
No GCs detected
2018-10-21 21:46:12,544 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 126 Total time for transactions(ms): 30 Number of transactions batched in Syncs: 12 Number of syncs: 93 SyncTimes(ms): 140 
2018-10-21 21:46:12,578 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741888_1066{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /app/hbase/WALs/bootcamp.local,16020,1540143951274/bootcamp.local%2C16020%2C1540143951274.default.1540158372517
2018-10-21 21:46:12,627 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* fsync: /app/hbase/WALs/bootcamp.local,16020,1540143951274/bootcamp.local%2C16020%2C1540143951274.default.1540158372517 for DFSClient_NONMAPREDUCE_187792693_1
2018-10-21 21:46:12,655 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* blk_1073741886_1064{UCState=COMMITTED, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} is not COMPLETE (ucState = COMMITTED, replication# = 0 <  minimum = 1) in file /app/hbase/WALs/bootcamp.local,16020,1540143951274/bootcamp.local%2C16020%2C1540143951274.default.1540154771641
2018-10-21 21:46:12,661 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741886_1064{UCState=COMMITTED, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 91
2018-10-21 21:46:13,089 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /app/hbase/WALs/bootcamp.local,16020,1540143951274/bootcamp.local%2C16020%2C1540143951274.default.1540154771641 is closed by DFSClient_NONMAPREDUCE_187792693_1
2018-10-21 21:46:33,952 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741889_1067{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /app/hbase/WALs/bootcamp.local,16020,1540143951274/bootcamp.local%2C16020%2C1540143951274..meta.1540158393933.meta
2018-10-21 21:46:33,972 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* fsync: /app/hbase/WALs/bootcamp.local,16020,1540143951274/bootcamp.local%2C16020%2C1540143951274..meta.1540158393933.meta for DFSClient_NONMAPREDUCE_187792693_1
2018-10-21 21:46:33,985 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741887_1065{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 83
2018-10-21 21:46:33,989 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /app/hbase/WALs/bootcamp.local,16020,1540143951274/bootcamp.local%2C16020%2C1540143951274..meta.1540154793614.meta is closed by DFSClient_NONMAPREDUCE_187792693_1
2018-10-21 21:56:56,314 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 142 Total time for transactions(ms): 31 Number of transactions batched in Syncs: 13 Number of syncs: 105 SyncTimes(ms): 157 
2018-10-21 21:56:56,320 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741887_1065 172.18.0.2:50010 
2018-10-21 21:56:56,331 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741886_1064 172.18.0.2:50010 
2018-10-21 21:56:56,843 INFO BlockStateChange: BLOCK* BlockManager: ask 172.18.0.2:50010 to delete [blk_1073741886_1064, blk_1073741887_1065]
2018-10-21 22:46:19,369 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 144 Total time for transactions(ms): 32 Number of transactions batched in Syncs: 13 Number of syncs: 107 SyncTimes(ms): 159 
2018-10-21 22:46:19,382 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741890_1068{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /app/hbase/WALs/bootcamp.local,16020,1540143951274/bootcamp.local%2C16020%2C1540143951274.default.1540161979349
2018-10-21 22:46:19,410 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* fsync: /app/hbase/WALs/bootcamp.local,16020,1540143951274/bootcamp.local%2C16020%2C1540143951274.default.1540161979349 for DFSClient_NONMAPREDUCE_187792693_1
2018-10-21 22:46:19,423 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741888_1066{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 83
2018-10-21 22:46:19,436 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /app/hbase/WALs/bootcamp.local,16020,1540143951274/bootcamp.local%2C16020%2C1540143951274.default.1540158372517 is closed by DFSClient_NONMAPREDUCE_187792693_1
2018-10-21 22:46:40,270 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741891_1069{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /app/hbase/WALs/bootcamp.local,16020,1540143951274/bootcamp.local%2C16020%2C1540143951274..meta.1540162000239.meta
2018-10-21 22:46:40,282 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* fsync: /app/hbase/WALs/bootcamp.local,16020,1540143951274/bootcamp.local%2C16020%2C1540143951274..meta.1540162000239.meta for DFSClient_NONMAPREDUCE_187792693_1
2018-10-21 22:46:40,300 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741889_1067{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 83
2018-10-21 22:46:40,304 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /app/hbase/WALs/bootcamp.local,16020,1540143951274/bootcamp.local%2C16020%2C1540143951274..meta.1540158393933.meta is closed by DFSClient_NONMAPREDUCE_187792693_1
2018-10-21 22:56:52,055 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 160 Total time for transactions(ms): 32 Number of transactions batched in Syncs: 13 Number of syncs: 119 SyncTimes(ms): 183 
2018-10-21 22:56:52,059 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741889_1067 172.18.0.2:50010 
2018-10-21 22:56:52,068 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741888_1066 172.18.0.2:50010 
2018-10-21 22:56:54,082 INFO BlockStateChange: BLOCK* BlockManager: ask 172.18.0.2:50010 to delete [blk_1073741888_1066, blk_1073741889_1067]
2018-10-21 23:46:25,567 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 162 Total time for transactions(ms): 33 Number of transactions batched in Syncs: 13 Number of syncs: 121 SyncTimes(ms): 186 
2018-10-21 23:46:25,578 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741892_1070{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /app/hbase/WALs/bootcamp.local,16020,1540143951274/bootcamp.local%2C16020%2C1540143951274.default.1540165585551
2018-10-21 23:46:25,600 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* fsync: /app/hbase/WALs/bootcamp.local,16020,1540143951274/bootcamp.local%2C16020%2C1540143951274.default.1540165585551 for DFSClient_NONMAPREDUCE_187792693_1
2018-10-21 23:46:25,619 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741890_1068{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 83
2018-10-21 23:46:25,626 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /app/hbase/WALs/bootcamp.local,16020,1540143951274/bootcamp.local%2C16020%2C1540143951274.default.1540161979349 is closed by DFSClient_NONMAPREDUCE_187792693_1
2018-10-21 23:46:46,489 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741893_1071{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /app/hbase/WALs/bootcamp.local,16020,1540143951274/bootcamp.local%2C16020%2C1540143951274..meta.1540165606462.meta
2018-10-21 23:46:46,505 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* fsync: /app/hbase/WALs/bootcamp.local,16020,1540143951274/bootcamp.local%2C16020%2C1540143951274..meta.1540165606462.meta for DFSClient_NONMAPREDUCE_187792693_1
2018-10-21 23:46:46,514 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741891_1069{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 83
2018-10-21 23:46:46,518 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /app/hbase/WALs/bootcamp.local,16020,1540143951274/bootcamp.local%2C16020%2C1540143951274..meta.1540162000239.meta is closed by DFSClient_NONMAPREDUCE_187792693_1
2018-10-21 23:56:47,852 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 178 Total time for transactions(ms): 35 Number of transactions batched in Syncs: 13 Number of syncs: 133 SyncTimes(ms): 202 
2018-10-21 23:56:47,857 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741891_1069 172.18.0.2:50010 
2018-10-21 23:56:47,865 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741890_1068 172.18.0.2:50010 
2018-10-21 23:56:48,480 INFO BlockStateChange: BLOCK* BlockManager: ask 172.18.0.2:50010 to delete [blk_1073741890_1068, blk_1073741891_1069]
2018-10-22 00:19:59,999 INFO BlockStateChange: BLOCK* processReport: from storage DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5 node DatanodeRegistration(172.18.0.2:50010, datanodeUuid=47ecd31e-43cd-4989-84ba-314b1664d0de, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-747ab8c6-1ec4-46a0-9dee-c8151846aca5;nsid=199960936;c=0), blocks: 23, hasStaleStorage: false, processing time: 4 msecs
2018-10-22 00:46:32,314 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 180 Total time for transactions(ms): 35 Number of transactions batched in Syncs: 13 Number of syncs: 135 SyncTimes(ms): 205 
2018-10-22 00:46:32,321 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741894_1072{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /app/hbase/WALs/bootcamp.local,16020,1540143951274/bootcamp.local%2C16020%2C1540143951274.default.1540169192309
2018-10-22 00:46:32,340 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* fsync: /app/hbase/WALs/bootcamp.local,16020,1540143951274/bootcamp.local%2C16020%2C1540143951274.default.1540169192309 for DFSClient_NONMAPREDUCE_187792693_1
2018-10-22 00:46:32,349 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741892_1070{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 83
2018-10-22 00:46:32,351 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /app/hbase/WALs/bootcamp.local,16020,1540143951274/bootcamp.local%2C16020%2C1540143951274.default.1540165585551 is closed by DFSClient_NONMAPREDUCE_187792693_1
2018-10-22 00:46:53,185 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741895_1073{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /app/hbase/WALs/bootcamp.local,16020,1540143951274/bootcamp.local%2C16020%2C1540143951274..meta.1540169213169.meta
2018-10-22 00:46:53,205 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* fsync: /app/hbase/WALs/bootcamp.local,16020,1540143951274/bootcamp.local%2C16020%2C1540143951274..meta.1540169213169.meta for DFSClient_NONMAPREDUCE_187792693_1
2018-10-22 00:46:53,213 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741893_1071{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 83
2018-10-22 00:46:53,215 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /app/hbase/WALs/bootcamp.local,16020,1540143951274/bootcamp.local%2C16020%2C1540143951274..meta.1540165606462.meta is closed by DFSClient_NONMAPREDUCE_187792693_1
2018-10-22 00:56:43,576 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 196 Total time for transactions(ms): 36 Number of transactions batched in Syncs: 13 Number of syncs: 147 SyncTimes(ms): 223 
2018-10-22 00:56:43,578 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741892_1070 172.18.0.2:50010 
2018-10-22 00:56:44,119 INFO BlockStateChange: BLOCK* BlockManager: ask 172.18.0.2:50010 to delete [blk_1073741892_1070]
2018-10-22 00:57:43,507 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 197 Total time for transactions(ms): 36 Number of transactions batched in Syncs: 13 Number of syncs: 148 SyncTimes(ms): 224 
2018-10-22 00:57:43,510 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741893_1071 172.18.0.2:50010 
2018-10-22 00:57:44,097 INFO BlockStateChange: BLOCK* BlockManager: ask 172.18.0.2:50010 to delete [blk_1073741893_1071]
2018-10-22 01:46:39,145 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 198 Total time for transactions(ms): 36 Number of transactions batched in Syncs: 13 Number of syncs: 149 SyncTimes(ms): 225 
2018-10-22 01:46:39,150 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741896_1074{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /app/hbase/WALs/bootcamp.local,16020,1540143951274/bootcamp.local%2C16020%2C1540143951274.default.1540172799138
2018-10-22 01:46:39,161 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* fsync: /app/hbase/WALs/bootcamp.local,16020,1540143951274/bootcamp.local%2C16020%2C1540143951274.default.1540172799138 for DFSClient_NONMAPREDUCE_187792693_1
2018-10-22 01:46:39,172 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741894_1072{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 83
2018-10-22 01:46:39,174 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /app/hbase/WALs/bootcamp.local,16020,1540143951274/bootcamp.local%2C16020%2C1540143951274.default.1540169192309 is closed by DFSClient_NONMAPREDUCE_187792693_1
2018-10-22 01:46:59,945 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741897_1075{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /app/hbase/WALs/bootcamp.local,16020,1540143951274/bootcamp.local%2C16020%2C1540143951274..meta.1540172819922.meta
2018-10-22 01:46:59,960 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* fsync: /app/hbase/WALs/bootcamp.local,16020,1540143951274/bootcamp.local%2C16020%2C1540143951274..meta.1540172819922.meta for DFSClient_NONMAPREDUCE_187792693_1
2018-10-22 01:46:59,971 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741895_1073{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 83
2018-10-22 01:46:59,974 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /app/hbase/WALs/bootcamp.local,16020,1540143951274/bootcamp.local%2C16020%2C1540143951274..meta.1540169213169.meta is closed by DFSClient_NONMAPREDUCE_187792693_1
2018-10-22 01:56:39,295 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 214 Total time for transactions(ms): 36 Number of transactions batched in Syncs: 13 Number of syncs: 161 SyncTimes(ms): 239 
2018-10-22 01:56:39,297 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741894_1072 172.18.0.2:50010 
2018-10-22 01:56:39,975 INFO BlockStateChange: BLOCK* BlockManager: ask 172.18.0.2:50010 to delete [blk_1073741894_1072]
2018-10-22 01:57:39,223 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741895_1073 172.18.0.2:50010 
2018-10-22 01:57:39,942 INFO BlockStateChange: BLOCK* BlockManager: ask 172.18.0.2:50010 to delete [blk_1073741895_1073]
2018-10-22 02:46:45,586 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 216 Total time for transactions(ms): 39 Number of transactions batched in Syncs: 13 Number of syncs: 163 SyncTimes(ms): 241 
2018-10-22 02:46:45,604 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741898_1076{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /app/hbase/WALs/bootcamp.local,16020,1540143951274/bootcamp.local%2C16020%2C1540143951274.default.1540176405537
2018-10-22 02:46:45,668 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* fsync: /app/hbase/WALs/bootcamp.local,16020,1540143951274/bootcamp.local%2C16020%2C1540143951274.default.1540176405537 for DFSClient_NONMAPREDUCE_187792693_1
2018-10-22 02:46:45,700 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741896_1074{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 83
2018-10-22 02:46:45,729 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /app/hbase/WALs/bootcamp.local,16020,1540143951274/bootcamp.local%2C16020%2C1540143951274.default.1540172799138 is closed by DFSClient_NONMAPREDUCE_187792693_1
2018-10-22 02:47:06,381 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741899_1077{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /app/hbase/WALs/bootcamp.local,16020,1540143951274/bootcamp.local%2C16020%2C1540143951274..meta.1540176426362.meta
2018-10-22 02:47:06,407 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* fsync: /app/hbase/WALs/bootcamp.local,16020,1540143951274/bootcamp.local%2C16020%2C1540143951274..meta.1540176426362.meta for DFSClient_NONMAPREDUCE_187792693_1
2018-10-22 02:47:06,425 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741897_1075{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 83
2018-10-22 02:47:06,430 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /app/hbase/WALs/bootcamp.local,16020,1540143951274/bootcamp.local%2C16020%2C1540143951274..meta.1540172819922.meta is closed by DFSClient_NONMAPREDUCE_187792693_1
2018-10-22 02:57:34,954 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 232 Total time for transactions(ms): 41 Number of transactions batched in Syncs: 13 Number of syncs: 175 SyncTimes(ms): 261 
2018-10-22 02:57:34,958 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741897_1075 172.18.0.2:50010 
2018-10-22 02:57:34,962 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741896_1074 172.18.0.2:50010 
2018-10-22 02:57:37,734 INFO BlockStateChange: BLOCK* BlockManager: ask 172.18.0.2:50010 to delete [blk_1073741896_1074, blk_1073741897_1075]
2018-10-22 03:46:52,233 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 234 Total time for transactions(ms): 41 Number of transactions batched in Syncs: 13 Number of syncs: 177 SyncTimes(ms): 264 
2018-10-22 03:46:52,271 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741900_1078{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /app/hbase/WALs/bootcamp.local,16020,1540143951274/bootcamp.local%2C16020%2C1540143951274.default.1540180012167
2018-10-22 03:46:52,442 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* fsync: /app/hbase/WALs/bootcamp.local,16020,1540143951274/bootcamp.local%2C16020%2C1540143951274.default.1540180012167 for DFSClient_NONMAPREDUCE_187792693_1
2018-10-22 03:46:52,554 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741898_1076{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 83
2018-10-22 03:46:52,563 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /app/hbase/WALs/bootcamp.local,16020,1540143951274/bootcamp.local%2C16020%2C1540143951274.default.1540176405537 is closed by DFSClient_NONMAPREDUCE_187792693_1
2018-10-22 03:47:13,027 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741901_1079{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /app/hbase/WALs/bootcamp.local,16020,1540143951274/bootcamp.local%2C16020%2C1540143951274..meta.1540180032992.meta
2018-10-22 03:47:13,070 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* fsync: /app/hbase/WALs/bootcamp.local,16020,1540143951274/bootcamp.local%2C16020%2C1540143951274..meta.1540180032992.meta for DFSClient_NONMAPREDUCE_187792693_1
2018-10-22 03:47:13,109 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741899_1077{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 83
2018-10-22 03:47:13,118 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /app/hbase/WALs/bootcamp.local,16020,1540143951274/bootcamp.local%2C16020%2C1540143951274..meta.1540176426362.meta is closed by DFSClient_NONMAPREDUCE_187792693_1
2018-10-22 03:57:30,708 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 250 Total time for transactions(ms): 50 Number of transactions batched in Syncs: 13 Number of syncs: 189 SyncTimes(ms): 312 
2018-10-22 03:57:30,715 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741899_1077 172.18.0.2:50010 
2018-10-22 03:57:30,718 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741898_1076 172.18.0.2:50010 
2018-10-22 03:57:32,214 INFO BlockStateChange: BLOCK* BlockManager: ask 172.18.0.2:50010 to delete [blk_1073741898_1076, blk_1073741899_1077]
2018-10-22 04:46:58,992 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 252 Total time for transactions(ms): 50 Number of transactions batched in Syncs: 13 Number of syncs: 191 SyncTimes(ms): 314 
2018-10-22 04:46:59,154 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741902_1080{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /app/hbase/WALs/bootcamp.local,16020,1540143951274/bootcamp.local%2C16020%2C1540143951274.default.1540183618937
2018-10-22 04:46:59,216 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* fsync: /app/hbase/WALs/bootcamp.local,16020,1540143951274/bootcamp.local%2C16020%2C1540143951274.default.1540183618937 for DFSClient_NONMAPREDUCE_187792693_1
2018-10-22 04:46:59,240 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* blk_1073741900_1078{UCState=COMMITTED, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} is not COMPLETE (ucState = COMMITTED, replication# = 0 <  minimum = 1) in file /app/hbase/WALs/bootcamp.local,16020,1540143951274/bootcamp.local%2C16020%2C1540143951274.default.1540180012167
2018-10-22 04:46:59,249 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741900_1078{UCState=COMMITTED, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 91
2018-10-22 04:46:59,647 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /app/hbase/WALs/bootcamp.local,16020,1540143951274/bootcamp.local%2C16020%2C1540143951274.default.1540180012167 is closed by DFSClient_NONMAPREDUCE_187792693_1
2018-10-22 04:47:19,345 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741903_1081{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /app/hbase/WALs/bootcamp.local,16020,1540143951274/bootcamp.local%2C16020%2C1540143951274..meta.1540183639324.meta
2018-10-22 04:47:19,366 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* fsync: /app/hbase/WALs/bootcamp.local,16020,1540143951274/bootcamp.local%2C16020%2C1540143951274..meta.1540183639324.meta for DFSClient_NONMAPREDUCE_187792693_1
2018-10-22 04:47:19,376 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741901_1079{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 83
2018-10-22 04:47:19,380 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /app/hbase/WALs/bootcamp.local,16020,1540143951274/bootcamp.local%2C16020%2C1540143951274..meta.1540180032992.meta is closed by DFSClient_NONMAPREDUCE_187792693_1
2018-10-22 04:57:26,459 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 268 Total time for transactions(ms): 50 Number of transactions batched in Syncs: 14 Number of syncs: 203 SyncTimes(ms): 330 
2018-10-22 04:57:26,465 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741901_1079 172.18.0.2:50010 
2018-10-22 04:57:26,472 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741900_1078 172.18.0.2:50010 
2018-10-22 04:57:29,287 INFO BlockStateChange: BLOCK* BlockManager: ask 172.18.0.2:50010 to delete [blk_1073741900_1078, blk_1073741901_1079]
2018-10-22 05:47:05,782 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 270 Total time for transactions(ms): 51 Number of transactions batched in Syncs: 14 Number of syncs: 205 SyncTimes(ms): 333 
2018-10-22 05:47:05,795 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741904_1082{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /app/hbase/WALs/bootcamp.local,16020,1540143951274/bootcamp.local%2C16020%2C1540143951274.default.1540187225752
2018-10-22 05:47:05,839 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* fsync: /app/hbase/WALs/bootcamp.local,16020,1540143951274/bootcamp.local%2C16020%2C1540143951274.default.1540187225752 for DFSClient_NONMAPREDUCE_187792693_1
2018-10-22 05:47:05,865 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741902_1080{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 83
2018-10-22 05:47:05,870 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /app/hbase/WALs/bootcamp.local,16020,1540143951274/bootcamp.local%2C16020%2C1540143951274.default.1540183618937 is closed by DFSClient_NONMAPREDUCE_187792693_1
2018-10-22 05:47:25,663 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741905_1083{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /app/hbase/WALs/bootcamp.local,16020,1540143951274/bootcamp.local%2C16020%2C1540143951274..meta.1540187245650.meta
2018-10-22 05:47:25,681 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* fsync: /app/hbase/WALs/bootcamp.local,16020,1540143951274/bootcamp.local%2C16020%2C1540143951274..meta.1540187245650.meta for DFSClient_NONMAPREDUCE_187792693_1
2018-10-22 05:47:25,699 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741903_1081{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 83
2018-10-22 05:47:25,708 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /app/hbase/WALs/bootcamp.local,16020,1540143951274/bootcamp.local%2C16020%2C1540143951274..meta.1540183639324.meta is closed by DFSClient_NONMAPREDUCE_187792693_1
2018-10-22 05:57:22,196 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 286 Total time for transactions(ms): 52 Number of transactions batched in Syncs: 14 Number of syncs: 217 SyncTimes(ms): 350 
2018-10-22 05:57:22,198 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741902_1080 172.18.0.2:50010 
2018-10-22 05:57:23,162 INFO BlockStateChange: BLOCK* BlockManager: ask 172.18.0.2:50010 to delete [blk_1073741902_1080]
2018-10-22 05:58:22,128 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 287 Total time for transactions(ms): 52 Number of transactions batched in Syncs: 14 Number of syncs: 218 SyncTimes(ms): 351 
2018-10-22 05:58:22,130 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741903_1081 172.18.0.2:50010 
2018-10-22 05:58:23,111 INFO BlockStateChange: BLOCK* BlockManager: ask 172.18.0.2:50010 to delete [blk_1073741903_1081]
2018-10-22 06:19:33,980 INFO BlockStateChange: BLOCK* processReport: from storage DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5 node DatanodeRegistration(172.18.0.2:50010, datanodeUuid=47ecd31e-43cd-4989-84ba-314b1664d0de, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-747ab8c6-1ec4-46a0-9dee-c8151846aca5;nsid=199960936;c=0), blocks: 23, hasStaleStorage: false, processing time: 1 msecs
2018-10-22 06:47:12,193 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 288 Total time for transactions(ms): 52 Number of transactions batched in Syncs: 14 Number of syncs: 219 SyncTimes(ms): 352 
2018-10-22 06:47:12,200 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741906_1084{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /app/hbase/WALs/bootcamp.local,16020,1540143951274/bootcamp.local%2C16020%2C1540143951274.default.1540190832179
2018-10-22 06:47:12,221 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* fsync: /app/hbase/WALs/bootcamp.local,16020,1540143951274/bootcamp.local%2C16020%2C1540143951274.default.1540190832179 for DFSClient_NONMAPREDUCE_187792693_1
2018-10-22 06:47:12,234 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741904_1082{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 83
2018-10-22 06:47:12,236 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /app/hbase/WALs/bootcamp.local,16020,1540143951274/bootcamp.local%2C16020%2C1540143951274.default.1540187225752 is closed by DFSClient_NONMAPREDUCE_187792693_1
2018-10-22 06:47:31,933 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741907_1085{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /app/hbase/WALs/bootcamp.local,16020,1540143951274/bootcamp.local%2C16020%2C1540143951274..meta.1540190851918.meta
2018-10-22 06:47:31,954 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* fsync: /app/hbase/WALs/bootcamp.local,16020,1540143951274/bootcamp.local%2C16020%2C1540143951274..meta.1540190851918.meta for DFSClient_NONMAPREDUCE_187792693_1
2018-10-22 06:47:31,963 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741905_1083{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 83
2018-10-22 06:47:31,966 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /app/hbase/WALs/bootcamp.local,16020,1540143951274/bootcamp.local%2C16020%2C1540143951274..meta.1540187245650.meta is closed by DFSClient_NONMAPREDUCE_187792693_1
2018-10-22 06:57:17,944 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 304 Total time for transactions(ms): 55 Number of transactions batched in Syncs: 14 Number of syncs: 231 SyncTimes(ms): 365 
2018-10-22 06:57:17,946 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741904_1082 172.18.0.2:50010 
2018-10-22 06:57:20,867 INFO BlockStateChange: BLOCK* BlockManager: ask 172.18.0.2:50010 to delete [blk_1073741904_1082]
2018-10-22 06:58:17,870 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741905_1083 172.18.0.2:50010 
2018-10-22 06:58:20,835 INFO BlockStateChange: BLOCK* BlockManager: ask 172.18.0.2:50010 to delete [blk_1073741905_1083]
2018-10-22 07:47:18,936 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 306 Total time for transactions(ms): 56 Number of transactions batched in Syncs: 14 Number of syncs: 233 SyncTimes(ms): 368 
2018-10-22 07:47:18,946 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741908_1086{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /app/hbase/WALs/bootcamp.local,16020,1540143951274/bootcamp.local%2C16020%2C1540143951274.default.1540194438918
2018-10-22 07:47:18,972 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* fsync: /app/hbase/WALs/bootcamp.local,16020,1540143951274/bootcamp.local%2C16020%2C1540143951274.default.1540194438918 for DFSClient_NONMAPREDUCE_187792693_1
2018-10-22 07:47:18,982 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741906_1084{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 83
2018-10-22 07:47:18,987 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /app/hbase/WALs/bootcamp.local,16020,1540143951274/bootcamp.local%2C16020%2C1540143951274.default.1540190832179 is closed by DFSClient_NONMAPREDUCE_187792693_1
2018-10-22 07:47:38,652 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741909_1087{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /app/hbase/WALs/bootcamp.local,16020,1540143951274/bootcamp.local%2C16020%2C1540143951274..meta.1540194458637.meta
2018-10-22 07:47:38,675 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* fsync: /app/hbase/WALs/bootcamp.local,16020,1540143951274/bootcamp.local%2C16020%2C1540143951274..meta.1540194458637.meta for DFSClient_NONMAPREDUCE_187792693_1
2018-10-22 07:47:38,694 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741907_1085{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 83
2018-10-22 07:47:38,697 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /app/hbase/WALs/bootcamp.local,16020,1540143951274/bootcamp.local%2C16020%2C1540143951274..meta.1540190851918.meta is closed by DFSClient_NONMAPREDUCE_187792693_1
2018-10-22 07:58:13,605 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 322 Total time for transactions(ms): 57 Number of transactions batched in Syncs: 14 Number of syncs: 245 SyncTimes(ms): 382 
2018-10-22 07:58:13,608 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741907_1085 172.18.0.2:50010 
2018-10-22 07:58:13,611 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741906_1084 172.18.0.2:50010 
2018-10-22 07:58:13,638 INFO BlockStateChange: BLOCK* BlockManager: ask 172.18.0.2:50010 to delete [blk_1073741906_1084, blk_1073741907_1085]
2018-10-22 08:47:25,645 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 324 Total time for transactions(ms): 57 Number of transactions batched in Syncs: 14 Number of syncs: 247 SyncTimes(ms): 385 
2018-10-22 08:47:25,661 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741910_1088{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /app/hbase/WALs/bootcamp.local,16020,1540143951274/bootcamp.local%2C16020%2C1540143951274.default.1540198045633
2018-10-22 08:47:25,678 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* fsync: /app/hbase/WALs/bootcamp.local,16020,1540143951274/bootcamp.local%2C16020%2C1540143951274.default.1540198045633 for DFSClient_NONMAPREDUCE_187792693_1
2018-10-22 08:47:25,691 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741908_1086{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 83
2018-10-22 08:47:25,695 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /app/hbase/WALs/bootcamp.local,16020,1540143951274/bootcamp.local%2C16020%2C1540143951274.default.1540194438918 is closed by DFSClient_NONMAPREDUCE_187792693_1
2018-10-22 08:47:45,297 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741911_1089{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /app/hbase/WALs/bootcamp.local,16020,1540143951274/bootcamp.local%2C16020%2C1540143951274..meta.1540198065280.meta
2018-10-22 08:47:45,320 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* fsync: /app/hbase/WALs/bootcamp.local,16020,1540143951274/bootcamp.local%2C16020%2C1540143951274..meta.1540198065280.meta for DFSClient_NONMAPREDUCE_187792693_1
2018-10-22 08:47:45,331 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741909_1087{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 83
2018-10-22 08:47:45,339 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /app/hbase/WALs/bootcamp.local,16020,1540143951274/bootcamp.local%2C16020%2C1540143951274..meta.1540194458637.meta is closed by DFSClient_NONMAPREDUCE_187792693_1
2018-10-22 08:58:09,328 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 340 Total time for transactions(ms): 58 Number of transactions batched in Syncs: 14 Number of syncs: 259 SyncTimes(ms): 397 
2018-10-22 08:58:09,331 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741909_1087 172.18.0.2:50010 
2018-10-22 08:58:09,334 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741908_1086 172.18.0.2:50010 
2018-10-22 08:58:09,520 INFO BlockStateChange: BLOCK* BlockManager: ask 172.18.0.2:50010 to delete [blk_1073741908_1086, blk_1073741909_1087]
2018-10-22 09:47:32,422 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 342 Total time for transactions(ms): 59 Number of transactions batched in Syncs: 14 Number of syncs: 261 SyncTimes(ms): 400 
2018-10-22 09:47:32,428 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741912_1090{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /app/hbase/WALs/bootcamp.local,16020,1540143951274/bootcamp.local%2C16020%2C1540143951274.default.1540201652412
2018-10-22 09:47:32,439 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* fsync: /app/hbase/WALs/bootcamp.local,16020,1540143951274/bootcamp.local%2C16020%2C1540143951274.default.1540201652412 for DFSClient_NONMAPREDUCE_187792693_1
2018-10-22 09:47:32,451 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741910_1088{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 83
2018-10-22 09:47:32,453 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /app/hbase/WALs/bootcamp.local,16020,1540143951274/bootcamp.local%2C16020%2C1540143951274.default.1540198045633 is closed by DFSClient_NONMAPREDUCE_187792693_1
2018-10-22 09:47:51,864 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741913_1091{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /app/hbase/WALs/bootcamp.local,16020,1540143951274/bootcamp.local%2C16020%2C1540143951274..meta.1540201671850.meta
2018-10-22 09:47:51,878 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* fsync: /app/hbase/WALs/bootcamp.local,16020,1540143951274/bootcamp.local%2C16020%2C1540143951274..meta.1540201671850.meta for DFSClient_NONMAPREDUCE_187792693_1
2018-10-22 09:47:51,887 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741911_1089{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 83
2018-10-22 09:47:51,889 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /app/hbase/WALs/bootcamp.local,16020,1540143951274/bootcamp.local%2C16020%2C1540143951274..meta.1540198065280.meta is closed by DFSClient_NONMAPREDUCE_187792693_1
2018-10-22 09:58:05,066 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 358 Total time for transactions(ms): 60 Number of transactions batched in Syncs: 14 Number of syncs: 273 SyncTimes(ms): 414 
2018-10-22 09:58:05,068 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741911_1089 172.18.0.2:50010 
2018-10-22 09:58:05,070 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741910_1088 172.18.0.2:50010 
2018-10-22 09:58:05,479 INFO BlockStateChange: BLOCK* BlockManager: ask 172.18.0.2:50010 to delete [blk_1073741910_1088, blk_1073741911_1089]
2018-10-22 10:47:39,199 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 360 Total time for transactions(ms): 60 Number of transactions batched in Syncs: 14 Number of syncs: 275 SyncTimes(ms): 415 
2018-10-22 10:47:39,219 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741914_1092{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /app/hbase/WALs/bootcamp.local,16020,1540143951274/bootcamp.local%2C16020%2C1540143951274.default.1540205259188
2018-10-22 10:47:39,236 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* fsync: /app/hbase/WALs/bootcamp.local,16020,1540143951274/bootcamp.local%2C16020%2C1540143951274.default.1540205259188 for DFSClient_NONMAPREDUCE_187792693_1
2018-10-22 10:47:39,255 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741912_1090{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 83
2018-10-22 10:47:39,258 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /app/hbase/WALs/bootcamp.local,16020,1540143951274/bootcamp.local%2C16020%2C1540143951274.default.1540201652412 is closed by DFSClient_NONMAPREDUCE_187792693_1
2018-10-22 10:47:58,590 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741915_1093{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /app/hbase/WALs/bootcamp.local,16020,1540143951274/bootcamp.local%2C16020%2C1540143951274..meta.1540205278566.meta
2018-10-22 10:47:58,608 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* fsync: /app/hbase/WALs/bootcamp.local,16020,1540143951274/bootcamp.local%2C16020%2C1540143951274..meta.1540205278566.meta for DFSClient_NONMAPREDUCE_187792693_1
2018-10-22 10:47:58,616 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741913_1091{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 83
2018-10-22 10:47:58,620 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /app/hbase/WALs/bootcamp.local,16020,1540143951274/bootcamp.local%2C16020%2C1540143951274..meta.1540201671850.meta is closed by DFSClient_NONMAPREDUCE_187792693_1
2018-10-22 10:58:00,792 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 376 Total time for transactions(ms): 60 Number of transactions batched in Syncs: 14 Number of syncs: 287 SyncTimes(ms): 432 
2018-10-22 10:58:00,794 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741913_1091 172.18.0.2:50010 
2018-10-22 10:58:00,797 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741912_1090 172.18.0.2:50010 
2018-10-22 10:58:01,233 INFO BlockStateChange: BLOCK* BlockManager: ask 172.18.0.2:50010 to delete [blk_1073741912_1090, blk_1073741913_1091]
2018-10-22 11:47:45,979 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 378 Total time for transactions(ms): 60 Number of transactions batched in Syncs: 14 Number of syncs: 289 SyncTimes(ms): 434 
2018-10-22 11:47:45,985 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741916_1094{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /app/hbase/WALs/bootcamp.local,16020,1540143951274/bootcamp.local%2C16020%2C1540143951274.default.1540208865972
2018-10-22 11:47:46,014 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* fsync: /app/hbase/WALs/bootcamp.local,16020,1540143951274/bootcamp.local%2C16020%2C1540143951274.default.1540208865972 for DFSClient_NONMAPREDUCE_187792693_1
2018-10-22 11:47:46,023 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741914_1092{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 83
2018-10-22 11:47:46,030 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /app/hbase/WALs/bootcamp.local,16020,1540143951274/bootcamp.local%2C16020%2C1540143951274.default.1540205259188 is closed by DFSClient_NONMAPREDUCE_187792693_1
2018-10-22 11:48:05,286 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741917_1095{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /app/hbase/WALs/bootcamp.local,16020,1540143951274/bootcamp.local%2C16020%2C1540143951274..meta.1540208885272.meta
2018-10-22 11:48:05,297 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* fsync: /app/hbase/WALs/bootcamp.local,16020,1540143951274/bootcamp.local%2C16020%2C1540143951274..meta.1540208885272.meta for DFSClient_NONMAPREDUCE_187792693_1
2018-10-22 11:48:05,309 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741915_1093{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 83
2018-10-22 11:48:05,311 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /app/hbase/WALs/bootcamp.local,16020,1540143951274/bootcamp.local%2C16020%2C1540143951274..meta.1540205278566.meta is closed by DFSClient_NONMAPREDUCE_187792693_1
2018-10-22 11:57:56,525 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 394 Total time for transactions(ms): 60 Number of transactions batched in Syncs: 14 Number of syncs: 301 SyncTimes(ms): 450 
2018-10-22 11:57:56,530 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741914_1092 172.18.0.2:50010 
2018-10-22 11:57:57,019 INFO BlockStateChange: BLOCK* BlockManager: ask 172.18.0.2:50010 to delete [blk_1073741914_1092]
2018-10-22 11:58:56,454 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741915_1093 172.18.0.2:50010 
2018-10-22 11:58:57,012 INFO BlockStateChange: BLOCK* BlockManager: ask 172.18.0.2:50010 to delete [blk_1073741915_1093]
2018-10-22 12:19:09,068 INFO BlockStateChange: BLOCK* processReport: from storage DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5 node DatanodeRegistration(172.18.0.2:50010, datanodeUuid=47ecd31e-43cd-4989-84ba-314b1664d0de, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-747ab8c6-1ec4-46a0-9dee-c8151846aca5;nsid=199960936;c=0), blocks: 23, hasStaleStorage: false, processing time: 0 msecs
2018-10-22 12:47:52,910 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 396 Total time for transactions(ms): 60 Number of transactions batched in Syncs: 14 Number of syncs: 303 SyncTimes(ms): 454 
2018-10-22 12:47:52,930 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741918_1096{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /app/hbase/WALs/bootcamp.local,16020,1540143951274/bootcamp.local%2C16020%2C1540143951274.default.1540212472904
2018-10-22 12:47:52,939 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* fsync: /app/hbase/WALs/bootcamp.local,16020,1540143951274/bootcamp.local%2C16020%2C1540143951274.default.1540212472904 for DFSClient_NONMAPREDUCE_187792693_1
2018-10-22 12:47:52,946 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741916_1094{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 83
2018-10-22 12:47:52,949 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /app/hbase/WALs/bootcamp.local,16020,1540143951274/bootcamp.local%2C16020%2C1540143951274.default.1540208865972 is closed by DFSClient_NONMAPREDUCE_187792693_1
2018-10-22 12:48:11,956 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741919_1097{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /app/hbase/WALs/bootcamp.local,16020,1540143951274/bootcamp.local%2C16020%2C1540143951274..meta.1540212491941.meta
2018-10-22 12:48:11,966 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* fsync: /app/hbase/WALs/bootcamp.local,16020,1540143951274/bootcamp.local%2C16020%2C1540143951274..meta.1540212491941.meta for DFSClient_NONMAPREDUCE_187792693_1
2018-10-22 12:48:11,973 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741917_1095{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 83
2018-10-22 12:48:11,975 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /app/hbase/WALs/bootcamp.local,16020,1540143951274/bootcamp.local%2C16020%2C1540143951274..meta.1540208885272.meta is closed by DFSClient_NONMAPREDUCE_187792693_1
2018-10-22 12:58:52,182 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 412 Total time for transactions(ms): 61 Number of transactions batched in Syncs: 14 Number of syncs: 315 SyncTimes(ms): 472 
2018-10-22 12:58:52,187 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741917_1095 172.18.0.2:50010 
2018-10-22 12:58:52,191 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741916_1094 172.18.0.2:50010 
2018-10-22 12:58:52,988 INFO BlockStateChange: BLOCK* BlockManager: ask 172.18.0.2:50010 to delete [blk_1073741916_1094, blk_1073741917_1095]
2018-10-22 13:47:59,646 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 414 Total time for transactions(ms): 62 Number of transactions batched in Syncs: 14 Number of syncs: 317 SyncTimes(ms): 477 
2018-10-22 13:47:59,651 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741920_1098{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /app/hbase/WALs/bootcamp.local,16020,1540143951274/bootcamp.local%2C16020%2C1540143951274.default.1540216079641
2018-10-22 13:47:59,660 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* fsync: /app/hbase/WALs/bootcamp.local,16020,1540143951274/bootcamp.local%2C16020%2C1540143951274.default.1540216079641 for DFSClient_NONMAPREDUCE_187792693_1
2018-10-22 13:47:59,668 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741918_1096{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 83
2018-10-22 13:47:59,669 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /app/hbase/WALs/bootcamp.local,16020,1540143951274/bootcamp.local%2C16020%2C1540143951274.default.1540212472904 is closed by DFSClient_NONMAPREDUCE_187792693_1
2018-10-22 13:48:18,727 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741921_1099{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /app/hbase/WALs/bootcamp.local,16020,1540143951274/bootcamp.local%2C16020%2C1540143951274..meta.1540216098714.meta
2018-10-22 13:48:18,737 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* fsync: /app/hbase/WALs/bootcamp.local,16020,1540143951274/bootcamp.local%2C16020%2C1540143951274..meta.1540216098714.meta for DFSClient_NONMAPREDUCE_187792693_1
2018-10-22 13:48:18,753 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741919_1097{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 83
2018-10-22 13:48:18,755 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /app/hbase/WALs/bootcamp.local,16020,1540143951274/bootcamp.local%2C16020%2C1540143951274..meta.1540212491941.meta is closed by DFSClient_NONMAPREDUCE_187792693_1
2018-10-22 13:58:47,911 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 430 Total time for transactions(ms): 63 Number of transactions batched in Syncs: 14 Number of syncs: 329 SyncTimes(ms): 488 
2018-10-22 13:58:47,915 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741919_1097 172.18.0.2:50010 
2018-10-22 13:58:47,918 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741918_1096 172.18.0.2:50010 
2018-10-22 13:58:49,111 INFO BlockStateChange: BLOCK* BlockManager: ask 172.18.0.2:50010 to delete [blk_1073741918_1096, blk_1073741919_1097]
2018-10-22 14:48:06,366 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 432 Total time for transactions(ms): 64 Number of transactions batched in Syncs: 14 Number of syncs: 331 SyncTimes(ms): 490 
2018-10-22 14:48:06,373 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741922_1100{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /app/hbase/WALs/bootcamp.local,16020,1540143951274/bootcamp.local%2C16020%2C1540143951274.default.1540219686360
2018-10-22 14:48:06,388 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* fsync: /app/hbase/WALs/bootcamp.local,16020,1540143951274/bootcamp.local%2C16020%2C1540143951274.default.1540219686360 for DFSClient_NONMAPREDUCE_187792693_1
2018-10-22 14:48:06,396 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741920_1098{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 83
2018-10-22 14:48:06,402 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /app/hbase/WALs/bootcamp.local,16020,1540143951274/bootcamp.local%2C16020%2C1540143951274.default.1540216079641 is closed by DFSClient_NONMAPREDUCE_187792693_1
2018-10-22 14:48:25,443 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741923_1101{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /app/hbase/WALs/bootcamp.local,16020,1540143951274/bootcamp.local%2C16020%2C1540143951274..meta.1540219705426.meta
2018-10-22 14:48:25,453 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* fsync: /app/hbase/WALs/bootcamp.local,16020,1540143951274/bootcamp.local%2C16020%2C1540143951274..meta.1540219705426.meta for DFSClient_NONMAPREDUCE_187792693_1
2018-10-22 14:48:25,462 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* blk_1073741921_1099{UCState=COMMITTED, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} is not COMPLETE (ucState = COMMITTED, replication# = 0 <  minimum = 1) in file /app/hbase/WALs/bootcamp.local,16020,1540143951274/bootcamp.local%2C16020%2C1540143951274..meta.1540216098714.meta
2018-10-22 14:48:25,462 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741921_1099{UCState=COMMITTED, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 91
2018-10-22 14:48:25,867 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /app/hbase/WALs/bootcamp.local,16020,1540143951274/bootcamp.local%2C16020%2C1540143951274..meta.1540216098714.meta is closed by DFSClient_NONMAPREDUCE_187792693_1
2018-10-22 14:58:43,640 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 448 Total time for transactions(ms): 66 Number of transactions batched in Syncs: 15 Number of syncs: 343 SyncTimes(ms): 506 
2018-10-22 14:58:43,646 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741921_1099 172.18.0.2:50010 
2018-10-22 14:58:43,649 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741920_1098 172.18.0.2:50010 
2018-10-22 14:58:45,312 INFO BlockStateChange: BLOCK* BlockManager: ask 172.18.0.2:50010 to delete [blk_1073741920_1098, blk_1073741921_1099]
2018-10-22 15:48:13,001 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 450 Total time for transactions(ms): 66 Number of transactions batched in Syncs: 15 Number of syncs: 345 SyncTimes(ms): 510 
2018-10-22 15:48:13,009 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741924_1102{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /app/hbase/WALs/bootcamp.local,16020,1540143951274/bootcamp.local%2C16020%2C1540143951274.default.1540223292993
2018-10-22 15:48:13,022 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* fsync: /app/hbase/WALs/bootcamp.local,16020,1540143951274/bootcamp.local%2C16020%2C1540143951274.default.1540223292993 for DFSClient_NONMAPREDUCE_187792693_1
2018-10-22 15:48:13,031 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741922_1100{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 83
2018-10-22 15:48:13,034 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /app/hbase/WALs/bootcamp.local,16020,1540143951274/bootcamp.local%2C16020%2C1540143951274.default.1540219686360 is closed by DFSClient_NONMAPREDUCE_187792693_1
2018-10-22 15:48:32,593 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741925_1103{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /app/hbase/WALs/bootcamp.local,16020,1540143951274/bootcamp.local%2C16020%2C1540143951274..meta.1540223312582.meta
2018-10-22 15:48:32,607 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* fsync: /app/hbase/WALs/bootcamp.local,16020,1540143951274/bootcamp.local%2C16020%2C1540143951274..meta.1540223312582.meta for DFSClient_NONMAPREDUCE_187792693_1
2018-10-22 15:48:32,615 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741923_1101{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 83
2018-10-22 15:48:32,618 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /app/hbase/WALs/bootcamp.local,16020,1540143951274/bootcamp.local%2C16020%2C1540143951274..meta.1540219705426.meta is closed by DFSClient_NONMAPREDUCE_187792693_1
2018-10-22 15:58:39,364 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 466 Total time for transactions(ms): 66 Number of transactions batched in Syncs: 15 Number of syncs: 357 SyncTimes(ms): 521 
2018-10-22 15:58:39,367 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741923_1101 172.18.0.2:50010 
2018-10-22 15:58:39,370 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741922_1100 172.18.0.2:50010 
2018-10-22 15:58:41,677 INFO BlockStateChange: BLOCK* BlockManager: ask 172.18.0.2:50010 to delete [blk_1073741922_1100, blk_1073741923_1101]
2018-10-22 16:48:19,600 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 468 Total time for transactions(ms): 66 Number of transactions batched in Syncs: 15 Number of syncs: 359 SyncTimes(ms): 525 
2018-10-22 16:48:19,606 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741926_1104{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /app/hbase/WALs/bootcamp.local,16020,1540143951274/bootcamp.local%2C16020%2C1540143951274.default.1540226899582
2018-10-22 16:48:19,622 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* fsync: /app/hbase/WALs/bootcamp.local,16020,1540143951274/bootcamp.local%2C16020%2C1540143951274.default.1540226899582 for DFSClient_NONMAPREDUCE_187792693_1
2018-10-22 16:48:19,630 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741924_1102{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 83
2018-10-22 16:48:19,632 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /app/hbase/WALs/bootcamp.local,16020,1540143951274/bootcamp.local%2C16020%2C1540143951274.default.1540223292993 is closed by DFSClient_NONMAPREDUCE_187792693_1
2018-10-22 16:48:39,251 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741927_1105{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /app/hbase/WALs/bootcamp.local,16020,1540143951274/bootcamp.local%2C16020%2C1540143951274..meta.1540226919240.meta
2018-10-22 16:48:39,260 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* fsync: /app/hbase/WALs/bootcamp.local,16020,1540143951274/bootcamp.local%2C16020%2C1540143951274..meta.1540226919240.meta for DFSClient_NONMAPREDUCE_187792693_1
2018-10-22 16:48:39,267 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741925_1103{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 83
2018-10-22 16:48:39,275 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /app/hbase/WALs/bootcamp.local,16020,1540143951274/bootcamp.local%2C16020%2C1540143951274..meta.1540223312582.meta is closed by DFSClient_NONMAPREDUCE_187792693_1
2018-10-22 16:58:35,091 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 484 Total time for transactions(ms): 66 Number of transactions batched in Syncs: 15 Number of syncs: 371 SyncTimes(ms): 537 
2018-10-22 16:58:35,093 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741924_1102 172.18.0.2:50010 
2018-10-22 16:58:37,244 INFO BlockStateChange: BLOCK* BlockManager: ask 172.18.0.2:50010 to delete [blk_1073741924_1102]
2018-10-22 16:59:35,022 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741925_1103 172.18.0.2:50010 
2018-10-22 16:59:37,203 INFO BlockStateChange: BLOCK* BlockManager: ask 172.18.0.2:50010 to delete [blk_1073741925_1103]
2018-10-22 17:48:25,852 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 486 Total time for transactions(ms): 66 Number of transactions batched in Syncs: 15 Number of syncs: 373 SyncTimes(ms): 541 
2018-10-22 17:48:25,864 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741928_1106{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /app/hbase/WALs/bootcamp.local,16020,1540143951274/bootcamp.local%2C16020%2C1540143951274.default.1540230505844
2018-10-22 17:48:25,879 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* fsync: /app/hbase/WALs/bootcamp.local,16020,1540143951274/bootcamp.local%2C16020%2C1540143951274.default.1540230505844 for DFSClient_NONMAPREDUCE_187792693_1
2018-10-22 17:48:25,887 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741926_1104{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 83
2018-10-22 17:48:25,888 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /app/hbase/WALs/bootcamp.local,16020,1540143951274/bootcamp.local%2C16020%2C1540143951274.default.1540226899582 is closed by DFSClient_NONMAPREDUCE_187792693_1
2018-10-22 17:48:45,526 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741929_1107{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /app/hbase/WALs/bootcamp.local,16020,1540143951274/bootcamp.local%2C16020%2C1540143951274..meta.1540230525504.meta
2018-10-22 17:48:45,546 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* fsync: /app/hbase/WALs/bootcamp.local,16020,1540143951274/bootcamp.local%2C16020%2C1540143951274..meta.1540230525504.meta for DFSClient_NONMAPREDUCE_187792693_1
2018-10-22 17:48:45,556 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741927_1105{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 83
2018-10-22 17:48:45,559 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /app/hbase/WALs/bootcamp.local,16020,1540143951274/bootcamp.local%2C16020%2C1540143951274..meta.1540226919240.meta is closed by DFSClient_NONMAPREDUCE_187792693_1
2018-10-22 17:58:30,834 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 502 Total time for transactions(ms): 66 Number of transactions batched in Syncs: 15 Number of syncs: 385 SyncTimes(ms): 559 
2018-10-22 17:58:30,836 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741926_1104 172.18.0.2:50010 
2018-10-22 17:58:31,663 INFO BlockStateChange: BLOCK* BlockManager: ask 172.18.0.2:50010 to delete [blk_1073741926_1104]
2018-10-22 17:59:30,767 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 503 Total time for transactions(ms): 66 Number of transactions batched in Syncs: 15 Number of syncs: 386 SyncTimes(ms): 560 
2018-10-22 17:59:30,771 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741927_1105 172.18.0.2:50010 
2018-10-22 17:59:31,623 INFO BlockStateChange: BLOCK* BlockManager: ask 172.18.0.2:50010 to delete [blk_1073741927_1105]
2018-10-22 18:18:43,579 INFO BlockStateChange: BLOCK* processReport: from storage DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5 node DatanodeRegistration(172.18.0.2:50010, datanodeUuid=47ecd31e-43cd-4989-84ba-314b1664d0de, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-747ab8c6-1ec4-46a0-9dee-c8151846aca5;nsid=199960936;c=0), blocks: 23, hasStaleStorage: false, processing time: 0 msecs
2018-10-22 18:48:32,037 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 504 Total time for transactions(ms): 66 Number of transactions batched in Syncs: 15 Number of syncs: 387 SyncTimes(ms): 561 
2018-10-22 18:48:32,044 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741930_1108{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /app/hbase/WALs/bootcamp.local,16020,1540143951274/bootcamp.local%2C16020%2C1540143951274.default.1540234112022
2018-10-22 18:48:32,052 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* fsync: /app/hbase/WALs/bootcamp.local,16020,1540143951274/bootcamp.local%2C16020%2C1540143951274.default.1540234112022 for DFSClient_NONMAPREDUCE_187792693_1
2018-10-22 18:48:32,060 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* blk_1073741928_1106{UCState=COMMITTED, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} is not COMPLETE (ucState = COMMITTED, replication# = 0 <  minimum = 1) in file /app/hbase/WALs/bootcamp.local,16020,1540143951274/bootcamp.local%2C16020%2C1540143951274.default.1540230505844
2018-10-22 18:48:32,062 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741928_1106{UCState=COMMITTED, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 91
2018-10-22 18:48:32,466 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /app/hbase/WALs/bootcamp.local,16020,1540143951274/bootcamp.local%2C16020%2C1540143951274.default.1540230505844 is closed by DFSClient_NONMAPREDUCE_187792693_1
2018-10-22 18:48:51,714 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741931_1109{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /app/hbase/WALs/bootcamp.local,16020,1540143951274/bootcamp.local%2C16020%2C1540143951274..meta.1540234131672.meta
2018-10-22 18:48:51,724 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* fsync: /app/hbase/WALs/bootcamp.local,16020,1540143951274/bootcamp.local%2C16020%2C1540143951274..meta.1540234131672.meta for DFSClient_NONMAPREDUCE_187792693_1
2018-10-22 18:48:51,731 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741929_1107{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 83
2018-10-22 18:48:51,733 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /app/hbase/WALs/bootcamp.local,16020,1540143951274/bootcamp.local%2C16020%2C1540143951274..meta.1540230525504.meta is closed by DFSClient_NONMAPREDUCE_187792693_1
2018-10-22 18:59:26,521 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 520 Total time for transactions(ms): 67 Number of transactions batched in Syncs: 16 Number of syncs: 399 SyncTimes(ms): 599 
2018-10-22 18:59:26,523 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741929_1107 172.18.0.2:50010 
2018-10-22 18:59:26,526 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741928_1106 172.18.0.2:50010 
2018-10-22 18:59:29,474 INFO BlockStateChange: BLOCK* BlockManager: ask 172.18.0.2:50010 to delete [blk_1073741928_1106, blk_1073741929_1107]
2018-10-22 19:48:38,638 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 522 Total time for transactions(ms): 67 Number of transactions batched in Syncs: 16 Number of syncs: 401 SyncTimes(ms): 600 
2018-10-22 19:48:38,648 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741932_1110{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /app/hbase/WALs/bootcamp.local,16020,1540143951274/bootcamp.local%2C16020%2C1540143951274.default.1540237718632
2018-10-22 19:48:38,682 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* fsync: /app/hbase/WALs/bootcamp.local,16020,1540143951274/bootcamp.local%2C16020%2C1540143951274.default.1540237718632 for DFSClient_NONMAPREDUCE_187792693_1
2018-10-22 19:48:38,695 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741930_1108{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 83
2018-10-22 19:48:38,698 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /app/hbase/WALs/bootcamp.local,16020,1540143951274/bootcamp.local%2C16020%2C1540143951274.default.1540234112022 is closed by DFSClient_NONMAPREDUCE_187792693_1
2018-10-22 19:48:58,121 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741933_1111{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /app/hbase/WALs/bootcamp.local,16020,1540143951274/bootcamp.local%2C16020%2C1540143951274..meta.1540237738107.meta
2018-10-22 19:48:58,134 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* fsync: /app/hbase/WALs/bootcamp.local,16020,1540143951274/bootcamp.local%2C16020%2C1540143951274..meta.1540237738107.meta for DFSClient_NONMAPREDUCE_187792693_1
2018-10-22 19:48:58,141 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741931_1109{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 83
2018-10-22 19:48:58,143 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /app/hbase/WALs/bootcamp.local,16020,1540143951274/bootcamp.local%2C16020%2C1540143951274..meta.1540234131672.meta is closed by DFSClient_NONMAPREDUCE_187792693_1
2018-10-22 19:59:22,266 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 538 Total time for transactions(ms): 67 Number of transactions batched in Syncs: 16 Number of syncs: 413 SyncTimes(ms): 611 
2018-10-22 19:59:22,269 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741931_1109 172.18.0.2:50010 
2018-10-22 19:59:22,274 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741930_1108 172.18.0.2:50010 
2018-10-22 19:59:23,865 INFO BlockStateChange: BLOCK* BlockManager: ask 172.18.0.2:50010 to delete [blk_1073741930_1108, blk_1073741931_1109]
2018-10-22 20:48:45,132 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 540 Total time for transactions(ms): 68 Number of transactions batched in Syncs: 16 Number of syncs: 415 SyncTimes(ms): 614 
2018-10-22 20:48:45,139 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741934_1112{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /app/hbase/WALs/bootcamp.local,16020,1540143951274/bootcamp.local%2C16020%2C1540143951274.default.1540241325122
2018-10-22 20:48:45,156 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* fsync: /app/hbase/WALs/bootcamp.local,16020,1540143951274/bootcamp.local%2C16020%2C1540143951274.default.1540241325122 for DFSClient_NONMAPREDUCE_187792693_1
2018-10-22 20:48:45,164 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741932_1110{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 83
2018-10-22 20:48:45,168 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /app/hbase/WALs/bootcamp.local,16020,1540143951274/bootcamp.local%2C16020%2C1540143951274.default.1540237718632 is closed by DFSClient_NONMAPREDUCE_187792693_1
2018-10-22 20:49:04,702 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741935_1113{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /app/hbase/WALs/bootcamp.local,16020,1540143951274/bootcamp.local%2C16020%2C1540143951274..meta.1540241344680.meta
2018-10-22 20:49:04,775 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* fsync: /app/hbase/WALs/bootcamp.local,16020,1540143951274/bootcamp.local%2C16020%2C1540143951274..meta.1540241344680.meta for DFSClient_NONMAPREDUCE_187792693_1
2018-10-22 20:49:04,791 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741933_1111{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 83
2018-10-22 20:49:04,797 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /app/hbase/WALs/bootcamp.local,16020,1540143951274/bootcamp.local%2C16020%2C1540143951274..meta.1540237738107.meta is closed by DFSClient_NONMAPREDUCE_187792693_1
2018-10-22 20:59:18,001 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 556 Total time for transactions(ms): 68 Number of transactions batched in Syncs: 16 Number of syncs: 427 SyncTimes(ms): 635 
2018-10-22 20:59:18,005 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741933_1111 172.18.0.2:50010 
2018-10-22 20:59:18,007 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741932_1110 172.18.0.2:50010 
2018-10-22 20:59:19,069 INFO BlockStateChange: BLOCK* BlockManager: ask 172.18.0.2:50010 to delete [blk_1073741932_1110, blk_1073741933_1111]
2018-10-22 21:48:51,503 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 558 Total time for transactions(ms): 68 Number of transactions batched in Syncs: 16 Number of syncs: 429 SyncTimes(ms): 638 
2018-10-22 21:48:51,508 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741936_1114{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /app/hbase/WALs/bootcamp.local,16020,1540143951274/bootcamp.local%2C16020%2C1540143951274.default.1540244931491
2018-10-22 21:48:51,523 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* fsync: /app/hbase/WALs/bootcamp.local,16020,1540143951274/bootcamp.local%2C16020%2C1540143951274.default.1540244931491 for DFSClient_NONMAPREDUCE_187792693_1
2018-10-22 21:48:51,532 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741934_1112{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 83
2018-10-22 21:48:51,534 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /app/hbase/WALs/bootcamp.local,16020,1540143951274/bootcamp.local%2C16020%2C1540143951274.default.1540241325122 is closed by DFSClient_NONMAPREDUCE_187792693_1
2018-10-22 21:49:11,049 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741937_1115{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /app/hbase/WALs/bootcamp.local,16020,1540143951274/bootcamp.local%2C16020%2C1540143951274..meta.1540244951040.meta
2018-10-22 21:49:11,070 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* fsync: /app/hbase/WALs/bootcamp.local,16020,1540143951274/bootcamp.local%2C16020%2C1540143951274..meta.1540244951040.meta for DFSClient_NONMAPREDUCE_187792693_1
2018-10-22 21:49:11,080 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741935_1113{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 83
2018-10-22 21:49:11,082 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /app/hbase/WALs/bootcamp.local,16020,1540143951274/bootcamp.local%2C16020%2C1540143951274..meta.1540241344680.meta is closed by DFSClient_NONMAPREDUCE_187792693_1
2018-10-22 21:59:13,736 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 574 Total time for transactions(ms): 69 Number of transactions batched in Syncs: 16 Number of syncs: 441 SyncTimes(ms): 649 
2018-10-22 21:59:13,739 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741935_1113 172.18.0.2:50010 
2018-10-22 21:59:13,742 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741934_1112 172.18.0.2:50010 
2018-10-22 21:59:13,776 INFO BlockStateChange: BLOCK* BlockManager: ask 172.18.0.2:50010 to delete [blk_1073741934_1112, blk_1073741935_1113]
2018-10-22 22:48:57,770 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 576 Total time for transactions(ms): 70 Number of transactions batched in Syncs: 16 Number of syncs: 443 SyncTimes(ms): 652 
2018-10-22 22:48:57,778 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741938_1116{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /app/hbase/WALs/bootcamp.local,16020,1540143951274/bootcamp.local%2C16020%2C1540143951274.default.1540248537762
2018-10-22 22:48:57,789 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* fsync: /app/hbase/WALs/bootcamp.local,16020,1540143951274/bootcamp.local%2C16020%2C1540143951274.default.1540248537762 for DFSClient_NONMAPREDUCE_187792693_1
2018-10-22 22:48:57,797 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741936_1114{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 83
2018-10-22 22:48:57,806 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /app/hbase/WALs/bootcamp.local,16020,1540143951274/bootcamp.local%2C16020%2C1540143951274.default.1540244931491 is closed by DFSClient_NONMAPREDUCE_187792693_1
2018-10-22 22:49:17,376 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741939_1117{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /app/hbase/WALs/bootcamp.local,16020,1540143951274/bootcamp.local%2C16020%2C1540143951274..meta.1540248557364.meta
2018-10-22 22:49:17,384 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* fsync: /app/hbase/WALs/bootcamp.local,16020,1540143951274/bootcamp.local%2C16020%2C1540143951274..meta.1540248557364.meta for DFSClient_NONMAPREDUCE_187792693_1
2018-10-22 22:49:17,391 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741937_1115{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 83
2018-10-22 22:49:17,395 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /app/hbase/WALs/bootcamp.local,16020,1540143951274/bootcamp.local%2C16020%2C1540143951274..meta.1540244951040.meta is closed by DFSClient_NONMAPREDUCE_187792693_1
2018-10-22 22:59:09,497 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 592 Total time for transactions(ms): 71 Number of transactions batched in Syncs: 16 Number of syncs: 455 SyncTimes(ms): 676 
2018-10-22 22:59:09,499 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741936_1114 172.18.0.2:50010 
2018-10-22 22:59:11,317 INFO BlockStateChange: BLOCK* BlockManager: ask 172.18.0.2:50010 to delete [blk_1073741936_1114]
2018-10-22 23:00:09,427 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741937_1115 172.18.0.2:50010 
2018-10-22 23:00:11,301 INFO BlockStateChange: BLOCK* BlockManager: ask 172.18.0.2:50010 to delete [blk_1073741937_1115]
2018-10-22 23:49:04,141 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 594 Total time for transactions(ms): 71 Number of transactions batched in Syncs: 16 Number of syncs: 457 SyncTimes(ms): 683 
2018-10-22 23:49:04,147 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741940_1118{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /app/hbase/WALs/bootcamp.local,16020,1540143951274/bootcamp.local%2C16020%2C1540143951274.default.1540252144127
2018-10-22 23:49:04,157 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* fsync: /app/hbase/WALs/bootcamp.local,16020,1540143951274/bootcamp.local%2C16020%2C1540143951274.default.1540252144127 for DFSClient_NONMAPREDUCE_187792693_1
2018-10-22 23:49:04,167 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741938_1116{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 83
2018-10-22 23:49:04,169 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /app/hbase/WALs/bootcamp.local,16020,1540143951274/bootcamp.local%2C16020%2C1540143951274.default.1540248537762 is closed by DFSClient_NONMAPREDUCE_187792693_1
2018-10-22 23:49:23,759 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741941_1119{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /app/hbase/WALs/bootcamp.local,16020,1540143951274/bootcamp.local%2C16020%2C1540143951274..meta.1540252163741.meta
2018-10-22 23:49:23,779 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* fsync: /app/hbase/WALs/bootcamp.local,16020,1540143951274/bootcamp.local%2C16020%2C1540143951274..meta.1540252163741.meta for DFSClient_NONMAPREDUCE_187792693_1
2018-10-22 23:49:23,797 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741939_1117{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 83
2018-10-22 23:49:23,799 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /app/hbase/WALs/bootcamp.local,16020,1540143951274/bootcamp.local%2C16020%2C1540143951274..meta.1540248557364.meta is closed by DFSClient_NONMAPREDUCE_187792693_1
2018-10-22 23:59:05,230 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 610 Total time for transactions(ms): 72 Number of transactions batched in Syncs: 16 Number of syncs: 469 SyncTimes(ms): 708 
2018-10-22 23:59:05,234 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741938_1116 172.18.0.2:50010 
2018-10-22 23:59:05,978 INFO BlockStateChange: BLOCK* BlockManager: ask 172.18.0.2:50010 to delete [blk_1073741938_1116]
2018-10-23 00:00:05,158 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 611 Total time for transactions(ms): 72 Number of transactions batched in Syncs: 16 Number of syncs: 470 SyncTimes(ms): 709 
2018-10-23 00:00:05,170 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741939_1117 172.18.0.2:50010 
2018-10-23 00:00:05,948 INFO BlockStateChange: BLOCK* BlockManager: ask 172.18.0.2:50010 to delete [blk_1073741939_1117]
2018-10-23 00:18:17,489 INFO BlockStateChange: BLOCK* processReport: from storage DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5 node DatanodeRegistration(172.18.0.2:50010, datanodeUuid=47ecd31e-43cd-4989-84ba-314b1664d0de, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-747ab8c6-1ec4-46a0-9dee-c8151846aca5;nsid=199960936;c=0), blocks: 23, hasStaleStorage: false, processing time: 0 msecs
2018-10-23 00:49:10,366 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 612 Total time for transactions(ms): 72 Number of transactions batched in Syncs: 16 Number of syncs: 471 SyncTimes(ms): 710 
2018-10-23 00:49:10,372 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741942_1120{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /app/hbase/WALs/bootcamp.local,16020,1540143951274/bootcamp.local%2C16020%2C1540143951274.default.1540255750357
2018-10-23 00:49:10,387 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* fsync: /app/hbase/WALs/bootcamp.local,16020,1540143951274/bootcamp.local%2C16020%2C1540143951274.default.1540255750357 for DFSClient_NONMAPREDUCE_187792693_1
2018-10-23 00:49:10,396 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741940_1118{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 83
2018-10-23 00:49:10,408 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /app/hbase/WALs/bootcamp.local,16020,1540143951274/bootcamp.local%2C16020%2C1540143951274.default.1540252144127 is closed by DFSClient_NONMAPREDUCE_187792693_1
2018-10-23 00:49:29,971 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741943_1121{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /app/hbase/WALs/bootcamp.local,16020,1540143951274/bootcamp.local%2C16020%2C1540143951274..meta.1540255769958.meta
2018-10-23 00:49:29,981 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* fsync: /app/hbase/WALs/bootcamp.local,16020,1540143951274/bootcamp.local%2C16020%2C1540143951274..meta.1540255769958.meta for DFSClient_NONMAPREDUCE_187792693_1
2018-10-23 00:49:29,988 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* blk_1073741941_1119{UCState=COMMITTED, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} is not COMPLETE (ucState = COMMITTED, replication# = 0 <  minimum = 1) in file /app/hbase/WALs/bootcamp.local,16020,1540143951274/bootcamp.local%2C16020%2C1540143951274..meta.1540252163741.meta
2018-10-23 00:49:29,990 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741941_1119{UCState=COMMITTED, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 91
2018-10-23 00:49:30,394 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /app/hbase/WALs/bootcamp.local,16020,1540143951274/bootcamp.local%2C16020%2C1540143951274..meta.1540252163741.meta is closed by DFSClient_NONMAPREDUCE_187792693_1
2018-10-23 01:00:00,901 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 628 Total time for transactions(ms): 72 Number of transactions batched in Syncs: 17 Number of syncs: 483 SyncTimes(ms): 727 
2018-10-23 01:00:00,908 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741941_1119 172.18.0.2:50010 
2018-10-23 01:00:00,910 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741940_1118 172.18.0.2:50010 
2018-10-23 01:00:03,133 INFO BlockStateChange: BLOCK* BlockManager: ask 172.18.0.2:50010 to delete [blk_1073741940_1118, blk_1073741941_1119]
2018-10-23 01:49:16,803 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 630 Total time for transactions(ms): 72 Number of transactions batched in Syncs: 17 Number of syncs: 485 SyncTimes(ms): 732 
2018-10-23 01:49:16,807 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741944_1122{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /app/hbase/WALs/bootcamp.local,16020,1540143951274/bootcamp.local%2C16020%2C1540143951274.default.1540259356798
2018-10-23 01:49:16,818 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* fsync: /app/hbase/WALs/bootcamp.local,16020,1540143951274/bootcamp.local%2C16020%2C1540143951274.default.1540259356798 for DFSClient_NONMAPREDUCE_187792693_1
2018-10-23 01:49:16,824 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741942_1120{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 83
2018-10-23 01:49:16,827 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /app/hbase/WALs/bootcamp.local,16020,1540143951274/bootcamp.local%2C16020%2C1540143951274.default.1540255750357 is closed by DFSClient_NONMAPREDUCE_187792693_1
2018-10-23 01:49:36,773 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741945_1123{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /app/hbase/WALs/bootcamp.local,16020,1540143951274/bootcamp.local%2C16020%2C1540143951274..meta.1540259376764.meta
2018-10-23 01:49:36,784 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* fsync: /app/hbase/WALs/bootcamp.local,16020,1540143951274/bootcamp.local%2C16020%2C1540143951274..meta.1540259376764.meta for DFSClient_NONMAPREDUCE_187792693_1
2018-10-23 01:49:36,791 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741943_1121{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 83
2018-10-23 01:49:36,792 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /app/hbase/WALs/bootcamp.local,16020,1540143951274/bootcamp.local%2C16020%2C1540143951274..meta.1540255769958.meta is closed by DFSClient_NONMAPREDUCE_187792693_1
2018-10-23 01:59:56,652 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 646 Total time for transactions(ms): 73 Number of transactions batched in Syncs: 17 Number of syncs: 497 SyncTimes(ms): 741 
2018-10-23 01:59:56,655 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741943_1121 172.18.0.2:50010 
2018-10-23 01:59:56,660 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741942_1120 172.18.0.2:50010 
2018-10-23 01:59:58,176 INFO BlockStateChange: BLOCK* BlockManager: ask 172.18.0.2:50010 to delete [blk_1073741942_1120, blk_1073741943_1121]
2018-10-23 02:49:23,133 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 648 Total time for transactions(ms): 73 Number of transactions batched in Syncs: 17 Number of syncs: 499 SyncTimes(ms): 744 
2018-10-23 02:49:23,141 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741946_1124{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /app/hbase/WALs/bootcamp.local,16020,1540143951274/bootcamp.local%2C16020%2C1540143951274.default.1540262963127
2018-10-23 02:49:23,156 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* fsync: /app/hbase/WALs/bootcamp.local,16020,1540143951274/bootcamp.local%2C16020%2C1540143951274.default.1540262963127 for DFSClient_NONMAPREDUCE_187792693_1
2018-10-23 02:49:23,167 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741944_1122{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 83
2018-10-23 02:49:23,169 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /app/hbase/WALs/bootcamp.local,16020,1540143951274/bootcamp.local%2C16020%2C1540143951274.default.1540259356798 is closed by DFSClient_NONMAPREDUCE_187792693_1
2018-10-23 02:49:43,142 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741947_1125{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /app/hbase/WALs/bootcamp.local,16020,1540143951274/bootcamp.local%2C16020%2C1540143951274..meta.1540262983128.meta
2018-10-23 02:49:43,153 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* fsync: /app/hbase/WALs/bootcamp.local,16020,1540143951274/bootcamp.local%2C16020%2C1540143951274..meta.1540262983128.meta for DFSClient_NONMAPREDUCE_187792693_1
2018-10-23 02:49:43,160 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741945_1123{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 83
2018-10-23 02:49:43,163 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /app/hbase/WALs/bootcamp.local,16020,1540143951274/bootcamp.local%2C16020%2C1540143951274..meta.1540259376764.meta is closed by DFSClient_NONMAPREDUCE_187792693_1
2018-10-23 02:59:52,387 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 664 Total time for transactions(ms): 75 Number of transactions batched in Syncs: 17 Number of syncs: 511 SyncTimes(ms): 757 
2018-10-23 02:59:52,390 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741945_1123 172.18.0.2:50010 
2018-10-23 02:59:52,399 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741944_1122 172.18.0.2:50010 
2018-10-23 02:59:53,048 INFO BlockStateChange: BLOCK* BlockManager: ask 172.18.0.2:50010 to delete [blk_1073741944_1122, blk_1073741945_1123]
2018-10-23 03:49:29,489 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 666 Total time for transactions(ms): 76 Number of transactions batched in Syncs: 17 Number of syncs: 513 SyncTimes(ms): 760 
2018-10-23 03:49:29,497 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741948_1126{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /app/hbase/WALs/bootcamp.local,16020,1540143951274/bootcamp.local%2C16020%2C1540143951274.default.1540266569481
2018-10-23 03:49:29,511 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* fsync: /app/hbase/WALs/bootcamp.local,16020,1540143951274/bootcamp.local%2C16020%2C1540143951274.default.1540266569481 for DFSClient_NONMAPREDUCE_187792693_1
2018-10-23 03:49:29,525 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* blk_1073741946_1124{UCState=COMMITTED, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} is not COMPLETE (ucState = COMMITTED, replication# = 0 <  minimum = 1) in file /app/hbase/WALs/bootcamp.local,16020,1540143951274/bootcamp.local%2C16020%2C1540143951274.default.1540262963127
2018-10-23 03:49:29,526 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741946_1124{UCState=COMMITTED, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 91
2018-10-23 03:49:29,931 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /app/hbase/WALs/bootcamp.local,16020,1540143951274/bootcamp.local%2C16020%2C1540143951274.default.1540262963127 is closed by DFSClient_NONMAPREDUCE_187792693_1
2018-10-23 03:49:49,461 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741949_1127{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /app/hbase/WALs/bootcamp.local,16020,1540143951274/bootcamp.local%2C16020%2C1540143951274..meta.1540266589450.meta
2018-10-23 03:49:49,478 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* fsync: /app/hbase/WALs/bootcamp.local,16020,1540143951274/bootcamp.local%2C16020%2C1540143951274..meta.1540266589450.meta for DFSClient_NONMAPREDUCE_187792693_1
2018-10-23 03:49:49,488 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741947_1125{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 83
2018-10-23 03:49:49,490 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /app/hbase/WALs/bootcamp.local,16020,1540143951274/bootcamp.local%2C16020%2C1540143951274..meta.1540262983128.meta is closed by DFSClient_NONMAPREDUCE_187792693_1
2018-10-23 03:59:48,118 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 682 Total time for transactions(ms): 77 Number of transactions batched in Syncs: 18 Number of syncs: 525 SyncTimes(ms): 774 
2018-10-23 03:59:48,120 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741946_1124 172.18.0.2:50010 
2018-10-23 03:59:50,894 INFO BlockStateChange: BLOCK* BlockManager: ask 172.18.0.2:50010 to delete [blk_1073741946_1124]
2018-10-23 04:00:48,046 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741947_1125 172.18.0.2:50010 
2018-10-23 04:00:50,851 INFO BlockStateChange: BLOCK* BlockManager: ask 172.18.0.2:50010 to delete [blk_1073741947_1125]
2018-10-23 04:49:36,161 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 684 Total time for transactions(ms): 78 Number of transactions batched in Syncs: 18 Number of syncs: 527 SyncTimes(ms): 776 
2018-10-23 04:49:36,168 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741950_1128{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /app/hbase/WALs/bootcamp.local,16020,1540143951274/bootcamp.local%2C16020%2C1540143951274.default.1540270176154
2018-10-23 04:49:36,178 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* fsync: /app/hbase/WALs/bootcamp.local,16020,1540143951274/bootcamp.local%2C16020%2C1540143951274.default.1540270176154 for DFSClient_NONMAPREDUCE_187792693_1
2018-10-23 04:49:36,187 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741948_1126{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 83
2018-10-23 04:49:36,189 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /app/hbase/WALs/bootcamp.local,16020,1540143951274/bootcamp.local%2C16020%2C1540143951274.default.1540266569481 is closed by DFSClient_NONMAPREDUCE_187792693_1
2018-10-23 04:49:55,692 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741951_1129{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /app/hbase/WALs/bootcamp.local,16020,1540143951274/bootcamp.local%2C16020%2C1540143951274..meta.1540270195679.meta
2018-10-23 04:49:55,707 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* fsync: /app/hbase/WALs/bootcamp.local,16020,1540143951274/bootcamp.local%2C16020%2C1540143951274..meta.1540270195679.meta for DFSClient_NONMAPREDUCE_187792693_1
2018-10-23 04:49:55,718 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741949_1127{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 83
2018-10-23 04:49:55,720 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /app/hbase/WALs/bootcamp.local,16020,1540143951274/bootcamp.local%2C16020%2C1540143951274..meta.1540266589450.meta is closed by DFSClient_NONMAPREDUCE_187792693_1
2018-10-23 04:57:50,432 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1121ms
No GCs detected
2018-10-23 04:58:02,603 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1147ms
No GCs detected
2018-10-23 07:23:23,163 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741952_1130{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /app/hbase/MasterProcWALs/state-00000000000000000004.log
2018-10-23 07:23:23,163 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 702 Total time for transactions(ms): 80 Number of transactions batched in Syncs: 18 Number of syncs: 539 SyncTimes(ms): 787 
2018-10-23 07:23:23,489 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741951_1129{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 83
2018-10-23 07:23:23,497 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /app/hbase/WALs/bootcamp.local,16020,1540143951274/bootcamp.local%2C16020%2C1540143951274..meta.1540270195679.meta is closed by DFSClient_NONMAPREDUCE_187792693_1
2018-10-23 07:23:23,506 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741950_1128{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 83
2018-10-23 07:23:23,507 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /app/hbase/WALs/bootcamp.local,16020,1540143951274/bootcamp.local%2C16020%2C1540143951274.default.1540270176154 is closed by DFSClient_NONMAPREDUCE_187792693_1
2018-10-23 07:23:23,618 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741952_1130{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 0
2018-10-23 07:23:23,623 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /app/hbase/MasterProcWALs/state-00000000000000000004.log is closed by DFSClient_NONMAPREDUCE_-1372360527_1
2018-10-23 09:23:30,541 WARN org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 65520ms
No GCs detected
2018-10-23 11:23:42,707 WARN org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 45113ms
No GCs detected
2018-10-23 12:53:09,734 WARN org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 29991ms
No GCs detected
2018-10-23 12:53:49,582 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1256ms
No GCs detected
2018-12-07 06:30:44,640 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NameNode
STARTUP_MSG:   host = bootcamp.local/172.18.0.2
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.3
STARTUP_MSG:   classpath = /etc/hadoop/conf:/usr/lib/hadoop/lib/asm-3.2.jar:/usr/lib/hadoop/lib/jackson-jaxrs-1.9.13.jar:/usr/lib/hadoop/lib/api-asn1-api-1.0.0-M20.jar:/usr/lib/hadoop/lib/jersey-json-1.9.jar:/usr/lib/hadoop/lib/gson-2.2.4.jar:/usr/lib/hadoop/lib/commons-net-3.1.jar:/usr/lib/hadoop/lib/commons-digester-1.8.jar:/usr/lib/hadoop/lib/guava-11.0.2.jar:/usr/lib/hadoop/lib/api-util-1.0.0-M20.jar:/usr/lib/hadoop/lib/jets3t-0.9.0.jar:/usr/lib/hadoop/lib/snappy-java-1.0.4.1.jar:/usr/lib/hadoop/lib/commons-compress-1.4.1.jar:/usr/lib/hadoop/lib/activation-1.1.jar:/usr/lib/hadoop/lib/slf4j-log4j12-1.7.10.jar:/usr/lib/hadoop/lib/curator-framework-2.7.1.jar:/usr/lib/hadoop/lib/jackson-core-asl-1.9.13.jar:/usr/lib/hadoop/lib/commons-beanutils-1.7.0.jar:/usr/lib/hadoop/lib/curator-client-2.7.1.jar:/usr/lib/hadoop/lib/jsr305-3.0.0.jar:/usr/lib/hadoop/lib/avro-1.7.4.jar:/usr/lib/hadoop/lib/jackson-xc-1.9.13.jar:/usr/lib/hadoop/lib/commons-configuration-1.6.jar:/usr/lib/hadoop/lib/commons-math3-3.1.1.jar:/usr/lib/hadoop/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/lib/hadoop/lib/jaxb-api-2.2.2.jar:/usr/lib/hadoop/lib/netty-3.6.2.Final.jar:/usr/lib/hadoop/lib/curator-recipes-2.7.1.jar:/usr/lib/hadoop/lib/mockito-all-1.8.5.jar:/usr/lib/hadoop/lib/commons-codec-1.4.jar:/usr/lib/hadoop/lib/jettison-1.1.jar:/usr/lib/hadoop/lib/commons-httpclient-3.1.jar:/usr/lib/hadoop/lib/jsch-0.1.42.jar:/usr/lib/hadoop/lib/java-xmlbuilder-0.4.jar:/usr/lib/hadoop/lib/xz-1.0.jar:/usr/lib/hadoop/lib/commons-logging-1.1.3.jar:/usr/lib/hadoop/lib/log4j-1.2.17.jar:/usr/lib/hadoop/lib/zookeeper-3.4.6.jar:/usr/lib/hadoop/lib/commons-lang-2.6.jar:/usr/lib/hadoop/lib/hamcrest-core-1.3.jar:/usr/lib/hadoop/lib/httpclient-4.2.5.jar:/usr/lib/hadoop/lib/commons-cli-1.2.jar:/usr/lib/hadoop/lib/commons-io-2.4.jar:/usr/lib/hadoop/lib/apacheds-i18n-2.0.0-M15.jar:/usr/lib/hadoop/lib/jetty-util-6.1.26.jar:/usr/lib/hadoop/lib/jackson-mapper-asl-1.9.13.jar:/usr/lib/hadoop/lib/htrace-core-3.1.0-incubating.jar:/usr/lib/hadoop/lib/paranamer-2.3.jar:/usr/lib/hadoop/lib/xmlenc-0.52.jar:/usr/lib/hadoop/lib/jaxb-impl-2.2.3-1.jar:/usr/lib/hadoop/lib/commons-beanutils-core-1.8.0.jar:/usr/lib/hadoop/lib/jersey-server-1.9.jar:/usr/lib/hadoop/lib/slf4j-api-1.7.10.jar:/usr/lib/hadoop/lib/jsp-api-2.1.jar:/usr/lib/hadoop/lib/jetty-6.1.26.jar:/usr/lib/hadoop/lib/junit-4.11.jar:/usr/lib/hadoop/lib/servlet-api-2.5.jar:/usr/lib/hadoop/lib/httpcore-4.2.5.jar:/usr/lib/hadoop/lib/protobuf-java-2.5.0.jar:/usr/lib/hadoop/lib/jersey-core-1.9.jar:/usr/lib/hadoop/lib/stax-api-1.0-2.jar:/usr/lib/hadoop/lib/commons-collections-3.2.2.jar:/usr/lib/hadoop/.//hadoop-nfs.jar:/usr/lib/hadoop/.//hadoop-common.jar:/usr/lib/hadoop/.//hadoop-auth-2.7.3.jar:/usr/lib/hadoop/.//hadoop-common-2.7.3-tests.jar:/usr/lib/hadoop/.//hadoop-common-2.7.3.jar:/usr/lib/hadoop/.//hadoop-auth.jar:/usr/lib/hadoop/.//hadoop-annotations.jar:/usr/lib/hadoop/.//hadoop-annotations-2.7.3.jar:/usr/lib/hadoop/.//hadoop-nfs-2.7.3.jar:/usr/lib/hadoop-hdfs/./:/usr/lib/hadoop-hdfs/lib/asm-3.2.jar:/usr/lib/hadoop-hdfs/lib/xercesImpl-2.9.1.jar:/usr/lib/hadoop-hdfs/lib/guava-11.0.2.jar:/usr/lib/hadoop-hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/lib/hadoop-hdfs/lib/jsr305-3.0.0.jar:/usr/lib/hadoop-hdfs/lib/leveldbjni-all-1.8.jar:/usr/lib/hadoop-hdfs/lib/netty-3.6.2.Final.jar:/usr/lib/hadoop-hdfs/lib/netty-all-4.0.23.Final.jar:/usr/lib/hadoop-hdfs/lib/commons-codec-1.4.jar:/usr/lib/hadoop-hdfs/lib/xml-apis-1.3.04.jar:/usr/lib/hadoop-hdfs/lib/commons-logging-1.1.3.jar:/usr/lib/hadoop-hdfs/lib/log4j-1.2.17.jar:/usr/lib/hadoop-hdfs/lib/commons-lang-2.6.jar:/usr/lib/hadoop-hdfs/lib/commons-cli-1.2.jar:/usr/lib/hadoop-hdfs/lib/commons-io-2.4.jar:/usr/lib/hadoop-hdfs/lib/jetty-util-6.1.26.jar:/usr/lib/hadoop-hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/lib/hadoop-hdfs/lib/htrace-core-3.1.0-incubating.jar:/usr/lib/hadoop-hdfs/lib/xmlenc-0.52.jar:/usr/lib/hadoop-hdfs/lib/jersey-server-1.9.jar:/usr/lib/hadoop-hdfs/lib/jetty-6.1.26.jar:/usr/lib/hadoop-hdfs/lib/commons-daemon-1.0.13.jar:/usr/lib/hadoop-hdfs/lib/servlet-api-2.5.jar:/usr/lib/hadoop-hdfs/lib/protobuf-java-2.5.0.jar:/usr/lib/hadoop-hdfs/lib/jersey-core-1.9.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs-nfs.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs-2.7.3-tests.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs-nfs-2.7.3.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs-2.7.3.jar:/usr/lib/hadoop-yarn/lib/asm-3.2.jar:/usr/lib/hadoop-yarn/lib/jackson-jaxrs-1.9.13.jar:/usr/lib/hadoop-yarn/lib/jersey-json-1.9.jar:/usr/lib/hadoop-yarn/lib/jersey-client-1.9.jar:/usr/lib/hadoop-yarn/lib/guava-11.0.2.jar:/usr/lib/hadoop-yarn/lib/jersey-guice-1.9.jar:/usr/lib/hadoop-yarn/lib/commons-compress-1.4.1.jar:/usr/lib/hadoop-yarn/lib/activation-1.1.jar:/usr/lib/hadoop-yarn/lib/guice-servlet-3.0.jar:/usr/lib/hadoop-yarn/lib/zookeeper-3.4.6-tests.jar:/usr/lib/hadoop-yarn/lib/jackson-core-asl-1.9.13.jar:/usr/lib/hadoop-yarn/lib/jsr305-3.0.0.jar:/usr/lib/hadoop-yarn/lib/jackson-xc-1.9.13.jar:/usr/lib/hadoop-yarn/lib/leveldbjni-all-1.8.jar:/usr/lib/hadoop-yarn/lib/jaxb-api-2.2.2.jar:/usr/lib/hadoop-yarn/lib/netty-3.6.2.Final.jar:/usr/lib/hadoop-yarn/lib/javax.inject-1.jar:/usr/lib/hadoop-yarn/lib/commons-codec-1.4.jar:/usr/lib/hadoop-yarn/lib/jettison-1.1.jar:/usr/lib/hadoop-yarn/lib/guice-3.0.jar:/usr/lib/hadoop-yarn/lib/xz-1.0.jar:/usr/lib/hadoop-yarn/lib/commons-logging-1.1.3.jar:/usr/lib/hadoop-yarn/lib/log4j-1.2.17.jar:/usr/lib/hadoop-yarn/lib/zookeeper-3.4.6.jar:/usr/lib/hadoop-yarn/lib/commons-lang-2.6.jar:/usr/lib/hadoop-yarn/lib/commons-cli-1.2.jar:/usr/lib/hadoop-yarn/lib/commons-io-2.4.jar:/usr/lib/hadoop-yarn/lib/jetty-util-6.1.26.jar:/usr/lib/hadoop-yarn/lib/jackson-mapper-asl-1.9.13.jar:/usr/lib/hadoop-yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/lib/hadoop-yarn/lib/jersey-server-1.9.jar:/usr/lib/hadoop-yarn/lib/aopalliance-1.0.jar:/usr/lib/hadoop-yarn/lib/jetty-6.1.26.jar:/usr/lib/hadoop-yarn/lib/servlet-api-2.5.jar:/usr/lib/hadoop-yarn/lib/protobuf-java-2.5.0.jar:/usr/lib/hadoop-yarn/lib/jersey-core-1.9.jar:/usr/lib/hadoop-yarn/lib/stax-api-1.0-2.jar:/usr/lib/hadoop-yarn/lib/commons-collections-3.2.2.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-resourcemanager.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-resourcemanager-2.7.3.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-applicationhistoryservice-2.7.3.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-registry.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-tests.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-common.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-common-2.7.3.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-applications-distributedshell.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-client.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-common-2.7.3.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-applications-unmanaged-am-launcher.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-web-proxy.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-api.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-tests-2.7.3.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-nodemanager-2.7.3.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-api-2.7.3.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-sharedcachemanager-2.7.3.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-common.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-client-2.7.3.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-nodemanager.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-sharedcachemanager.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-registry-2.7.3.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-applications-unmanaged-am-launcher-2.7.3.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-web-proxy-2.7.3.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-applicationhistoryservice.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-applications-distributedshell-2.7.3.jar:/usr/lib/hadoop-mapreduce/lib/asm-3.2.jar:/usr/lib/hadoop-mapreduce/lib/jersey-guice-1.9.jar:/usr/lib/hadoop-mapreduce/lib/snappy-java-1.0.4.1.jar:/usr/lib/hadoop-mapreduce/lib/commons-compress-1.4.1.jar:/usr/lib/hadoop-mapreduce/lib/guice-servlet-3.0.jar:/usr/lib/hadoop-mapreduce/lib/jackson-core-asl-1.9.13.jar:/usr/lib/hadoop-mapreduce/lib/avro-1.7.4.jar:/usr/lib/hadoop-mapreduce/lib/leveldbjni-all-1.8.jar:/usr/lib/hadoop-mapreduce/lib/netty-3.6.2.Final.jar:/usr/lib/hadoop-mapreduce/lib/javax.inject-1.jar:/usr/lib/hadoop-mapreduce/lib/guice-3.0.jar:/usr/lib/hadoop-mapreduce/lib/xz-1.0.jar:/usr/lib/hadoop-mapreduce/lib/log4j-1.2.17.jar:/usr/lib/hadoop-mapreduce/lib/hamcrest-core-1.3.jar:/usr/lib/hadoop-mapreduce/lib/commons-io-2.4.jar:/usr/lib/hadoop-mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/usr/lib/hadoop-mapreduce/lib/paranamer-2.3.jar:/usr/lib/hadoop-mapreduce/lib/jersey-server-1.9.jar:/usr/lib/hadoop-mapreduce/lib/aopalliance-1.0.jar:/usr/lib/hadoop-mapreduce/lib/junit-4.11.jar:/usr/lib/hadoop-mapreduce/lib/protobuf-java-2.5.0.jar:/usr/lib/hadoop-mapreduce/lib/jersey-core-1.9.jar:/usr/lib/hadoop-mapreduce/.//jackson-core-2.2.3.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-jobclient-2.7.3-tests.jar:/usr/lib/hadoop-mapreduce/.//azure-storage-2.0.0.jar:/usr/lib/hadoop-mapreduce/.//metrics-core-3.0.1.jar:/usr/lib/hadoop-mapreduce/.//asm-3.2.jar:/usr/lib/hadoop-mapreduce/.//jackson-jaxrs-1.9.13.jar:/usr/lib/hadoop-mapreduce/.//hadoop-sls-2.7.3.jar:/usr/lib/hadoop-mapreduce/.//api-asn1-api-1.0.0-M20.jar:/usr/lib/hadoop-mapreduce/.//jersey-json-1.9.jar:/usr/lib/hadoop-mapreduce/.//gson-2.2.4.jar:/usr/lib/hadoop-mapreduce/.//commons-net-3.1.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-app-2.7.3.jar:/usr/lib/hadoop-mapreduce/.//commons-digester-1.8.jar:/usr/lib/hadoop-mapreduce/.//guava-11.0.2.jar:/usr/lib/hadoop-mapreduce/.//api-util-1.0.0-M20.jar:/usr/lib/hadoop-mapreduce/.//jets3t-0.9.0.jar:/usr/lib/hadoop-mapreduce/.//snappy-java-1.0.4.1.jar:/usr/lib/hadoop-mapreduce/.//hadoop-streaming-2.7.3.jar:/usr/lib/hadoop-mapreduce/.//commons-compress-1.4.1.jar:/usr/lib/hadoop-mapreduce/.//activation-1.1.jar:/usr/lib/hadoop-mapreduce/.//curator-framework-2.7.1.jar:/usr/lib/hadoop-mapreduce/.//hadoop-archives.jar:/usr/lib/hadoop-mapreduce/.//hadoop-aws.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-core.jar:/usr/lib/hadoop-mapreduce/.//jackson-core-asl-1.9.13.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-hs.jar:/usr/lib/hadoop-mapreduce/.//commons-beanutils-1.7.0.jar:/usr/lib/hadoop-mapreduce/.//curator-client-2.7.1.jar:/usr/lib/hadoop-mapreduce/.//hadoop-azure-2.7.3.jar:/usr/lib/hadoop-mapreduce/.//jsr305-3.0.0.jar:/usr/lib/hadoop-mapreduce/.//avro-1.7.4.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-jobclient.jar:/usr/lib/hadoop-mapreduce/.//hadoop-gridmix.jar:/usr/lib/hadoop-mapreduce/.//hadoop-distcp.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-app.jar:/usr/lib/hadoop-mapreduce/.//jackson-xc-1.9.13.jar:/usr/lib/hadoop-mapreduce/.//hadoop-auth-2.7.3.jar:/usr/lib/hadoop-mapreduce/.//commons-configuration-1.6.jar:/usr/lib/hadoop-mapreduce/.//commons-math3-3.1.1.jar:/usr/lib/hadoop-mapreduce/.//hadoop-datajoin-2.7.3.jar:/usr/lib/hadoop-mapreduce/.//apacheds-kerberos-codec-2.0.0-M15.jar:/usr/lib/hadoop-mapreduce/.//hadoop-gridmix-2.7.3.jar:/usr/lib/hadoop-mapreduce/.//hadoop-ant.jar:/usr/lib/hadoop-mapreduce/.//hadoop-auth.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-shuffle-2.7.3.jar:/usr/lib/hadoop-mapreduce/.//jaxb-api-2.2.2.jar:/usr/lib/hadoop-mapreduce/.//netty-3.6.2.Final.jar:/usr/lib/hadoop-mapreduce/.//curator-recipes-2.7.1.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-hs-plugins.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-common-2.7.3.jar:/usr/lib/hadoop-mapreduce/.//mockito-all-1.8.5.jar:/usr/lib/hadoop-mapreduce/.//joda-time-2.9.9.jar:/usr/lib/hadoop-mapreduce/.//hadoop-openstack.jar:/usr/lib/hadoop-mapreduce/.//jackson-annotations-2.2.3.jar:/usr/lib/hadoop-mapreduce/.//commons-codec-1.4.jar:/usr/lib/hadoop-mapreduce/.//hadoop-extras-2.7.3.jar:/usr/lib/hadoop-mapreduce/.//jettison-1.1.jar:/usr/lib/hadoop-mapreduce/.//hadoop-distcp-2.7.3.jar:/usr/lib/hadoop-mapreduce/.//commons-httpclient-3.1.jar:/usr/lib/hadoop-mapreduce/.//jsch-0.1.42.jar:/usr/lib/hadoop-mapreduce/.//hadoop-sls.jar:/usr/lib/hadoop-mapreduce/.//jackson-databind-2.2.3.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-hs-2.7.3.jar:/usr/lib/hadoop-mapreduce/.//java-xmlbuilder-0.4.jar:/usr/lib/hadoop-mapreduce/.//aws-java-sdk-1.7.4.jar:/usr/lib/hadoop-mapreduce/.//hadoop-aws-2.7.3.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-examples-2.7.3.jar:/usr/lib/hadoop-mapreduce/.//xz-1.0.jar:/usr/lib/hadoop-mapreduce/.//hadoop-rumen.jar:/usr/lib/hadoop-mapreduce/.//commons-logging-1.1.3.jar:/usr/lib/hadoop-mapreduce/.//log4j-1.2.17.jar:/usr/lib/hadoop-mapreduce/.//zookeeper-3.4.6.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-core-2.7.3.jar:/usr/lib/hadoop-mapreduce/.//hadoop-datajoin.jar:/usr/lib/hadoop-mapreduce/.//commons-lang-2.6.jar:/usr/lib/hadoop-mapreduce/.//commons-lang3-3.3.2.jar:/usr/lib/hadoop-mapreduce/.//hamcrest-core-1.3.jar:/usr/lib/hadoop-mapreduce/.//httpclient-4.2.5.jar:/usr/lib/hadoop-mapreduce/.//commons-cli-1.2.jar:/usr/lib/hadoop-mapreduce/.//commons-io-2.4.jar:/usr/lib/hadoop-mapreduce/.//apacheds-i18n-2.0.0-M15.jar:/usr/lib/hadoop-mapreduce/.//jetty-util-6.1.26.jar:/usr/lib/hadoop-mapreduce/.//jackson-mapper-asl-1.9.13.jar:/usr/lib/hadoop-mapreduce/.//hadoop-archives-2.7.3.jar:/usr/lib/hadoop-mapreduce/.//htrace-core-3.1.0-incubating.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-common.jar:/usr/lib/hadoop-mapreduce/.//paranamer-2.3.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-jobclient-2.7.3.jar:/usr/lib/hadoop-mapreduce/.//hadoop-extras.jar:/usr/lib/hadoop-mapreduce/.//xmlenc-0.52.jar:/usr/lib/hadoop-mapreduce/.//hadoop-openstack-2.7.3.jar:/usr/lib/hadoop-mapreduce/.//jaxb-impl-2.2.3-1.jar:/usr/lib/hadoop-mapreduce/.//commons-beanutils-core-1.8.0.jar:/usr/lib/hadoop-mapreduce/.//jersey-server-1.9.jar:/usr/lib/hadoop-mapreduce/.//jsp-api-2.1.jar:/usr/lib/hadoop-mapreduce/.//jetty-6.1.26.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-hs-plugins-2.7.3.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-examples.jar:/usr/lib/hadoop-mapreduce/.//junit-4.11.jar:/usr/lib/hadoop-mapreduce/.//hadoop-azure.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-shuffle.jar:/usr/lib/hadoop-mapreduce/.//hadoop-streaming.jar:/usr/lib/hadoop-mapreduce/.//hadoop-ant-2.7.3.jar:/usr/lib/hadoop-mapreduce/.//servlet-api-2.5.jar:/usr/lib/hadoop-mapreduce/.//httpcore-4.2.5.jar:/usr/lib/hadoop-mapreduce/.//hadoop-rumen-2.7.3.jar:/usr/lib/hadoop-mapreduce/.//protobuf-java-2.5.0.jar:/usr/lib/hadoop-mapreduce/.//jersey-core-1.9.jar:/usr/lib/hadoop-mapreduce/.//stax-api-1.0-2.jar:/usr/lib/hadoop-mapreduce/.//commons-collections-3.2.2.jar:/usr/lib/hadoop/contrib/capacity-scheduler/*.jar:/usr/lib/hadoop/contrib/capacity-scheduler/*.jar:/usr/lib/hadoop/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/bigtop.git -r 2365207dc0440bb884e41d4ffe32a37ad0d0ed28; compiled by 'jenkins' on 2017-10-05T21:00Z
STARTUP_MSG:   java = 1.8.0_181
************************************************************/
2018-12-07 06:30:44,651 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2018-12-07 06:30:44,655 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: createNameNode []
2018-12-07 06:30:44,953 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2018-12-07 06:30:45,029 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2018-12-07 06:30:45,029 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NameNode metrics system started
2018-12-07 06:30:45,033 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: fs.defaultFS is hdfs://bootcamp.local:9000
2018-12-07 06:30:45,034 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Clients are to use bootcamp.local:9000 to access this namenode/service.
2018-12-07 06:30:45,187 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for hdfs at: http://0.0.0.0:50070
2018-12-07 06:30:45,248 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2018-12-07 06:30:45,256 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2018-12-07 06:30:45,262 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.namenode is not defined
2018-12-07 06:30:45,270 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2018-12-07 06:30:45,272 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2018-12-07 06:30:45,273 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2018-12-07 06:30:45,273 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2018-12-07 06:30:45,431 INFO org.apache.hadoop.http.HttpServer2: Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2018-12-07 06:30:45,434 INFO org.apache.hadoop.http.HttpServer2: addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2018-12-07 06:30:45,452 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50070
2018-12-07 06:30:45,453 INFO org.mortbay.log: jetty-6.1.26
2018-12-07 06:30:45,707 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:50070
2018-12-07 06:30:45,792 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one image storage directory (dfs.namenode.name.dir) configured. Beware of data loss due to lack of redundant storage directories!
2018-12-07 06:30:45,792 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one namespace edits storage directory (dfs.namenode.edits.dir) configured. Beware of data loss due to lack of redundant storage directories!
2018-12-07 06:30:45,847 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: No KeyProvider found.
2018-12-07 06:30:45,847 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair:true
2018-12-07 06:30:45,913 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2018-12-07 06:30:45,914 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2018-12-07 06:30:45,915 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2018-12-07 06:30:45,916 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2018 Dec 07 06:30:45
2018-12-07 06:30:45,918 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2018-12-07 06:30:45,918 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2018-12-07 06:30:45,921 INFO org.apache.hadoop.util.GSet: 2.0% max memory 889 MB = 17.8 MB
2018-12-07 06:30:45,921 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2018-12-07 06:30:45,927 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2018-12-07 06:30:45,928 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 1
2018-12-07 06:30:45,928 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2018-12-07 06:30:45,928 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2018-12-07 06:30:45,929 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2018-12-07 06:30:45,929 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2018-12-07 06:30:45,929 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2018-12-07 06:30:45,930 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2018-12-07 06:30:45,936 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = hdfs (auth:SIMPLE)
2018-12-07 06:30:45,936 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2018-12-07 06:30:45,937 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2018-12-07 06:30:45,937 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2018-12-07 06:30:45,939 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2018-12-07 06:30:46,006 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2018-12-07 06:30:46,007 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2018-12-07 06:30:46,007 INFO org.apache.hadoop.util.GSet: 1.0% max memory 889 MB = 8.9 MB
2018-12-07 06:30:46,008 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2018-12-07 06:30:46,009 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: ACLs enabled? false
2018-12-07 06:30:46,009 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: XAttrs enabled? true
2018-12-07 06:30:46,010 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Maximum size of an xattr: 16384
2018-12-07 06:30:46,010 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times
2018-12-07 06:30:46,017 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2018-12-07 06:30:46,017 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2018-12-07 06:30:46,018 INFO org.apache.hadoop.util.GSet: 0.25% max memory 889 MB = 2.2 MB
2018-12-07 06:30:46,018 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2018-12-07 06:30:46,019 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2018-12-07 06:30:46,020 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2018-12-07 06:30:46,020 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2018-12-07 06:30:46,024 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.window.num.buckets = 10
2018-12-07 06:30:46,024 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.num.users = 10
2018-12-07 06:30:46,024 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2018-12-07 06:30:46,026 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache on namenode is enabled
2018-12-07 06:30:46,026 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2018-12-07 06:30:46,028 INFO org.apache.hadoop.util.GSet: Computing capacity for map NameNodeRetryCache
2018-12-07 06:30:46,028 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2018-12-07 06:30:46,029 INFO org.apache.hadoop.util.GSet: 0.029999999329447746% max memory 889 MB = 273.1 KB
2018-12-07 06:30:46,029 INFO org.apache.hadoop.util.GSet: capacity      = 2^15 = 32768 entries
2018-12-07 06:30:46,045 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /data/name/in_use.lock acquired by nodename 742@bootcamp.local
2018-12-07 06:30:46,087 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Recovering unfinalized segments in /data/name/current
2018-12-07 06:30:46,246 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /data/name/current/edits_inprogress_0000000000000000001 -> /data/name/current/edits_0000000000000000001-0000000000000000014
2018-12-07 06:30:46,257 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Planning to load image: FSImageFile(file=/data/name/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2018-12-07 06:30:46,283 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Loading 1 INodes.
2018-12-07 06:30:46,306 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Loaded FSImage in 0 seconds.
2018-12-07 06:30:46,307 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 0 from /data/name/current/fsimage_0000000000000000000
2018-12-07 06:30:46,308 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@2cae1042 expecting start txid #1
2018-12-07 06:30:46,308 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /data/name/current/edits_0000000000000000001-0000000000000000014
2018-12-07 06:30:46,310 INFO org.apache.hadoop.hdfs.server.namenode.EditLogInputStream: Fast-forwarding stream '/data/name/current/edits_0000000000000000001-0000000000000000014' to transaction ID 1
2018-12-07 06:30:46,327 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /data/name/current/edits_0000000000000000001-0000000000000000014 of size 1048576 edits # 14 loaded in 0 seconds
2018-12-07 06:30:46,328 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Need to save fs image? true (staleImage=true, haEnabled=false, isRollingUpgrade=false)
2018-12-07 06:30:46,329 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Save namespace ...
2018-12-07 06:30:46,334 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /data/name/current/fsimage.ckpt_0000000000000000014 using no compression
2018-12-07 06:30:46,365 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /data/name/current/fsimage.ckpt_0000000000000000014 of size 804 bytes saved in 0 seconds.
2018-12-07 06:30:46,371 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 0
2018-12-07 06:30:46,380 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 15
2018-12-07 06:30:46,483 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2018-12-07 06:30:46,486 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Finished loading FSImage in 453 msecs
2018-12-07 06:30:46,725 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: RPC server is binding to bootcamp.local:9000
2018-12-07 06:30:46,730 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2018-12-07 06:30:46,740 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 9000
2018-12-07 06:30:46,766 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Registered FSNamesystemState MBean
2018-12-07 06:30:46,778 INFO org.apache.hadoop.hdfs.server.namenode.LeaseManager: Number of blocks under construction: 0
2018-12-07 06:30:46,779 INFO org.apache.hadoop.hdfs.server.namenode.LeaseManager: Number of blocks under construction: 0
2018-12-07 06:30:46,779 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: initializing replication queues
2018-12-07 06:30:46,780 INFO org.apache.hadoop.hdfs.StateChange: STATE* Leaving safe mode after 0 secs
2018-12-07 06:30:46,780 INFO org.apache.hadoop.hdfs.StateChange: STATE* Network topology has 0 racks and 0 datanodes
2018-12-07 06:30:46,780 INFO org.apache.hadoop.hdfs.StateChange: STATE* UnderReplicatedBlocks has 0 blocks
2018-12-07 06:30:46,786 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Number of failed storage changes from 0 to 0
2018-12-07 06:30:46,788 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Total number of blocks            = 0
2018-12-07 06:30:46,788 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of invalid blocks          = 0
2018-12-07 06:30:46,789 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of under-replicated blocks = 0
2018-12-07 06:30:46,789 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of  over-replicated blocks = 0
2018-12-07 06:30:46,790 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of blocks being written    = 0
2018-12-07 06:30:46,790 INFO org.apache.hadoop.hdfs.StateChange: STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 10 msec
2018-12-07 06:30:46,814 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2018-12-07 06:30:46,814 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 9000: starting
2018-12-07 06:30:46,819 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: NameNode RPC up at: bootcamp.local/172.18.0.2:9000
2018-12-07 06:30:46,820 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Starting services required for active state
2018-12-07 06:30:46,825 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Starting CacheReplicationMonitor with interval 30000 milliseconds
2018-12-07 06:30:55,626 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(172.18.0.2:50010, datanodeUuid=47ecd31e-43cd-4989-84ba-314b1664d0de, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-747ab8c6-1ec4-46a0-9dee-c8151846aca5;nsid=199960936;c=0) storage 47ecd31e-43cd-4989-84ba-314b1664d0de
2018-12-07 06:30:55,627 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Number of failed storage changes from 0 to 0
2018-12-07 06:30:55,628 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/172.18.0.2:50010
2018-12-07 06:30:55,741 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Number of failed storage changes from 0 to 0
2018-12-07 06:30:55,742 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Adding new storage ID DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5 for DN 172.18.0.2:50010
2018-12-07 06:30:55,797 INFO BlockStateChange: BLOCK* processReport: from storage DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5 node DatanodeRegistration(172.18.0.2:50010, datanodeUuid=47ecd31e-43cd-4989-84ba-314b1664d0de, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-747ab8c6-1ec4-46a0-9dee-c8151846aca5;nsid=199960936;c=0), blocks: 0, hasStaleStorage: false, processing time: 1 msecs
2018-12-07 06:31:21,598 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741825_1001{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /app/hbase/.tmp/hbase.version
2018-12-07 06:31:21,930 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* blk_1073741825_1001{UCState=COMMITTED, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} is not COMPLETE (ucState = COMMITTED, replication# = 0 <  minimum = 1) in file /app/hbase/.tmp/hbase.version
2018-12-07 06:31:21,931 INFO org.apache.hadoop.hdfs.server.namenode.EditLogFileOutputStream: Nothing to flush
2018-12-07 06:31:21,962 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741825_1001{UCState=COMMITTED, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 7
2018-12-07 06:31:22,352 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /app/hbase/.tmp/hbase.version is closed by DFSClient_NONMAPREDUCE_-1459410254_1
2018-12-07 06:31:22,381 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741826_1002{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /app/hbase/.tmp/hbase.id
2018-12-07 06:31:22,395 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741826_1002{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 0
2018-12-07 06:31:22,398 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /app/hbase/.tmp/hbase.id is closed by DFSClient_NONMAPREDUCE_-1459410254_1
2018-12-07 06:31:22,507 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741827_1003{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /app/hbase/data/hbase/meta/1588230740/.regioninfo
2018-12-07 06:31:22,522 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741827_1003{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 0
2018-12-07 06:31:22,524 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /app/hbase/data/hbase/meta/1588230740/.regioninfo is closed by DFSClient_NONMAPREDUCE_-1459410254_1
2018-12-07 06:31:22,676 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /app/hbase/data/hbase/meta/1588230740/recovered.edits/2.seqid is closed by DFSClient_NONMAPREDUCE_-1459410254_1
2018-12-07 06:31:22,702 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741828_1004{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /app/hbase/data/hbase/meta/.tmp/.tableinfo.0000000001
2018-12-07 06:31:22,719 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741828_1004{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 0
2018-12-07 06:31:22,721 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /app/hbase/data/hbase/meta/.tmp/.tableinfo.0000000001 is closed by DFSClient_NONMAPREDUCE_-1459410254_1
2018-12-07 06:31:23,505 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741829_1005{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /app/hbase/WALs/bootcamp.local,16020,1544164277809/bootcamp.local%2C16020%2C1544164277809.default.1544164283447
2018-12-07 06:31:23,600 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* fsync: /app/hbase/WALs/bootcamp.local,16020,1544164277809/bootcamp.local%2C16020%2C1544164277809.default.1544164283447 for DFSClient_NONMAPREDUCE_1982901237_1
2018-12-07 06:31:28,544 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741830_1006{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /app/hbase/WALs/bootcamp.local,16020,1544164277809/bootcamp.local%2C16020%2C1544164277809..meta.1544164288528.meta
2018-12-07 06:31:28,558 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* fsync: /app/hbase/WALs/bootcamp.local,16020,1544164277809/bootcamp.local%2C16020%2C1544164277809..meta.1544164288528.meta for DFSClient_NONMAPREDUCE_1982901237_1
2018-12-07 06:31:28,774 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /app/hbase/data/hbase/meta/1588230740/recovered.edits/3.seqid is closed by DFSClient_NONMAPREDUCE_1982901237_1
2018-12-07 06:31:29,079 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741831_1007{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /app/hbase/MasterProcWALs/state-00000000000000000001.log
2018-12-07 06:31:29,095 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* fsync: /app/hbase/MasterProcWALs/state-00000000000000000001.log for DFSClient_NONMAPREDUCE_-1459410254_1
2018-12-07 06:31:29,253 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741832_1008{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /app/hbase/.tmp/data/hbase/namespace/.tmp/.tableinfo.0000000001
2018-12-07 06:31:29,269 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741832_1008{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 0
2018-12-07 06:31:29,272 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /app/hbase/.tmp/data/hbase/namespace/.tmp/.tableinfo.0000000001 is closed by DFSClient_NONMAPREDUCE_-1459410254_1
2018-12-07 06:31:29,294 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741833_1009{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /app/hbase/.tmp/data/hbase/namespace/00cd1087428e356f701fbc2cacd741e9/.regioninfo
2018-12-07 06:31:29,305 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741833_1009{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 0
2018-12-07 06:31:29,307 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /app/hbase/.tmp/data/hbase/namespace/00cd1087428e356f701fbc2cacd741e9/.regioninfo is closed by DFSClient_NONMAPREDUCE_-1459410254_1
2018-12-07 06:31:29,720 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /app/hbase/data/hbase/namespace/00cd1087428e356f701fbc2cacd741e9/recovered.edits/2.seqid is closed by DFSClient_NONMAPREDUCE_1982901237_1
2018-12-07 06:33:22,724 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 91 Total time for transactions(ms): 9 Number of transactions batched in Syncs: 8 Number of syncs: 57 SyncTimes(ms): 58 
2018-12-07 06:34:11,435 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741834_1010{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /ccs/ccs_dx_map/ccs_dx_map.csv._COPYING_
2018-12-07 06:34:11,536 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741834_1010{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 0
2018-12-07 06:34:11,539 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /ccs/ccs_dx_map/ccs_dx_map.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1691221048_1
2018-12-07 06:34:13,359 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741835_1011{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /ccs/ccs_proc_map/ccs_proc_map.csv._COPYING_
2018-12-07 06:34:13,461 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741835_1011{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 0
2018-12-07 06:34:13,467 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /ccs/ccs_proc_map/ccs_proc_map.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1497407110_1
2018-12-07 06:36:51,566 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 108 Total time for transactions(ms): 10 Number of transactions batched in Syncs: 8 Number of syncs: 70 SyncTimes(ms): 75 
2018-12-07 06:36:51,604 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741836_1012{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /app/hbase/data/hbase/meta/1588230740/.tmp/7b451b22ba9e4ef1bf5136e5aaa4da27
2018-12-07 06:36:51,625 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741836_1012{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 0
2018-12-07 06:36:51,627 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /app/hbase/data/hbase/meta/1588230740/.tmp/7b451b22ba9e4ef1bf5136e5aaa4da27 is closed by DFSClient_NONMAPREDUCE_1982901237_1
2018-12-07 06:37:27,060 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741837_1013{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /ccs/ccs_dx_map/ccs_dx_map.csv._COPYING_
2018-12-07 06:37:27,161 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741837_1013{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 0
2018-12-07 06:37:27,167 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /ccs/ccs_dx_map/ccs_dx_map.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_1936840532_1
2018-12-07 06:37:27,173 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741834_1010 172.18.0.2:50010 
2018-12-07 06:37:28,663 INFO BlockStateChange: BLOCK* BlockManager: ask 172.18.0.2:50010 to delete [blk_1073741834_1010]
2018-12-07 06:37:29,079 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741838_1014{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /ccs/ccs_proc_map/ccs_proc_map.csv._COPYING_
2018-12-07 06:37:29,182 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741838_1014{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 0
2018-12-07 06:37:29,186 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /ccs/ccs_proc_map/ccs_proc_map.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_989699574_1
2018-12-07 06:37:29,192 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741835_1011 172.18.0.2:50010 
2018-12-07 06:37:31,666 INFO BlockStateChange: BLOCK* BlockManager: ask 172.18.0.2:50010 to delete [blk_1073741835_1011]
2018-12-07 06:38:06,888 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 130 Total time for transactions(ms): 12 Number of transactions batched in Syncs: 8 Number of syncs: 85 SyncTimes(ms): 96 
2018-12-07 06:40:01,857 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 143 Total time for transactions(ms): 14 Number of transactions batched in Syncs: 8 Number of syncs: 98 SyncTimes(ms): 126 
2018-12-07 06:40:34,595 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741839_1015{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /mimic/admissions/ADMISSIONS.csv._COPYING_
2018-12-07 06:40:34,683 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741839_1015{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 0
2018-12-07 06:40:34,687 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /mimic/admissions/ADMISSIONS.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_-11860980_1
2018-12-07 06:40:36,656 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741840_1016{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /mimic/callout/CALLOUT.csv._COPYING_
2018-12-07 06:40:36,749 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741840_1016{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 0
2018-12-07 06:40:36,752 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /mimic/callout/CALLOUT.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1872806752_1
2018-12-07 06:40:38,522 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741841_1017{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /mimic/caregivers/CAREGIVERS.csv._COPYING_
2018-12-07 06:40:38,638 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741841_1017{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 0
2018-12-07 06:40:38,643 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /mimic/caregivers/CAREGIVERS.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_460065536_1
2018-12-07 06:40:40,571 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741842_1018{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /mimic/chartevents/CHARTEVENTS.csv._COPYING_
2018-12-07 06:40:40,679 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741842_1018{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 0
2018-12-07 06:40:40,684 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /mimic/chartevents/CHARTEVENTS.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_373431823_1
2018-12-07 06:40:42,582 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741843_1019{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /mimic/cptevents/CPTEVENTS.csv._COPYING_
2018-12-07 06:40:42,701 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741843_1019{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 0
2018-12-07 06:40:42,705 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /mimic/cptevents/CPTEVENTS.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1478699980_1
2018-12-07 06:40:44,537 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741844_1020{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /mimic/datetimeevents/DATETIMEEVENTS.csv._COPYING_
2018-12-07 06:40:44,647 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741844_1020{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 0
2018-12-07 06:40:44,652 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /mimic/datetimeevents/DATETIMEEVENTS.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_-219667569_1
2018-12-07 06:40:46,584 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741845_1021{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /mimic/diagnoses_icd/DIAGNOSES_ICD.csv._COPYING_
2018-12-07 06:40:46,674 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741845_1021{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 0
2018-12-07 06:40:46,680 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /mimic/diagnoses_icd/DIAGNOSES_ICD.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1125295155_1
2018-12-07 06:40:48,771 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741846_1022{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /mimic/drgcodes/DRGCODES.csv._COPYING_
2018-12-07 06:40:48,898 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741846_1022{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 0
2018-12-07 06:40:48,903 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /mimic/drgcodes/DRGCODES.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_1831954406_1
2018-12-07 06:40:50,814 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741847_1023{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /mimic/d_cpt/D_CPT.csv._COPYING_
2018-12-07 06:40:50,903 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741847_1023{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 0
2018-12-07 06:40:50,907 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /mimic/d_cpt/D_CPT.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1938172165_1
2018-12-07 06:40:52,698 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741848_1024{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /mimic/d_icd_diagnoses/D_ICD_DIAGNOSES.csv._COPYING_
2018-12-07 06:40:52,817 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741848_1024{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 0
2018-12-07 06:40:52,821 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /mimic/d_icd_diagnoses/D_ICD_DIAGNOSES.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_-209113270_1
2018-12-07 06:40:54,637 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741849_1025{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /mimic/d_icd_procedures/D_ICD_PROCEDURES.csv._COPYING_
2018-12-07 06:40:54,731 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741849_1025{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 0
2018-12-07 06:40:54,735 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /mimic/d_icd_procedures/D_ICD_PROCEDURES.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_906941046_1
2018-12-07 06:40:56,793 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741850_1026{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /mimic/d_items/D_ITEMS.csv._COPYING_
2018-12-07 06:40:56,925 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741850_1026{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 0
2018-12-07 06:40:56,928 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /mimic/d_items/D_ITEMS.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_-254925462_1
2018-12-07 06:40:58,869 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741851_1027{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /mimic/d_labitems/D_LABITEMS.csv._COPYING_
2018-12-07 06:40:58,963 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741851_1027{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 0
2018-12-07 06:40:58,967 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /mimic/d_labitems/D_LABITEMS.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1897614381_1
2018-12-07 06:41:00,968 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741852_1028{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /mimic/icustays/ICUSTAYS.csv._COPYING_
2018-12-07 06:41:01,064 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741852_1028{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 0
2018-12-07 06:41:01,070 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /mimic/icustays/ICUSTAYS.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_-102236906_1
2018-12-07 06:41:02,972 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 267 Total time for transactions(ms): 22 Number of transactions batched in Syncs: 8 Number of syncs: 194 SyncTimes(ms): 281 
2018-12-07 06:41:03,000 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741853_1029{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /mimic/inputevents_cv/INPUTEVENTS_CV.csv._COPYING_
2018-12-07 06:41:03,099 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741853_1029{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 0
2018-12-07 06:41:03,104 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /mimic/inputevents_cv/INPUTEVENTS_CV.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_-294807613_1
2018-12-07 06:41:05,290 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741854_1030{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /mimic/inputevents_mv/INPUTEVENTS_MV.csv._COPYING_
2018-12-07 06:41:05,384 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741854_1030{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 0
2018-12-07 06:41:05,388 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /mimic/inputevents_mv/INPUTEVENTS_MV.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_2016381621_1
2018-12-07 06:41:07,661 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741855_1031{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /mimic/labevents/LABEVENTS.csv._COPYING_
2018-12-07 06:41:07,772 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741855_1031{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 0
2018-12-07 06:41:07,777 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /mimic/labevents/LABEVENTS.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_686988397_1
2018-12-07 06:41:10,007 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741856_1032{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /mimic/microbiologyevents/MICROBIOLOGYEVENTS.csv._COPYING_
2018-12-07 06:41:10,122 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741856_1032{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 0
2018-12-07 06:41:10,128 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /mimic/microbiologyevents/MICROBIOLOGYEVENTS.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_-822473448_1
2018-12-07 06:41:12,346 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741857_1033{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /mimic/notevents/NOTEEVENTS.csv._COPYING_
2018-12-07 06:41:12,465 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741857_1033{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 0
2018-12-07 06:41:12,469 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /mimic/notevents/NOTEEVENTS.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_1748891203_1
2018-12-07 06:41:14,802 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741858_1034{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /mimic/outputevents/OUTPUTEVENTS.csv._COPYING_
2018-12-07 06:41:14,906 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741858_1034{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 0
2018-12-07 06:41:14,912 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /mimic/outputevents/OUTPUTEVENTS.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_1758504546_1
2018-12-07 06:41:17,326 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741859_1035{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /mimic/patients/PATIENTS.csv._COPYING_
2018-12-07 06:41:17,476 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741859_1035{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 0
2018-12-07 06:41:17,495 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /mimic/patients/PATIENTS.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_1364526136_1
2018-12-07 06:41:19,848 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741860_1036{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /mimic/prescriptions/PRESCRIPTIONS.csv._COPYING_
2018-12-07 06:41:19,955 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741860_1036{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 0
2018-12-07 06:41:19,959 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /mimic/prescriptions/PRESCRIPTIONS.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1515823318_1
2018-12-07 06:41:22,009 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741861_1037{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /mimic/procedureevents_mv/PROCEDUREEVENTS_MV.csv._COPYING_
2018-12-07 06:41:22,114 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741861_1037{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 0
2018-12-07 06:41:22,118 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /mimic/procedureevents_mv/PROCEDUREEVENTS_MV.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_125904973_1
2018-12-07 06:41:24,200 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741862_1038{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /mimic/procedures_icd/PROCEDURES_ICD.csv._COPYING_
2018-12-07 06:41:24,414 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741862_1038{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 0
2018-12-07 06:41:24,417 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /mimic/procedures_icd/PROCEDURES_ICD.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_-481392722_1
2018-12-07 06:41:26,297 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741863_1039{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /mimic/services/SERVICES.csv._COPYING_
2018-12-07 06:41:26,396 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741863_1039{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 0
2018-12-07 06:41:26,401 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /mimic/services/SERVICES.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_985916999_1
2018-12-07 06:41:28,407 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741864_1040{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /mimic/transfers/TRANSFERS.csv._COPYING_
2018-12-07 06:41:28,543 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741864_1040{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 0
2018-12-07 06:41:28,546 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /mimic/transfers/TRANSFERS.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_1727355337_1
2018-12-07 06:41:30,757 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741865_1041{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /ccs/ccs_dx_map/ccs_dx_map.csv._COPYING_
2018-12-07 06:41:30,881 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741865_1041{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 0
2018-12-07 06:41:30,885 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /ccs/ccs_dx_map/ccs_dx_map.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_221422547_1
2018-12-07 06:41:30,890 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741837_1013 172.18.0.2:50010 
2018-12-07 06:41:31,567 INFO BlockStateChange: BLOCK* BlockManager: ask 172.18.0.2:50010 to delete [blk_1073741837_1013]
2018-12-07 06:41:32,987 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741866_1042{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /ccs/ccs_proc_map/ccs_proc_map.csv._COPYING_
2018-12-07 06:41:33,157 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741866_1042{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 0
2018-12-07 06:41:33,163 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /ccs/ccs_proc_map/ccs_proc_map.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_407764946_1
2018-12-07 06:41:33,170 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741838_1014 172.18.0.2:50010 
2018-12-07 06:41:34,569 INFO BlockStateChange: BLOCK* BlockManager: ask 172.18.0.2:50010 to delete [blk_1073741838_1014]
2018-12-07 06:46:53,716 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 353 Total time for transactions(ms): 30 Number of transactions batched in Syncs: 8 Number of syncs: 252 SyncTimes(ms): 347 
2018-12-07 06:46:53,730 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741831_1007{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 469
2018-12-07 06:46:53,733 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /app/hbase/MasterProcWALs/state-00000000000000000001.log is closed by DFSClient_NONMAPREDUCE_-1459410254_1
2018-12-07 06:46:53,738 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741831_1007 172.18.0.2:50010 
2018-12-07 06:46:55,495 INFO BlockStateChange: BLOCK* BlockManager: ask 172.18.0.2:50010 to delete [blk_1073741831_1007]
2018-12-07 07:16:55,529 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741867_1043{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /app/hbase/MasterProcWALs/state-00000000000000000002.log
2018-12-07 07:16:55,546 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741867_1043{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 0
2018-12-07 07:16:55,550 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /app/hbase/MasterProcWALs/state-00000000000000000002.log is closed by DFSClient_NONMAPREDUCE_-1459410254_1
2018-12-07 07:16:56,384 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741830_1006{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 83
2018-12-07 07:16:56,389 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /app/hbase/WALs/bootcamp.local,16020,1544164277809/bootcamp.local%2C16020%2C1544164277809..meta.1544164288528.meta is closed by DFSClient_NONMAPREDUCE_1982901237_1
2018-12-07 07:16:56,395 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741829_1005{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 83
2018-12-07 07:16:56,398 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /app/hbase/WALs/bootcamp.local,16020,1544164277809/bootcamp.local%2C16020%2C1544164277809.default.1544164283447 is closed by DFSClient_NONMAPREDUCE_1982901237_1
2018-12-07 07:17:28,482 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1020ms
No GCs detected
2018-12-07 08:20:16,681 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1221ms
No GCs detected
2018-12-07 09:49:43,773 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1190ms
No GCs detected
2018-12-07 10:51:02,766 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1136ms
No GCs detected
2018-12-07 11:50:07,660 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1278ms
No GCs detected
2018-12-07 12:51:31,221 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1048ms
No GCs detected
2018-12-07 13:47:27,667 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1199ms
No GCs detected
2018-12-07 15:11:09,076 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1630ms
No GCs detected
2018-12-07 15:55:05,023 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1353ms
No GCs detected
2018-12-07 16:49:46,654 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1121ms
No GCs detected
2018-12-07 20:11:59,837 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1476ms
No GCs detected
2018-12-07 20:33:33,013 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 362 Total time for transactions(ms): 38 Number of transactions batched in Syncs: 8 Number of syncs: 259 SyncTimes(ms): 355 
2018-12-07 20:34:39,596 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 367 Total time for transactions(ms): 38 Number of transactions batched in Syncs: 8 Number of syncs: 263 SyncTimes(ms): 358 
2018-12-07 20:58:59,351 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 368 Total time for transactions(ms): 39 Number of transactions batched in Syncs: 8 Number of syncs: 264 SyncTimes(ms): 359 
2018-12-07 21:02:09,599 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1374ms
No GCs detected
2018-12-07 21:45:31,092 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 369 Total time for transactions(ms): 42 Number of transactions batched in Syncs: 8 Number of syncs: 265 SyncTimes(ms): 360 
2018-12-07 21:49:22,508 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 371 Total time for transactions(ms): 42 Number of transactions batched in Syncs: 8 Number of syncs: 267 SyncTimes(ms): 364 
2018-12-07 22:32:55,747 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 374 Total time for transactions(ms): 45 Number of transactions batched in Syncs: 8 Number of syncs: 269 SyncTimes(ms): 366 
2018-12-07 22:38:47,842 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 375 Total time for transactions(ms): 46 Number of transactions batched in Syncs: 8 Number of syncs: 270 SyncTimes(ms): 368 
2018-12-07 22:48:32,921 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 381 Total time for transactions(ms): 47 Number of transactions batched in Syncs: 8 Number of syncs: 276 SyncTimes(ms): 389 
2018-12-07 22:49:39,194 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 382 Total time for transactions(ms): 47 Number of transactions batched in Syncs: 8 Number of syncs: 277 SyncTimes(ms): 390 
2018-12-07 22:52:36,982 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 387 Total time for transactions(ms): 48 Number of transactions batched in Syncs: 8 Number of syncs: 282 SyncTimes(ms): 395 
2018-12-07 22:54:10,380 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 393 Total time for transactions(ms): 50 Number of transactions batched in Syncs: 8 Number of syncs: 288 SyncTimes(ms): 402 
2018-12-07 23:25:13,214 INFO BlockStateChange: BLOCK* processReport: from storage DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5 node DatanodeRegistration(172.18.0.2:50010, datanodeUuid=47ecd31e-43cd-4989-84ba-314b1664d0de, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-747ab8c6-1ec4-46a0-9dee-c8151846aca5;nsid=199960936;c=0), blocks: 38, hasStaleStorage: false, processing time: 14 msecs
2018-12-07 23:33:03,147 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 398 Total time for transactions(ms): 52 Number of transactions batched in Syncs: 8 Number of syncs: 291 SyncTimes(ms): 405 
2018-12-07 23:33:09,099 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741868_1044{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /user/hive/warehouse/.hive-staging_hive_2018-12-07_23-33-03_093_119464589774386579-1/_task_tmp.-ext-10001/_tmp.000000_0
2018-12-07 23:33:09,207 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* blk_1073741868_1044{UCState=COMMITTED, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} is not COMPLETE (ucState = COMMITTED, replication# = 0 <  minimum = 1) in file /user/hive/warehouse/.hive-staging_hive_2018-12-07_23-33-03_093_119464589774386579-1/_task_tmp.-ext-10001/_tmp.000000_0
2018-12-07 23:33:09,209 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741868_1044{UCState=COMMITTED, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 2965
2018-12-07 23:33:09,616 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/hive/warehouse/.hive-staging_hive_2018-12-07_23-33-03_093_119464589774386579-1/_task_tmp.-ext-10001/_tmp.000000_0 is closed by DFSClient_NONMAPREDUCE_34427701_1
2018-12-07 23:33:09,638 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741869_1045{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /user/hive/warehouse/.hive-staging_hive_2018-12-07_23-33-03_093_119464589774386579-1/-ext-10002/tmpstats-0
2018-12-07 23:33:09,666 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741869_1045{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 0
2018-12-07 23:33:09,672 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/hive/warehouse/.hive-staging_hive_2018-12-07_23-33-03_093_119464589774386579-1/-ext-10002/tmpstats-0 is closed by DFSClient_NONMAPREDUCE_34427701_1
2018-12-07 23:33:10,329 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741869_1045 172.18.0.2:50010 
2018-12-07 23:33:11,764 INFO BlockStateChange: BLOCK* BlockManager: ask 172.18.0.2:50010 to delete [blk_1073741869_1045]
2018-12-07 23:34:27,951 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 419 Total time for transactions(ms): 54 Number of transactions batched in Syncs: 11 Number of syncs: 307 SyncTimes(ms): 424 
2018-12-07 23:34:39,992 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741870_1046{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /mimic/noteevents/NOTEEVENTS.csv._COPYING_
2018-12-07 23:34:40,133 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741870_1046{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 0
2018-12-07 23:34:40,139 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /mimic/noteevents/NOTEEVENTS.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_-974476197_1
2018-12-07 23:35:37,445 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 428 Total time for transactions(ms): 54 Number of transactions batched in Syncs: 11 Number of syncs: 314 SyncTimes(ms): 445 
2018-12-07 23:36:47,926 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 431 Total time for transactions(ms): 54 Number of transactions batched in Syncs: 11 Number of syncs: 317 SyncTimes(ms): 451 
2018-12-07 23:38:32,548 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 434 Total time for transactions(ms): 54 Number of transactions batched in Syncs: 11 Number of syncs: 320 SyncTimes(ms): 453 
2018-12-07 23:40:37,993 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 440 Total time for transactions(ms): 55 Number of transactions batched in Syncs: 11 Number of syncs: 326 SyncTimes(ms): 462 
2018-12-07 23:48:31,995 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 443 Total time for transactions(ms): 57 Number of transactions batched in Syncs: 11 Number of syncs: 329 SyncTimes(ms): 463 
2018-12-07 23:48:32,050 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741871_1047{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /mimic/noteevents/NOTEEVENTS.csv._COPYING_
2018-12-07 23:48:32,317 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741871_1047{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 0
2018-12-07 23:48:32,320 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /mimic/noteevents/NOTEEVENTS.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_866842138_1
2018-12-07 23:48:32,330 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741870_1046 172.18.0.2:50010 
2018-12-07 23:48:35,077 INFO BlockStateChange: BLOCK* BlockManager: ask 172.18.0.2:50010 to delete [blk_1073741870_1046]
2018-12-07 23:49:45,452 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 451 Total time for transactions(ms): 57 Number of transactions batched in Syncs: 11 Number of syncs: 335 SyncTimes(ms): 468 
2018-12-07 23:51:44,590 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 456 Total time for transactions(ms): 57 Number of transactions batched in Syncs: 11 Number of syncs: 340 SyncTimes(ms): 470 
2018-12-07 23:53:21,721 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 459 Total time for transactions(ms): 57 Number of transactions batched in Syncs: 11 Number of syncs: 343 SyncTimes(ms): 472 
2018-12-07 23:57:06,982 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 462 Total time for transactions(ms): 58 Number of transactions batched in Syncs: 11 Number of syncs: 346 SyncTimes(ms): 472 
2018-12-07 23:59:44,434 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 465 Total time for transactions(ms): 58 Number of transactions batched in Syncs: 11 Number of syncs: 349 SyncTimes(ms): 476 
2018-12-08 00:00:52,751 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 468 Total time for transactions(ms): 58 Number of transactions batched in Syncs: 11 Number of syncs: 352 SyncTimes(ms): 479 
2018-12-08 00:02:31,715 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 474 Total time for transactions(ms): 59 Number of transactions batched in Syncs: 11 Number of syncs: 358 SyncTimes(ms): 487 
2018-12-08 00:07:00,827 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 477 Total time for transactions(ms): 60 Number of transactions batched in Syncs: 11 Number of syncs: 361 SyncTimes(ms): 488 
2018-12-08 00:08:35,088 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 480 Total time for transactions(ms): 60 Number of transactions batched in Syncs: 11 Number of syncs: 364 SyncTimes(ms): 492 
2018-12-08 00:14:23,473 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 483 Total time for transactions(ms): 60 Number of transactions batched in Syncs: 11 Number of syncs: 367 SyncTimes(ms): 499 
2018-12-08 00:17:01,924 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 487 Total time for transactions(ms): 60 Number of transactions batched in Syncs: 11 Number of syncs: 370 SyncTimes(ms): 505 
2018-12-08 00:18:04,800 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 490 Total time for transactions(ms): 60 Number of transactions batched in Syncs: 11 Number of syncs: 373 SyncTimes(ms): 509 
2018-12-08 00:18:04,840 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741872_1048{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /model/noteevents_with_topics/noteevents_with_topics.csv._COPYING_
2018-12-08 00:18:05,005 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741872_1048{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 0
2018-12-08 00:18:05,008 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /model/noteevents_with_topics/noteevents_with_topics.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_-2036379604_1
2018-12-08 00:21:11,514 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 496 Total time for transactions(ms): 61 Number of transactions batched in Syncs: 11 Number of syncs: 377 SyncTimes(ms): 511 
2018-12-08 00:22:01,719 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741868_1044 172.18.0.2:50010 
2018-12-08 00:22:03,486 INFO BlockStateChange: BLOCK* BlockManager: ask 172.18.0.2:50010 to delete [blk_1073741868_1044]
2018-12-08 00:22:09,347 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741873_1049{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /user/hive/warehouse/.hive-staging_hive_2018-12-08_00-22-01_777_3781555572835606948-1/_task_tmp.-ext-10001/_tmp.000000_0
2018-12-08 00:22:09,444 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741873_1049{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 0
2018-12-08 00:22:09,450 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/hive/warehouse/.hive-staging_hive_2018-12-08_00-22-01_777_3781555572835606948-1/_task_tmp.-ext-10001/_tmp.000000_0 is closed by DFSClient_NONMAPREDUCE_-1059990702_1
2018-12-08 00:22:09,484 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741874_1050{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /user/hive/warehouse/.hive-staging_hive_2018-12-08_00-22-01_777_3781555572835606948-1/-ext-10002/tmpstats-0
2018-12-08 00:22:09,500 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741874_1050{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 0
2018-12-08 00:22:09,503 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/hive/warehouse/.hive-staging_hive_2018-12-08_00-22-01_777_3781555572835606948-1/-ext-10002/tmpstats-0 is closed by DFSClient_NONMAPREDUCE_-1059990702_1
2018-12-08 00:22:10,178 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741874_1050 172.18.0.2:50010 
2018-12-08 00:22:12,489 INFO BlockStateChange: BLOCK* BlockManager: ask 172.18.0.2:50010 to delete [blk_1073741874_1050]
2018-12-08 00:22:21,714 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 524 Total time for transactions(ms): 64 Number of transactions batched in Syncs: 13 Number of syncs: 400 SyncTimes(ms): 545 
2018-12-08 00:23:26,602 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 530 Total time for transactions(ms): 64 Number of transactions batched in Syncs: 13 Number of syncs: 406 SyncTimes(ms): 553 
2018-12-08 00:27:20,858 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 534 Total time for transactions(ms): 64 Number of transactions batched in Syncs: 13 Number of syncs: 410 SyncTimes(ms): 561 
2018-12-08 00:27:23,804 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741873_1049 172.18.0.2:50010 
2018-12-08 00:27:24,273 INFO BlockStateChange: BLOCK* BlockManager: ask 172.18.0.2:50010 to delete [blk_1073741873_1049]
2018-12-08 00:27:32,642 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741875_1051{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /user/hive/warehouse/.hive-staging_hive_2018-12-08_00-27-25_078_8908685480331484128-1/_task_tmp.-ext-10001/_tmp.000000_0
2018-12-08 00:27:32,733 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741875_1051{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 0
2018-12-08 00:27:32,744 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/hive/warehouse/.hive-staging_hive_2018-12-08_00-27-25_078_8908685480331484128-1/_task_tmp.-ext-10001/_tmp.000000_0 is closed by DFSClient_NONMAPREDUCE_-75487263_1
2018-12-08 00:27:32,771 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741876_1052{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /user/hive/warehouse/.hive-staging_hive_2018-12-08_00-27-25_078_8908685480331484128-1/-ext-10002/tmpstats-0
2018-12-08 00:27:32,790 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741876_1052{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 0
2018-12-08 00:27:32,793 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/hive/warehouse/.hive-staging_hive_2018-12-08_00-27-25_078_8908685480331484128-1/-ext-10002/tmpstats-0 is closed by DFSClient_NONMAPREDUCE_-75487263_1
2018-12-08 00:27:33,441 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741876_1052 172.18.0.2:50010 
2018-12-08 00:27:36,243 INFO BlockStateChange: BLOCK* BlockManager: ask 172.18.0.2:50010 to delete [blk_1073741876_1052]
2018-12-08 00:31:08,198 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 559 Total time for transactions(ms): 64 Number of transactions batched in Syncs: 15 Number of syncs: 429 SyncTimes(ms): 594 
2018-12-08 00:31:08,200 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741875_1051 172.18.0.2:50010 
2018-12-08 00:31:09,101 INFO BlockStateChange: BLOCK* BlockManager: ask 172.18.0.2:50010 to delete [blk_1073741875_1051]
2018-12-08 00:31:13,899 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741877_1053{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /user/hive/warehouse/.hive-staging_hive_2018-12-08_00-31-08_209_3331689477577852130-1/_task_tmp.-ext-10001/_tmp.000000_0
2018-12-08 00:31:13,923 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741877_1053{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 0
2018-12-08 00:31:13,927 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/hive/warehouse/.hive-staging_hive_2018-12-08_00-31-08_209_3331689477577852130-1/_task_tmp.-ext-10001/_tmp.000000_0 is closed by DFSClient_NONMAPREDUCE_-75487263_1
2018-12-08 00:31:13,942 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741878_1054{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /user/hive/warehouse/.hive-staging_hive_2018-12-08_00-31-08_209_3331689477577852130-1/-ext-10002/tmpstats-0
2018-12-08 00:31:13,962 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741878_1054{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 0
2018-12-08 00:31:13,967 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/hive/warehouse/.hive-staging_hive_2018-12-08_00-31-08_209_3331689477577852130-1/-ext-10002/tmpstats-0 is closed by DFSClient_NONMAPREDUCE_-75487263_1
2018-12-08 00:31:14,929 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741878_1054 172.18.0.2:50010 
2018-12-08 00:31:15,104 INFO BlockStateChange: BLOCK* BlockManager: ask 172.18.0.2:50010 to delete [blk_1073741878_1054]
2018-12-08 00:37:32,056 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 588 Total time for transactions(ms): 65 Number of transactions batched in Syncs: 17 Number of syncs: 452 SyncTimes(ms): 646 
2018-12-08 00:39:32,173 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 594 Total time for transactions(ms): 66 Number of transactions batched in Syncs: 17 Number of syncs: 458 SyncTimes(ms): 652 
2018-12-08 00:42:05,059 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 601 Total time for transactions(ms): 67 Number of transactions batched in Syncs: 17 Number of syncs: 465 SyncTimes(ms): 667 
2018-12-08 00:48:48,235 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 602 Total time for transactions(ms): 67 Number of transactions batched in Syncs: 17 Number of syncs: 466 SyncTimes(ms): 668 
2018-12-08 00:50:13,599 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 608 Total time for transactions(ms): 67 Number of transactions batched in Syncs: 17 Number of syncs: 472 SyncTimes(ms): 676 
2018-12-08 00:52:56,660 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 614 Total time for transactions(ms): 67 Number of transactions batched in Syncs: 17 Number of syncs: 478 SyncTimes(ms): 684 
2018-12-08 00:53:00,396 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741879_1055{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /model/noteevents_with_topics/noteevents_with_topics.csv._COPYING_
2018-12-08 00:53:00,539 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741879_1055{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 0
2018-12-08 00:53:00,545 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /model/noteevents_with_topics/noteevents_with_topics.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_-223990069_1
2018-12-08 00:53:00,552 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741872_1048 172.18.0.2:50010 
2018-12-08 00:53:02,032 INFO BlockStateChange: BLOCK* BlockManager: ask 172.18.0.2:50010 to delete [blk_1073741872_1048]
2018-12-08 00:53:06,580 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741880_1056{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /model/admissions_ccs_ohe/admissions_ccs_ohe.csv._COPYING_
2018-12-08 00:53:06,725 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741880_1056{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 0
2018-12-08 00:53:06,730 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /model/admissions_ccs_ohe/admissions_ccs_ohe.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_1271244123_1
2018-12-08 00:54:15,745 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 630 Total time for transactions(ms): 68 Number of transactions batched in Syncs: 17 Number of syncs: 490 SyncTimes(ms): 699 
2018-12-08 00:56:32,112 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 636 Total time for transactions(ms): 68 Number of transactions batched in Syncs: 17 Number of syncs: 496 SyncTimes(ms): 705 
2018-12-08 00:56:37,415 INFO org.apache.hadoop.ipc.Server: IPC Server handler 4 on 9000, call org.apache.hadoop.hdfs.protocol.ClientProtocol.create from 172.18.0.2:56090 Call#3 Retry#0: org.apache.hadoop.security.AccessControlException: Permission denied: user=root, access=WRITE, inode="/model/admissions_topic_scores/admissions_topic_scores.csv._COPYING_":hdfs:supergroup:drwxr-xr-x
2018-12-08 00:59:07,566 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 640 Total time for transactions(ms): 68 Number of transactions batched in Syncs: 18 Number of syncs: 500 SyncTimes(ms): 709 
2018-12-08 01:01:19,306 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 642 Total time for transactions(ms): 68 Number of transactions batched in Syncs: 18 Number of syncs: 502 SyncTimes(ms): 710 
2018-12-08 01:01:25,937 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741881_1057{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /user/hive/warehouse/.hive-staging_hive_2018-12-08_01-01-19_218_4622265581014516192-1/_task_tmp.-ext-10001/_tmp.000000_0
2018-12-08 01:01:26,048 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741881_1057{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 0
2018-12-08 01:01:26,054 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/hive/warehouse/.hive-staging_hive_2018-12-08_01-01-19_218_4622265581014516192-1/_task_tmp.-ext-10001/_tmp.000000_0 is closed by DFSClient_NONMAPREDUCE_404273630_1
2018-12-08 01:01:26,074 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741882_1058{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /user/hive/warehouse/.hive-staging_hive_2018-12-08_01-01-19_218_4622265581014516192-1/-ext-10002/tmpstats-0
2018-12-08 01:01:26,092 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741882_1058{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 0
2018-12-08 01:01:26,095 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/hive/warehouse/.hive-staging_hive_2018-12-08_01-01-19_218_4622265581014516192-1/-ext-10002/tmpstats-0 is closed by DFSClient_NONMAPREDUCE_404273630_1
2018-12-08 01:01:26,647 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741882_1058 172.18.0.2:50010 
2018-12-08 01:01:28,616 INFO BlockStateChange: BLOCK* BlockManager: ask 172.18.0.2:50010 to delete [blk_1073741882_1058]
2018-12-08 01:05:03,796 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 665 Total time for transactions(ms): 69 Number of transactions batched in Syncs: 20 Number of syncs: 518 SyncTimes(ms): 725 
2018-12-08 01:05:09,415 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741883_1059{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /user/hive/warehouse/.hive-staging_hive_2018-12-08_01-05-03_657_7951809322512807592-1/_task_tmp.-ext-10001/_tmp.000000_0
2018-12-08 01:05:09,438 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741883_1059{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 0
2018-12-08 01:05:09,442 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/hive/warehouse/.hive-staging_hive_2018-12-08_01-05-03_657_7951809322512807592-1/_task_tmp.-ext-10001/_tmp.000000_0 is closed by DFSClient_NONMAPREDUCE_404273630_1
2018-12-08 01:05:09,458 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741884_1060{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /user/hive/warehouse/.hive-staging_hive_2018-12-08_01-05-03_657_7951809322512807592-1/-ext-10002/tmpstats-0
2018-12-08 01:05:09,468 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741884_1060{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 0
2018-12-08 01:05:09,476 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/hive/warehouse/.hive-staging_hive_2018-12-08_01-05-03_657_7951809322512807592-1/-ext-10002/tmpstats-0 is closed by DFSClient_NONMAPREDUCE_404273630_1
2018-12-08 01:05:10,563 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741884_1060 172.18.0.2:50010 
2018-12-08 01:05:13,448 INFO BlockStateChange: BLOCK* BlockManager: ask 172.18.0.2:50010 to delete [blk_1073741884_1060]
2018-12-08 01:05:43,340 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741885_1061{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /user/hive/warehouse/.hive-staging_hive_2018-12-08_01-05-37_721_4815164770709657596-1/_task_tmp.-ext-10001/_tmp.000000_0
2018-12-08 01:05:43,354 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741885_1061{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 0
2018-12-08 01:05:43,356 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/hive/warehouse/.hive-staging_hive_2018-12-08_01-05-37_721_4815164770709657596-1/_task_tmp.-ext-10001/_tmp.000000_0 is closed by DFSClient_NONMAPREDUCE_404273630_1
2018-12-08 01:05:43,368 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741886_1062{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /user/hive/warehouse/.hive-staging_hive_2018-12-08_01-05-37_721_4815164770709657596-1/-ext-10002/tmpstats-0
2018-12-08 01:05:43,381 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741886_1062{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 0
2018-12-08 01:05:43,383 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/hive/warehouse/.hive-staging_hive_2018-12-08_01-05-37_721_4815164770709657596-1/-ext-10002/tmpstats-0 is closed by DFSClient_NONMAPREDUCE_404273630_1
2018-12-08 01:05:44,485 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741886_1062 172.18.0.2:50010 
2018-12-08 01:05:46,424 INFO BlockStateChange: BLOCK* BlockManager: ask 172.18.0.2:50010 to delete [blk_1073741886_1062]
2018-12-08 01:11:58,560 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 707 Total time for transactions(ms): 75 Number of transactions batched in Syncs: 24 Number of syncs: 550 SyncTimes(ms): 753 
2018-12-08 01:11:58,564 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741881_1057 172.18.0.2:50010 
2018-12-08 01:12:01,173 INFO BlockStateChange: BLOCK* BlockManager: ask 172.18.0.2:50010 to delete [blk_1073741881_1057]
2018-12-08 01:12:04,261 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741887_1063{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /user/hive/warehouse/.hive-staging_hive_2018-12-08_01-11-58_600_5470885739125755152-1/_task_tmp.-ext-10001/_tmp.000000_0
2018-12-08 01:12:04,279 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741887_1063{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 0
2018-12-08 01:12:04,284 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/hive/warehouse/.hive-staging_hive_2018-12-08_01-11-58_600_5470885739125755152-1/_task_tmp.-ext-10001/_tmp.000000_0 is closed by DFSClient_NONMAPREDUCE_404273630_1
2018-12-08 01:12:04,295 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741888_1064{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /user/hive/warehouse/.hive-staging_hive_2018-12-08_01-11-58_600_5470885739125755152-1/-ext-10002/tmpstats-0
2018-12-08 01:12:04,309 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741888_1064{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 0
2018-12-08 01:12:04,312 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/hive/warehouse/.hive-staging_hive_2018-12-08_01-11-58_600_5470885739125755152-1/-ext-10002/tmpstats-0 is closed by DFSClient_NONMAPREDUCE_404273630_1
2018-12-08 01:12:05,248 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741888_1064 172.18.0.2:50010 
2018-12-08 01:12:07,176 INFO BlockStateChange: BLOCK* BlockManager: ask 172.18.0.2:50010 to delete [blk_1073741888_1064]
2018-12-08 01:12:29,493 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741887_1063 172.18.0.2:50010 
2018-12-08 01:12:31,150 INFO BlockStateChange: BLOCK* BlockManager: ask 172.18.0.2:50010 to delete [blk_1073741887_1063]
2018-12-08 01:12:34,899 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741889_1065{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /user/hive/warehouse/.hive-staging_hive_2018-12-08_01-12-29_508_5414036980851180559-1/_task_tmp.-ext-10001/_tmp.000000_0
2018-12-08 01:12:34,917 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* blk_1073741889_1065{UCState=COMMITTED, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} is not COMPLETE (ucState = COMMITTED, replication# = 0 <  minimum = 1) in file /user/hive/warehouse/.hive-staging_hive_2018-12-08_01-12-29_508_5414036980851180559-1/_task_tmp.-ext-10001/_tmp.000000_0
2018-12-08 01:12:34,918 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741889_1065{UCState=COMMITTED, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 7382
2018-12-08 01:12:35,325 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/hive/warehouse/.hive-staging_hive_2018-12-08_01-12-29_508_5414036980851180559-1/_task_tmp.-ext-10001/_tmp.000000_0 is closed by DFSClient_NONMAPREDUCE_404273630_1
2018-12-08 01:12:35,342 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741890_1066{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /user/hive/warehouse/.hive-staging_hive_2018-12-08_01-12-29_508_5414036980851180559-1/-ext-10002/tmpstats-0
2018-12-08 01:12:35,358 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741890_1066{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 0
2018-12-08 01:12:35,361 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/hive/warehouse/.hive-staging_hive_2018-12-08_01-12-29_508_5414036980851180559-1/-ext-10002/tmpstats-0 is closed by DFSClient_NONMAPREDUCE_404273630_1
2018-12-08 01:12:35,946 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741890_1066 172.18.0.2:50010 
2018-12-08 01:12:37,156 INFO BlockStateChange: BLOCK* BlockManager: ask 172.18.0.2:50010 to delete [blk_1073741890_1066]
2018-12-08 01:16:40,864 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 751 Total time for transactions(ms): 79 Number of transactions batched in Syncs: 29 Number of syncs: 584 SyncTimes(ms): 784 
2018-12-08 01:16:45,038 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741891_1067{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /mimic/patients/PATIENTS.csv._COPYING_
2018-12-08 01:16:45,210 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741891_1067{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 0
2018-12-08 01:16:45,213 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /mimic/patients/PATIENTS.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1214682805_1
2018-12-08 01:16:45,220 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741859_1035 172.18.0.2:50010 
2018-12-08 01:16:45,975 INFO BlockStateChange: BLOCK* BlockManager: ask 172.18.0.2:50010 to delete [blk_1073741859_1035]
2018-12-08 01:18:33,400 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 761 Total time for transactions(ms): 79 Number of transactions batched in Syncs: 29 Number of syncs: 592 SyncTimes(ms): 792 
2018-12-08 01:18:33,402 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741889_1065 172.18.0.2:50010 
2018-12-08 01:18:33,875 INFO BlockStateChange: BLOCK* BlockManager: ask 172.18.0.2:50010 to delete [blk_1073741889_1065]
2018-12-08 01:18:39,668 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741892_1068{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /user/hive/warehouse/.hive-staging_hive_2018-12-08_01-18-33_429_6916668043579645314-1/_task_tmp.-ext-10001/_tmp.000000_0
2018-12-08 01:18:39,759 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741892_1068{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 0
2018-12-08 01:18:39,766 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/hive/warehouse/.hive-staging_hive_2018-12-08_01-18-33_429_6916668043579645314-1/_task_tmp.-ext-10001/_tmp.000000_0 is closed by DFSClient_NONMAPREDUCE_587082301_1
2018-12-08 01:18:39,793 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741893_1069{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /user/hive/warehouse/.hive-staging_hive_2018-12-08_01-18-33_429_6916668043579645314-1/-ext-10002/tmpstats-0
2018-12-08 01:18:39,812 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741893_1069{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 0
2018-12-08 01:18:39,815 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/hive/warehouse/.hive-staging_hive_2018-12-08_01-18-33_429_6916668043579645314-1/-ext-10002/tmpstats-0 is closed by DFSClient_NONMAPREDUCE_587082301_1
2018-12-08 01:18:40,675 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741893_1069 172.18.0.2:50010 
2018-12-08 01:18:41,833 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741883_1059 172.18.0.2:50010 
2018-12-08 01:18:42,878 INFO BlockStateChange: BLOCK* BlockManager: ask 172.18.0.2:50010 to delete [blk_1073741893_1069, blk_1073741883_1059]
2018-12-08 01:18:48,761 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741894_1070{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /user/hive/warehouse/.hive-staging_hive_2018-12-08_01-18-42_688_6641144021650523214-1/_task_tmp.-ext-10001/_tmp.000000_0
2018-12-08 01:18:48,786 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741894_1070{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 0
2018-12-08 01:18:48,789 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/hive/warehouse/.hive-staging_hive_2018-12-08_01-18-42_688_6641144021650523214-1/_task_tmp.-ext-10001/_tmp.000000_0 is closed by DFSClient_NONMAPREDUCE_587082301_1
2018-12-08 01:18:48,803 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741895_1071{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /user/hive/warehouse/.hive-staging_hive_2018-12-08_01-18-42_688_6641144021650523214-1/-ext-10002/tmpstats-0
2018-12-08 01:18:48,813 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741895_1071{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 0
2018-12-08 01:18:48,818 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/hive/warehouse/.hive-staging_hive_2018-12-08_01-18-42_688_6641144021650523214-1/-ext-10002/tmpstats-0 is closed by DFSClient_NONMAPREDUCE_587082301_1
2018-12-08 01:18:49,925 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741895_1071 172.18.0.2:50010 
2018-12-08 01:18:51,083 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741885_1061 172.18.0.2:50010 
2018-12-08 01:18:51,882 INFO BlockStateChange: BLOCK* BlockManager: ask 172.18.0.2:50010 to delete [blk_1073741895_1071, blk_1073741885_1061]
2018-12-08 01:18:57,223 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741896_1072{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /user/hive/warehouse/.hive-staging_hive_2018-12-08_01-18-51_687_4880755076403611009-1/_task_tmp.-ext-10001/_tmp.000000_0
2018-12-08 01:18:57,239 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741896_1072{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 0
2018-12-08 01:18:57,240 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/hive/warehouse/.hive-staging_hive_2018-12-08_01-18-51_687_4880755076403611009-1/_task_tmp.-ext-10001/_tmp.000000_0 is closed by DFSClient_NONMAPREDUCE_587082301_1
2018-12-08 01:18:57,279 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741897_1073{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /user/hive/warehouse/.hive-staging_hive_2018-12-08_01-18-51_687_4880755076403611009-1/-ext-10002/tmpstats-0
2018-12-08 01:18:57,303 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741897_1073{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 0
2018-12-08 01:18:57,307 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/hive/warehouse/.hive-staging_hive_2018-12-08_01-18-51_687_4880755076403611009-1/-ext-10002/tmpstats-0 is closed by DFSClient_NONMAPREDUCE_587082301_1
2018-12-08 01:18:58,341 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741897_1073 172.18.0.2:50010 
2018-12-08 01:19:00,850 INFO BlockStateChange: BLOCK* BlockManager: ask 172.18.0.2:50010 to delete [blk_1073741897_1073]
2018-12-08 01:19:35,163 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 827 Total time for transactions(ms): 83 Number of transactions batched in Syncs: 35 Number of syncs: 643 SyncTimes(ms): 856 
2018-12-08 01:42:50,932 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NameNode
STARTUP_MSG:   host = bootcamp.local/172.18.0.2
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.3
STARTUP_MSG:   classpath = /etc/hadoop/conf:/usr/lib/hadoop/lib/asm-3.2.jar:/usr/lib/hadoop/lib/jackson-jaxrs-1.9.13.jar:/usr/lib/hadoop/lib/api-asn1-api-1.0.0-M20.jar:/usr/lib/hadoop/lib/jersey-json-1.9.jar:/usr/lib/hadoop/lib/gson-2.2.4.jar:/usr/lib/hadoop/lib/commons-net-3.1.jar:/usr/lib/hadoop/lib/commons-digester-1.8.jar:/usr/lib/hadoop/lib/guava-11.0.2.jar:/usr/lib/hadoop/lib/api-util-1.0.0-M20.jar:/usr/lib/hadoop/lib/jets3t-0.9.0.jar:/usr/lib/hadoop/lib/snappy-java-1.0.4.1.jar:/usr/lib/hadoop/lib/commons-compress-1.4.1.jar:/usr/lib/hadoop/lib/activation-1.1.jar:/usr/lib/hadoop/lib/slf4j-log4j12-1.7.10.jar:/usr/lib/hadoop/lib/curator-framework-2.7.1.jar:/usr/lib/hadoop/lib/jackson-core-asl-1.9.13.jar:/usr/lib/hadoop/lib/commons-beanutils-1.7.0.jar:/usr/lib/hadoop/lib/curator-client-2.7.1.jar:/usr/lib/hadoop/lib/jsr305-3.0.0.jar:/usr/lib/hadoop/lib/avro-1.7.4.jar:/usr/lib/hadoop/lib/jackson-xc-1.9.13.jar:/usr/lib/hadoop/lib/commons-configuration-1.6.jar:/usr/lib/hadoop/lib/commons-math3-3.1.1.jar:/usr/lib/hadoop/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/lib/hadoop/lib/jaxb-api-2.2.2.jar:/usr/lib/hadoop/lib/netty-3.6.2.Final.jar:/usr/lib/hadoop/lib/curator-recipes-2.7.1.jar:/usr/lib/hadoop/lib/mockito-all-1.8.5.jar:/usr/lib/hadoop/lib/commons-codec-1.4.jar:/usr/lib/hadoop/lib/jettison-1.1.jar:/usr/lib/hadoop/lib/commons-httpclient-3.1.jar:/usr/lib/hadoop/lib/jsch-0.1.42.jar:/usr/lib/hadoop/lib/java-xmlbuilder-0.4.jar:/usr/lib/hadoop/lib/xz-1.0.jar:/usr/lib/hadoop/lib/commons-logging-1.1.3.jar:/usr/lib/hadoop/lib/log4j-1.2.17.jar:/usr/lib/hadoop/lib/zookeeper-3.4.6.jar:/usr/lib/hadoop/lib/commons-lang-2.6.jar:/usr/lib/hadoop/lib/hamcrest-core-1.3.jar:/usr/lib/hadoop/lib/httpclient-4.2.5.jar:/usr/lib/hadoop/lib/commons-cli-1.2.jar:/usr/lib/hadoop/lib/commons-io-2.4.jar:/usr/lib/hadoop/lib/apacheds-i18n-2.0.0-M15.jar:/usr/lib/hadoop/lib/jetty-util-6.1.26.jar:/usr/lib/hadoop/lib/jackson-mapper-asl-1.9.13.jar:/usr/lib/hadoop/lib/htrace-core-3.1.0-incubating.jar:/usr/lib/hadoop/lib/paranamer-2.3.jar:/usr/lib/hadoop/lib/xmlenc-0.52.jar:/usr/lib/hadoop/lib/jaxb-impl-2.2.3-1.jar:/usr/lib/hadoop/lib/commons-beanutils-core-1.8.0.jar:/usr/lib/hadoop/lib/jersey-server-1.9.jar:/usr/lib/hadoop/lib/slf4j-api-1.7.10.jar:/usr/lib/hadoop/lib/jsp-api-2.1.jar:/usr/lib/hadoop/lib/jetty-6.1.26.jar:/usr/lib/hadoop/lib/junit-4.11.jar:/usr/lib/hadoop/lib/servlet-api-2.5.jar:/usr/lib/hadoop/lib/httpcore-4.2.5.jar:/usr/lib/hadoop/lib/protobuf-java-2.5.0.jar:/usr/lib/hadoop/lib/jersey-core-1.9.jar:/usr/lib/hadoop/lib/stax-api-1.0-2.jar:/usr/lib/hadoop/lib/commons-collections-3.2.2.jar:/usr/lib/hadoop/.//hadoop-nfs.jar:/usr/lib/hadoop/.//hadoop-common.jar:/usr/lib/hadoop/.//hadoop-auth-2.7.3.jar:/usr/lib/hadoop/.//hadoop-common-2.7.3-tests.jar:/usr/lib/hadoop/.//hadoop-common-2.7.3.jar:/usr/lib/hadoop/.//hadoop-auth.jar:/usr/lib/hadoop/.//hadoop-annotations.jar:/usr/lib/hadoop/.//hadoop-annotations-2.7.3.jar:/usr/lib/hadoop/.//hadoop-nfs-2.7.3.jar:/usr/lib/hadoop-hdfs/./:/usr/lib/hadoop-hdfs/lib/asm-3.2.jar:/usr/lib/hadoop-hdfs/lib/xercesImpl-2.9.1.jar:/usr/lib/hadoop-hdfs/lib/guava-11.0.2.jar:/usr/lib/hadoop-hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/lib/hadoop-hdfs/lib/jsr305-3.0.0.jar:/usr/lib/hadoop-hdfs/lib/leveldbjni-all-1.8.jar:/usr/lib/hadoop-hdfs/lib/netty-3.6.2.Final.jar:/usr/lib/hadoop-hdfs/lib/netty-all-4.0.23.Final.jar:/usr/lib/hadoop-hdfs/lib/commons-codec-1.4.jar:/usr/lib/hadoop-hdfs/lib/xml-apis-1.3.04.jar:/usr/lib/hadoop-hdfs/lib/commons-logging-1.1.3.jar:/usr/lib/hadoop-hdfs/lib/log4j-1.2.17.jar:/usr/lib/hadoop-hdfs/lib/commons-lang-2.6.jar:/usr/lib/hadoop-hdfs/lib/commons-cli-1.2.jar:/usr/lib/hadoop-hdfs/lib/commons-io-2.4.jar:/usr/lib/hadoop-hdfs/lib/jetty-util-6.1.26.jar:/usr/lib/hadoop-hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/lib/hadoop-hdfs/lib/htrace-core-3.1.0-incubating.jar:/usr/lib/hadoop-hdfs/lib/xmlenc-0.52.jar:/usr/lib/hadoop-hdfs/lib/jersey-server-1.9.jar:/usr/lib/hadoop-hdfs/lib/jetty-6.1.26.jar:/usr/lib/hadoop-hdfs/lib/commons-daemon-1.0.13.jar:/usr/lib/hadoop-hdfs/lib/servlet-api-2.5.jar:/usr/lib/hadoop-hdfs/lib/protobuf-java-2.5.0.jar:/usr/lib/hadoop-hdfs/lib/jersey-core-1.9.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs-nfs.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs-2.7.3-tests.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs-nfs-2.7.3.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs-2.7.3.jar:/usr/lib/hadoop-yarn/lib/asm-3.2.jar:/usr/lib/hadoop-yarn/lib/jackson-jaxrs-1.9.13.jar:/usr/lib/hadoop-yarn/lib/jersey-json-1.9.jar:/usr/lib/hadoop-yarn/lib/jersey-client-1.9.jar:/usr/lib/hadoop-yarn/lib/guava-11.0.2.jar:/usr/lib/hadoop-yarn/lib/jersey-guice-1.9.jar:/usr/lib/hadoop-yarn/lib/commons-compress-1.4.1.jar:/usr/lib/hadoop-yarn/lib/activation-1.1.jar:/usr/lib/hadoop-yarn/lib/guice-servlet-3.0.jar:/usr/lib/hadoop-yarn/lib/zookeeper-3.4.6-tests.jar:/usr/lib/hadoop-yarn/lib/jackson-core-asl-1.9.13.jar:/usr/lib/hadoop-yarn/lib/jsr305-3.0.0.jar:/usr/lib/hadoop-yarn/lib/jackson-xc-1.9.13.jar:/usr/lib/hadoop-yarn/lib/leveldbjni-all-1.8.jar:/usr/lib/hadoop-yarn/lib/jaxb-api-2.2.2.jar:/usr/lib/hadoop-yarn/lib/netty-3.6.2.Final.jar:/usr/lib/hadoop-yarn/lib/javax.inject-1.jar:/usr/lib/hadoop-yarn/lib/commons-codec-1.4.jar:/usr/lib/hadoop-yarn/lib/jettison-1.1.jar:/usr/lib/hadoop-yarn/lib/guice-3.0.jar:/usr/lib/hadoop-yarn/lib/xz-1.0.jar:/usr/lib/hadoop-yarn/lib/commons-logging-1.1.3.jar:/usr/lib/hadoop-yarn/lib/log4j-1.2.17.jar:/usr/lib/hadoop-yarn/lib/zookeeper-3.4.6.jar:/usr/lib/hadoop-yarn/lib/commons-lang-2.6.jar:/usr/lib/hadoop-yarn/lib/commons-cli-1.2.jar:/usr/lib/hadoop-yarn/lib/commons-io-2.4.jar:/usr/lib/hadoop-yarn/lib/jetty-util-6.1.26.jar:/usr/lib/hadoop-yarn/lib/jackson-mapper-asl-1.9.13.jar:/usr/lib/hadoop-yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/lib/hadoop-yarn/lib/jersey-server-1.9.jar:/usr/lib/hadoop-yarn/lib/aopalliance-1.0.jar:/usr/lib/hadoop-yarn/lib/jetty-6.1.26.jar:/usr/lib/hadoop-yarn/lib/servlet-api-2.5.jar:/usr/lib/hadoop-yarn/lib/protobuf-java-2.5.0.jar:/usr/lib/hadoop-yarn/lib/jersey-core-1.9.jar:/usr/lib/hadoop-yarn/lib/stax-api-1.0-2.jar:/usr/lib/hadoop-yarn/lib/commons-collections-3.2.2.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-resourcemanager.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-resourcemanager-2.7.3.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-applicationhistoryservice-2.7.3.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-registry.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-tests.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-common.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-common-2.7.3.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-applications-distributedshell.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-client.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-common-2.7.3.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-applications-unmanaged-am-launcher.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-web-proxy.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-api.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-tests-2.7.3.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-nodemanager-2.7.3.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-api-2.7.3.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-sharedcachemanager-2.7.3.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-common.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-client-2.7.3.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-nodemanager.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-sharedcachemanager.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-registry-2.7.3.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-applications-unmanaged-am-launcher-2.7.3.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-web-proxy-2.7.3.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-applicationhistoryservice.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-applications-distributedshell-2.7.3.jar:/usr/lib/hadoop-mapreduce/lib/asm-3.2.jar:/usr/lib/hadoop-mapreduce/lib/jersey-guice-1.9.jar:/usr/lib/hadoop-mapreduce/lib/snappy-java-1.0.4.1.jar:/usr/lib/hadoop-mapreduce/lib/commons-compress-1.4.1.jar:/usr/lib/hadoop-mapreduce/lib/guice-servlet-3.0.jar:/usr/lib/hadoop-mapreduce/lib/jackson-core-asl-1.9.13.jar:/usr/lib/hadoop-mapreduce/lib/avro-1.7.4.jar:/usr/lib/hadoop-mapreduce/lib/leveldbjni-all-1.8.jar:/usr/lib/hadoop-mapreduce/lib/netty-3.6.2.Final.jar:/usr/lib/hadoop-mapreduce/lib/javax.inject-1.jar:/usr/lib/hadoop-mapreduce/lib/guice-3.0.jar:/usr/lib/hadoop-mapreduce/lib/xz-1.0.jar:/usr/lib/hadoop-mapreduce/lib/log4j-1.2.17.jar:/usr/lib/hadoop-mapreduce/lib/hamcrest-core-1.3.jar:/usr/lib/hadoop-mapreduce/lib/commons-io-2.4.jar:/usr/lib/hadoop-mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/usr/lib/hadoop-mapreduce/lib/paranamer-2.3.jar:/usr/lib/hadoop-mapreduce/lib/jersey-server-1.9.jar:/usr/lib/hadoop-mapreduce/lib/aopalliance-1.0.jar:/usr/lib/hadoop-mapreduce/lib/junit-4.11.jar:/usr/lib/hadoop-mapreduce/lib/protobuf-java-2.5.0.jar:/usr/lib/hadoop-mapreduce/lib/jersey-core-1.9.jar:/usr/lib/hadoop-mapreduce/.//jackson-core-2.2.3.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-jobclient-2.7.3-tests.jar:/usr/lib/hadoop-mapreduce/.//azure-storage-2.0.0.jar:/usr/lib/hadoop-mapreduce/.//metrics-core-3.0.1.jar:/usr/lib/hadoop-mapreduce/.//asm-3.2.jar:/usr/lib/hadoop-mapreduce/.//jackson-jaxrs-1.9.13.jar:/usr/lib/hadoop-mapreduce/.//hadoop-sls-2.7.3.jar:/usr/lib/hadoop-mapreduce/.//api-asn1-api-1.0.0-M20.jar:/usr/lib/hadoop-mapreduce/.//jersey-json-1.9.jar:/usr/lib/hadoop-mapreduce/.//gson-2.2.4.jar:/usr/lib/hadoop-mapreduce/.//commons-net-3.1.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-app-2.7.3.jar:/usr/lib/hadoop-mapreduce/.//commons-digester-1.8.jar:/usr/lib/hadoop-mapreduce/.//guava-11.0.2.jar:/usr/lib/hadoop-mapreduce/.//api-util-1.0.0-M20.jar:/usr/lib/hadoop-mapreduce/.//jets3t-0.9.0.jar:/usr/lib/hadoop-mapreduce/.//snappy-java-1.0.4.1.jar:/usr/lib/hadoop-mapreduce/.//hadoop-streaming-2.7.3.jar:/usr/lib/hadoop-mapreduce/.//commons-compress-1.4.1.jar:/usr/lib/hadoop-mapreduce/.//activation-1.1.jar:/usr/lib/hadoop-mapreduce/.//curator-framework-2.7.1.jar:/usr/lib/hadoop-mapreduce/.//hadoop-archives.jar:/usr/lib/hadoop-mapreduce/.//hadoop-aws.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-core.jar:/usr/lib/hadoop-mapreduce/.//jackson-core-asl-1.9.13.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-hs.jar:/usr/lib/hadoop-mapreduce/.//commons-beanutils-1.7.0.jar:/usr/lib/hadoop-mapreduce/.//curator-client-2.7.1.jar:/usr/lib/hadoop-mapreduce/.//hadoop-azure-2.7.3.jar:/usr/lib/hadoop-mapreduce/.//jsr305-3.0.0.jar:/usr/lib/hadoop-mapreduce/.//avro-1.7.4.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-jobclient.jar:/usr/lib/hadoop-mapreduce/.//hadoop-gridmix.jar:/usr/lib/hadoop-mapreduce/.//hadoop-distcp.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-app.jar:/usr/lib/hadoop-mapreduce/.//jackson-xc-1.9.13.jar:/usr/lib/hadoop-mapreduce/.//hadoop-auth-2.7.3.jar:/usr/lib/hadoop-mapreduce/.//commons-configuration-1.6.jar:/usr/lib/hadoop-mapreduce/.//commons-math3-3.1.1.jar:/usr/lib/hadoop-mapreduce/.//hadoop-datajoin-2.7.3.jar:/usr/lib/hadoop-mapreduce/.//apacheds-kerberos-codec-2.0.0-M15.jar:/usr/lib/hadoop-mapreduce/.//hadoop-gridmix-2.7.3.jar:/usr/lib/hadoop-mapreduce/.//hadoop-ant.jar:/usr/lib/hadoop-mapreduce/.//hadoop-auth.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-shuffle-2.7.3.jar:/usr/lib/hadoop-mapreduce/.//jaxb-api-2.2.2.jar:/usr/lib/hadoop-mapreduce/.//netty-3.6.2.Final.jar:/usr/lib/hadoop-mapreduce/.//curator-recipes-2.7.1.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-hs-plugins.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-common-2.7.3.jar:/usr/lib/hadoop-mapreduce/.//mockito-all-1.8.5.jar:/usr/lib/hadoop-mapreduce/.//joda-time-2.9.9.jar:/usr/lib/hadoop-mapreduce/.//hadoop-openstack.jar:/usr/lib/hadoop-mapreduce/.//jackson-annotations-2.2.3.jar:/usr/lib/hadoop-mapreduce/.//commons-codec-1.4.jar:/usr/lib/hadoop-mapreduce/.//hadoop-extras-2.7.3.jar:/usr/lib/hadoop-mapreduce/.//jettison-1.1.jar:/usr/lib/hadoop-mapreduce/.//hadoop-distcp-2.7.3.jar:/usr/lib/hadoop-mapreduce/.//commons-httpclient-3.1.jar:/usr/lib/hadoop-mapreduce/.//jsch-0.1.42.jar:/usr/lib/hadoop-mapreduce/.//hadoop-sls.jar:/usr/lib/hadoop-mapreduce/.//jackson-databind-2.2.3.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-hs-2.7.3.jar:/usr/lib/hadoop-mapreduce/.//java-xmlbuilder-0.4.jar:/usr/lib/hadoop-mapreduce/.//aws-java-sdk-1.7.4.jar:/usr/lib/hadoop-mapreduce/.//hadoop-aws-2.7.3.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-examples-2.7.3.jar:/usr/lib/hadoop-mapreduce/.//xz-1.0.jar:/usr/lib/hadoop-mapreduce/.//hadoop-rumen.jar:/usr/lib/hadoop-mapreduce/.//commons-logging-1.1.3.jar:/usr/lib/hadoop-mapreduce/.//log4j-1.2.17.jar:/usr/lib/hadoop-mapreduce/.//zookeeper-3.4.6.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-core-2.7.3.jar:/usr/lib/hadoop-mapreduce/.//hadoop-datajoin.jar:/usr/lib/hadoop-mapreduce/.//commons-lang-2.6.jar:/usr/lib/hadoop-mapreduce/.//commons-lang3-3.3.2.jar:/usr/lib/hadoop-mapreduce/.//hamcrest-core-1.3.jar:/usr/lib/hadoop-mapreduce/.//httpclient-4.2.5.jar:/usr/lib/hadoop-mapreduce/.//commons-cli-1.2.jar:/usr/lib/hadoop-mapreduce/.//commons-io-2.4.jar:/usr/lib/hadoop-mapreduce/.//apacheds-i18n-2.0.0-M15.jar:/usr/lib/hadoop-mapreduce/.//jetty-util-6.1.26.jar:/usr/lib/hadoop-mapreduce/.//jackson-mapper-asl-1.9.13.jar:/usr/lib/hadoop-mapreduce/.//hadoop-archives-2.7.3.jar:/usr/lib/hadoop-mapreduce/.//htrace-core-3.1.0-incubating.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-common.jar:/usr/lib/hadoop-mapreduce/.//paranamer-2.3.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-jobclient-2.7.3.jar:/usr/lib/hadoop-mapreduce/.//hadoop-extras.jar:/usr/lib/hadoop-mapreduce/.//xmlenc-0.52.jar:/usr/lib/hadoop-mapreduce/.//hadoop-openstack-2.7.3.jar:/usr/lib/hadoop-mapreduce/.//jaxb-impl-2.2.3-1.jar:/usr/lib/hadoop-mapreduce/.//commons-beanutils-core-1.8.0.jar:/usr/lib/hadoop-mapreduce/.//jersey-server-1.9.jar:/usr/lib/hadoop-mapreduce/.//jsp-api-2.1.jar:/usr/lib/hadoop-mapreduce/.//jetty-6.1.26.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-hs-plugins-2.7.3.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-examples.jar:/usr/lib/hadoop-mapreduce/.//junit-4.11.jar:/usr/lib/hadoop-mapreduce/.//hadoop-azure.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-shuffle.jar:/usr/lib/hadoop-mapreduce/.//hadoop-streaming.jar:/usr/lib/hadoop-mapreduce/.//hadoop-ant-2.7.3.jar:/usr/lib/hadoop-mapreduce/.//servlet-api-2.5.jar:/usr/lib/hadoop-mapreduce/.//httpcore-4.2.5.jar:/usr/lib/hadoop-mapreduce/.//hadoop-rumen-2.7.3.jar:/usr/lib/hadoop-mapreduce/.//protobuf-java-2.5.0.jar:/usr/lib/hadoop-mapreduce/.//jersey-core-1.9.jar:/usr/lib/hadoop-mapreduce/.//stax-api-1.0-2.jar:/usr/lib/hadoop-mapreduce/.//commons-collections-3.2.2.jar:/usr/lib/hadoop/contrib/capacity-scheduler/*.jar:/usr/lib/hadoop/contrib/capacity-scheduler/*.jar:/usr/lib/hadoop/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/bigtop.git -r 2365207dc0440bb884e41d4ffe32a37ad0d0ed28; compiled by 'jenkins' on 2017-10-05T21:00Z
STARTUP_MSG:   java = 1.8.0_181
************************************************************/
2018-12-08 01:42:50,944 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2018-12-08 01:42:50,953 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: createNameNode []
2018-12-08 01:42:51,324 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2018-12-08 01:42:51,455 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2018-12-08 01:42:51,456 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NameNode metrics system started
2018-12-08 01:42:51,460 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: fs.defaultFS is hdfs://bootcamp.local:9000
2018-12-08 01:42:51,461 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Clients are to use bootcamp.local:9000 to access this namenode/service.
2018-12-08 01:42:51,663 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for hdfs at: http://0.0.0.0:50070
2018-12-08 01:42:51,740 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2018-12-08 01:42:51,751 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2018-12-08 01:42:51,762 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.namenode is not defined
2018-12-08 01:42:51,772 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2018-12-08 01:42:51,776 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2018-12-08 01:42:51,776 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2018-12-08 01:42:51,777 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2018-12-08 01:42:52,001 INFO org.apache.hadoop.http.HttpServer2: Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2018-12-08 01:42:52,004 INFO org.apache.hadoop.http.HttpServer2: addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2018-12-08 01:42:52,030 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50070
2018-12-08 01:42:52,030 INFO org.mortbay.log: jetty-6.1.26
2018-12-08 01:42:52,196 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:50070
2018-12-08 01:42:52,248 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one image storage directory (dfs.namenode.name.dir) configured. Beware of data loss due to lack of redundant storage directories!
2018-12-08 01:42:52,248 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one namespace edits storage directory (dfs.namenode.edits.dir) configured. Beware of data loss due to lack of redundant storage directories!
2018-12-08 01:42:52,312 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: No KeyProvider found.
2018-12-08 01:42:52,313 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair:true
2018-12-08 01:42:52,393 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2018-12-08 01:42:52,393 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2018-12-08 01:42:52,396 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2018-12-08 01:42:52,396 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2018 Dec 08 01:42:52
2018-12-08 01:42:52,399 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2018-12-08 01:42:52,400 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2018-12-08 01:42:52,403 INFO org.apache.hadoop.util.GSet: 2.0% max memory 889 MB = 17.8 MB
2018-12-08 01:42:52,404 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2018-12-08 01:42:52,414 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2018-12-08 01:42:52,414 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 1
2018-12-08 01:42:52,415 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2018-12-08 01:42:52,416 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2018-12-08 01:42:52,416 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2018-12-08 01:42:52,416 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2018-12-08 01:42:52,417 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2018-12-08 01:42:52,417 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2018-12-08 01:42:52,430 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = hdfs (auth:SIMPLE)
2018-12-08 01:42:52,430 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2018-12-08 01:42:52,431 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2018-12-08 01:42:52,432 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2018-12-08 01:42:52,435 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2018-12-08 01:42:52,533 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2018-12-08 01:42:52,534 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2018-12-08 01:42:52,534 INFO org.apache.hadoop.util.GSet: 1.0% max memory 889 MB = 8.9 MB
2018-12-08 01:42:52,534 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2018-12-08 01:42:52,536 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: ACLs enabled? false
2018-12-08 01:42:52,536 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: XAttrs enabled? true
2018-12-08 01:42:52,537 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Maximum size of an xattr: 16384
2018-12-08 01:42:52,537 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times
2018-12-08 01:42:52,547 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2018-12-08 01:42:52,547 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2018-12-08 01:42:52,548 INFO org.apache.hadoop.util.GSet: 0.25% max memory 889 MB = 2.2 MB
2018-12-08 01:42:52,548 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2018-12-08 01:42:52,550 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2018-12-08 01:42:52,551 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2018-12-08 01:42:52,551 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2018-12-08 01:42:52,555 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.window.num.buckets = 10
2018-12-08 01:42:52,556 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.num.users = 10
2018-12-08 01:42:52,556 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2018-12-08 01:42:52,558 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache on namenode is enabled
2018-12-08 01:42:52,559 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2018-12-08 01:42:52,562 INFO org.apache.hadoop.util.GSet: Computing capacity for map NameNodeRetryCache
2018-12-08 01:42:52,562 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2018-12-08 01:42:52,563 INFO org.apache.hadoop.util.GSet: 0.029999999329447746% max memory 889 MB = 273.1 KB
2018-12-08 01:42:52,563 INFO org.apache.hadoop.util.GSet: capacity      = 2^15 = 32768 entries
2018-12-08 01:42:52,583 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /data/name/in_use.lock acquired by nodename 751@bootcamp.local
2018-12-08 01:42:52,636 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Recovering unfinalized segments in /data/name/current
2018-12-08 01:42:52,781 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /data/name/current/edits_inprogress_0000000000000000015 -> /data/name/current/edits_0000000000000000015-0000000000000000841
2018-12-08 01:42:52,788 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Planning to load image: FSImageFile(file=/data/name/current/fsimage_0000000000000000014, cpktTxId=0000000000000000014)
2018-12-08 01:42:52,826 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Loading 8 INodes.
2018-12-08 01:42:52,868 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Loaded FSImage in 0 seconds.
2018-12-08 01:42:52,869 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 14 from /data/name/current/fsimage_0000000000000000014
2018-12-08 01:42:52,869 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@2262b621 expecting start txid #15
2018-12-08 01:42:52,870 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /data/name/current/edits_0000000000000000015-0000000000000000841
2018-12-08 01:42:52,873 INFO org.apache.hadoop.hdfs.server.namenode.EditLogInputStream: Fast-forwarding stream '/data/name/current/edits_0000000000000000015-0000000000000000841' to transaction ID 15
2018-12-08 01:42:52,988 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /data/name/current/edits_0000000000000000015-0000000000000000841 of size 1048576 edits # 827 loaded in 0 seconds
2018-12-08 01:42:52,990 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Need to save fs image? true (staleImage=true, haEnabled=false, isRollingUpgrade=false)
2018-12-08 01:42:52,990 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Save namespace ...
2018-12-08 01:42:53,000 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /data/name/current/fsimage.ckpt_0000000000000000841 using no compression
2018-12-08 01:42:53,064 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /data/name/current/fsimage.ckpt_0000000000000000841 of size 9326 bytes saved in 0 seconds.
2018-12-08 01:42:53,076 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 14
2018-12-08 01:42:53,077 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/data/name/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2018-12-08 01:42:53,091 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 842
2018-12-08 01:42:53,191 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 2 entries 24 lookups
2018-12-08 01:42:53,192 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Finished loading FSImage in 661 msecs
2018-12-08 01:42:53,497 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: RPC server is binding to bootcamp.local:9000
2018-12-08 01:42:53,507 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2018-12-08 01:42:53,521 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 9000
2018-12-08 01:42:53,554 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Registered FSNamesystemState MBean
2018-12-08 01:42:53,569 INFO org.apache.hadoop.hdfs.server.namenode.LeaseManager: Number of blocks under construction: 0
2018-12-08 01:42:53,569 INFO org.apache.hadoop.hdfs.server.namenode.LeaseManager: Number of blocks under construction: 0
2018-12-08 01:42:53,570 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode ON. 
The reported blocks 0 needs additional 45 blocks to reach the threshold 0.9990 of total blocks 45.
The number of live datanodes 0 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached.
2018-12-08 01:42:53,578 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Number of failed storage changes from 0 to 0
2018-12-08 01:42:53,613 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2018-12-08 01:42:53,613 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 9000: starting
2018-12-08 01:42:53,625 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: NameNode RPC up at: bootcamp.local/172.18.0.2:9000
2018-12-08 01:42:53,625 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Starting services required for active state
2018-12-08 01:42:53,632 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Starting CacheReplicationMonitor with interval 30000 milliseconds
2018-12-08 01:43:02,345 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(172.18.0.2:50010, datanodeUuid=47ecd31e-43cd-4989-84ba-314b1664d0de, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-747ab8c6-1ec4-46a0-9dee-c8151846aca5;nsid=199960936;c=0) storage 47ecd31e-43cd-4989-84ba-314b1664d0de
2018-12-08 01:43:02,346 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Number of failed storage changes from 0 to 0
2018-12-08 01:43:02,357 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/172.18.0.2:50010
2018-12-08 01:43:02,506 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Number of failed storage changes from 0 to 0
2018-12-08 01:43:02,507 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Adding new storage ID DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5 for DN 172.18.0.2:50010
2018-12-08 01:43:02,587 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode extension entered. 
The reported blocks 44 has reached the threshold 0.9990 of total blocks 45. The number of live datanodes 1 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 29 seconds.
2018-12-08 01:43:02,587 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: initializing replication queues
2018-12-08 01:43:02,589 INFO BlockStateChange: BLOCK* processReport: from storage DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5 node DatanodeRegistration(172.18.0.2:50010, datanodeUuid=47ecd31e-43cd-4989-84ba-314b1664d0de, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-747ab8c6-1ec4-46a0-9dee-c8151846aca5;nsid=199960936;c=0), blocks: 45, hasStaleStorage: false, processing time: 9 msecs
2018-12-08 01:43:02,614 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Total number of blocks            = 45
2018-12-08 01:43:02,614 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of invalid blocks          = 0
2018-12-08 01:43:02,614 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of under-replicated blocks = 0
2018-12-08 01:43:02,615 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of  over-replicated blocks = 0
2018-12-08 01:43:02,615 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of blocks being written    = 0
2018-12-08 01:43:02,616 INFO org.apache.hadoop.hdfs.StateChange: STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 27 msec
2018-12-08 01:43:22,626 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode ON, in safe mode extension. 
The reported blocks 45 has reached the threshold 0.9990 of total blocks 45. The number of live datanodes 1 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 9 seconds.
2018-12-08 01:43:32,607 INFO org.apache.hadoop.hdfs.StateChange: STATE* Leaving safe mode after 40 secs
2018-12-08 01:43:32,608 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode is OFF
2018-12-08 01:43:32,608 INFO org.apache.hadoop.hdfs.StateChange: STATE* Network topology has 1 racks and 1 datanodes
2018-12-08 01:43:32,609 INFO org.apache.hadoop.hdfs.StateChange: STATE* UnderReplicatedBlocks has 0 blocks
2018-12-08 01:43:42,218 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741898_1074{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /app/hbase/WALs/bootcamp.local,16020,1544233405155/bootcamp.local%2C16020%2C1544233405155.default.1544233422113
2018-12-08 01:43:42,436 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* fsync: /app/hbase/WALs/bootcamp.local,16020,1544233405155/bootcamp.local%2C16020%2C1544233405155.default.1544233422113 for DFSClient_NONMAPREDUCE_-1157747464_1
2018-12-08 01:43:45,174 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741899_1075{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /app/hbase/data/hbase/meta/1588230740/recovered.edits/0000000000000000004.temp
2018-12-08 01:43:45,196 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741899_1075{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 0
2018-12-08 01:43:45,206 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /app/hbase/data/hbase/meta/1588230740/recovered.edits/0000000000000000004.temp is closed by DFSClient_NONMAPREDUCE_-1157747464_1
2018-12-08 01:43:45,293 INFO org.apache.hadoop.ipc.Server: IPC Server handler 8 on 9000, call org.apache.hadoop.hdfs.protocol.ClientProtocol.delete from 172.18.0.2:56856 Call#53 Retry#0
org.apache.hadoop.fs.PathIsNotEmptyDirectoryException: `/app/hbase/WALs/bootcamp.local,16020,1544164277809-splitting is non empty': Directory is not empty
	at org.apache.hadoop.hdfs.server.namenode.FSDirDeleteOp.delete(FSDirDeleteOp.java:85)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:3714)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.delete(NameNodeRpcServer.java:953)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.delete(ClientNamenodeProtocolServerSideTranslatorPB.java:611)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2049)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2045)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2045)
2018-12-08 01:43:45,453 INFO org.apache.hadoop.ipc.Server: IPC Server handler 6 on 9000, call org.apache.hadoop.hdfs.protocol.ClientProtocol.delete from 172.18.0.2:56856 Call#60 Retry#0
org.apache.hadoop.fs.PathIsNotEmptyDirectoryException: `/app/hbase/WALs/bootcamp.local,16020,1544164277809-splitting is non empty': Directory is not empty
	at org.apache.hadoop.hdfs.server.namenode.FSDirDeleteOp.delete(FSDirDeleteOp.java:85)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:3714)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.delete(NameNodeRpcServer.java:953)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.delete(ClientNamenodeProtocolServerSideTranslatorPB.java:611)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2049)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2045)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2045)
2018-12-08 01:43:45,557 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741900_1076{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /app/hbase/WALs/bootcamp.local,16020,1544233405155/bootcamp.local%2C16020%2C1544233405155..meta.1544233425541.meta
2018-12-08 01:43:45,575 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* fsync: /app/hbase/WALs/bootcamp.local,16020,1544233405155/bootcamp.local%2C16020%2C1544233405155..meta.1544233425541.meta for DFSClient_NONMAPREDUCE_-1157747464_1
2018-12-08 01:43:46,041 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741899_1075 172.18.0.2:50010 
2018-12-08 01:43:46,085 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /app/hbase/data/hbase/meta/1588230740/recovered.edits/12.seqid is closed by DFSClient_NONMAPREDUCE_-1157747464_1
2018-12-08 01:43:46,443 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741901_1077{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /app/hbase/data/hbase/namespace/00cd1087428e356f701fbc2cacd741e9/recovered.edits/0000000000000000003.temp
2018-12-08 01:43:46,460 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741901_1077{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 0
2018-12-08 01:43:46,464 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /app/hbase/data/hbase/namespace/00cd1087428e356f701fbc2cacd741e9/recovered.edits/0000000000000000003.temp is closed by DFSClient_NONMAPREDUCE_-1157747464_1
2018-12-08 01:43:46,638 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741902_1078{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /app/hbase/data/hbase/namespace/00cd1087428e356f701fbc2cacd741e9/.tmp/e87a5c37df754723abd246d0931ee291
2018-12-08 01:43:46,653 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741902_1078{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 0
2018-12-08 01:43:46,656 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /app/hbase/data/hbase/namespace/00cd1087428e356f701fbc2cacd741e9/.tmp/e87a5c37df754723abd246d0931ee291 is closed by DFSClient_NONMAPREDUCE_-1157747464_1
2018-12-08 01:43:46,717 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741901_1077 172.18.0.2:50010 
2018-12-08 01:43:46,737 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /app/hbase/data/hbase/namespace/00cd1087428e356f701fbc2cacd741e9/recovered.edits/8.seqid is closed by DFSClient_NONMAPREDUCE_-1157747464_1
2018-12-08 01:43:47,561 INFO BlockStateChange: BLOCK* BlockManager: ask 172.18.0.2:50010 to delete [blk_1073741899_1075, blk_1073741901_1077]
2018-12-08 01:49:06,021 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 60 Total time for transactions(ms): 14 Number of transactions batched in Syncs: 9 Number of syncs: 43 SyncTimes(ms): 63 
2018-12-08 01:49:06,034 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741903_1079{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /app/hbase/data/hbase/meta/1588230740/.tmp/b83b417713e245d99ed13bf90c34807b
2018-12-08 01:49:06,056 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741903_1079{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 0
2018-12-08 01:49:06,060 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /app/hbase/data/hbase/meta/1588230740/.tmp/b83b417713e245d99ed13bf90c34807b is closed by DFSClient_NONMAPREDUCE_-1157747464_1
2018-12-08 01:54:39,548 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 67 Total time for transactions(ms): 15 Number of transactions batched in Syncs: 9 Number of syncs: 48 SyncTimes(ms): 68 
2018-12-08 01:54:39,555 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741830_1006 172.18.0.2:50010 
2018-12-08 01:54:39,559 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741829_1005 172.18.0.2:50010 
2018-12-08 01:54:41,161 INFO BlockStateChange: BLOCK* BlockManager: ask 172.18.0.2:50010 to delete [blk_1073741829_1005, blk_1073741830_1006]
2018-12-08 02:43:29,223 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 69 Total time for transactions(ms): 17 Number of transactions batched in Syncs: 9 Number of syncs: 50 SyncTimes(ms): 72 
2018-12-08 02:43:29,237 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741904_1080{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /app/hbase/WALs/bootcamp.local,16020,1544233405155/bootcamp.local%2C16020%2C1544233405155.default.1544237009201
2018-12-08 02:43:29,268 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* fsync: /app/hbase/WALs/bootcamp.local,16020,1544233405155/bootcamp.local%2C16020%2C1544233405155.default.1544237009201 for DFSClient_NONMAPREDUCE_-1157747464_1
2018-12-08 02:43:29,311 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741898_1074{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 83
2018-12-08 02:43:29,315 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /app/hbase/WALs/bootcamp.local,16020,1544233405155/bootcamp.local%2C16020%2C1544233405155.default.1544233422113 is closed by DFSClient_NONMAPREDUCE_-1157747464_1
2018-12-08 02:43:52,284 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741905_1081{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /app/hbase/WALs/bootcamp.local,16020,1544233405155/bootcamp.local%2C16020%2C1544233405155..meta.1544237032268.meta
2018-12-08 02:43:52,300 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* fsync: /app/hbase/WALs/bootcamp.local,16020,1544233405155/bootcamp.local%2C16020%2C1544233405155..meta.1544237032268.meta for DFSClient_NONMAPREDUCE_-1157747464_1
2018-12-08 02:43:52,310 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741900_1076{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 83
2018-12-08 02:43:52,315 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /app/hbase/WALs/bootcamp.local,16020,1544233405155/bootcamp.local%2C16020%2C1544233405155..meta.1544233425541.meta is closed by DFSClient_NONMAPREDUCE_-1157747464_1
2018-12-08 02:53:02,203 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NameNode
STARTUP_MSG:   host = bootcamp.local/172.18.0.2
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.3
STARTUP_MSG:   classpath = /etc/hadoop/conf:/usr/lib/hadoop/lib/asm-3.2.jar:/usr/lib/hadoop/lib/jackson-jaxrs-1.9.13.jar:/usr/lib/hadoop/lib/api-asn1-api-1.0.0-M20.jar:/usr/lib/hadoop/lib/jersey-json-1.9.jar:/usr/lib/hadoop/lib/gson-2.2.4.jar:/usr/lib/hadoop/lib/commons-net-3.1.jar:/usr/lib/hadoop/lib/commons-digester-1.8.jar:/usr/lib/hadoop/lib/guava-11.0.2.jar:/usr/lib/hadoop/lib/api-util-1.0.0-M20.jar:/usr/lib/hadoop/lib/jets3t-0.9.0.jar:/usr/lib/hadoop/lib/snappy-java-1.0.4.1.jar:/usr/lib/hadoop/lib/commons-compress-1.4.1.jar:/usr/lib/hadoop/lib/activation-1.1.jar:/usr/lib/hadoop/lib/slf4j-log4j12-1.7.10.jar:/usr/lib/hadoop/lib/curator-framework-2.7.1.jar:/usr/lib/hadoop/lib/jackson-core-asl-1.9.13.jar:/usr/lib/hadoop/lib/commons-beanutils-1.7.0.jar:/usr/lib/hadoop/lib/curator-client-2.7.1.jar:/usr/lib/hadoop/lib/jsr305-3.0.0.jar:/usr/lib/hadoop/lib/avro-1.7.4.jar:/usr/lib/hadoop/lib/jackson-xc-1.9.13.jar:/usr/lib/hadoop/lib/commons-configuration-1.6.jar:/usr/lib/hadoop/lib/commons-math3-3.1.1.jar:/usr/lib/hadoop/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/lib/hadoop/lib/jaxb-api-2.2.2.jar:/usr/lib/hadoop/lib/netty-3.6.2.Final.jar:/usr/lib/hadoop/lib/curator-recipes-2.7.1.jar:/usr/lib/hadoop/lib/mockito-all-1.8.5.jar:/usr/lib/hadoop/lib/commons-codec-1.4.jar:/usr/lib/hadoop/lib/jettison-1.1.jar:/usr/lib/hadoop/lib/commons-httpclient-3.1.jar:/usr/lib/hadoop/lib/jsch-0.1.42.jar:/usr/lib/hadoop/lib/java-xmlbuilder-0.4.jar:/usr/lib/hadoop/lib/xz-1.0.jar:/usr/lib/hadoop/lib/commons-logging-1.1.3.jar:/usr/lib/hadoop/lib/log4j-1.2.17.jar:/usr/lib/hadoop/lib/zookeeper-3.4.6.jar:/usr/lib/hadoop/lib/commons-lang-2.6.jar:/usr/lib/hadoop/lib/hamcrest-core-1.3.jar:/usr/lib/hadoop/lib/httpclient-4.2.5.jar:/usr/lib/hadoop/lib/commons-cli-1.2.jar:/usr/lib/hadoop/lib/commons-io-2.4.jar:/usr/lib/hadoop/lib/apacheds-i18n-2.0.0-M15.jar:/usr/lib/hadoop/lib/jetty-util-6.1.26.jar:/usr/lib/hadoop/lib/jackson-mapper-asl-1.9.13.jar:/usr/lib/hadoop/lib/htrace-core-3.1.0-incubating.jar:/usr/lib/hadoop/lib/paranamer-2.3.jar:/usr/lib/hadoop/lib/xmlenc-0.52.jar:/usr/lib/hadoop/lib/jaxb-impl-2.2.3-1.jar:/usr/lib/hadoop/lib/commons-beanutils-core-1.8.0.jar:/usr/lib/hadoop/lib/jersey-server-1.9.jar:/usr/lib/hadoop/lib/slf4j-api-1.7.10.jar:/usr/lib/hadoop/lib/jsp-api-2.1.jar:/usr/lib/hadoop/lib/jetty-6.1.26.jar:/usr/lib/hadoop/lib/junit-4.11.jar:/usr/lib/hadoop/lib/servlet-api-2.5.jar:/usr/lib/hadoop/lib/httpcore-4.2.5.jar:/usr/lib/hadoop/lib/protobuf-java-2.5.0.jar:/usr/lib/hadoop/lib/jersey-core-1.9.jar:/usr/lib/hadoop/lib/stax-api-1.0-2.jar:/usr/lib/hadoop/lib/commons-collections-3.2.2.jar:/usr/lib/hadoop/.//hadoop-nfs.jar:/usr/lib/hadoop/.//hadoop-common.jar:/usr/lib/hadoop/.//hadoop-auth-2.7.3.jar:/usr/lib/hadoop/.//hadoop-common-2.7.3-tests.jar:/usr/lib/hadoop/.//hadoop-common-2.7.3.jar:/usr/lib/hadoop/.//hadoop-auth.jar:/usr/lib/hadoop/.//hadoop-annotations.jar:/usr/lib/hadoop/.//hadoop-annotations-2.7.3.jar:/usr/lib/hadoop/.//hadoop-nfs-2.7.3.jar:/usr/lib/hadoop-hdfs/./:/usr/lib/hadoop-hdfs/lib/asm-3.2.jar:/usr/lib/hadoop-hdfs/lib/xercesImpl-2.9.1.jar:/usr/lib/hadoop-hdfs/lib/guava-11.0.2.jar:/usr/lib/hadoop-hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/lib/hadoop-hdfs/lib/jsr305-3.0.0.jar:/usr/lib/hadoop-hdfs/lib/leveldbjni-all-1.8.jar:/usr/lib/hadoop-hdfs/lib/netty-3.6.2.Final.jar:/usr/lib/hadoop-hdfs/lib/netty-all-4.0.23.Final.jar:/usr/lib/hadoop-hdfs/lib/commons-codec-1.4.jar:/usr/lib/hadoop-hdfs/lib/xml-apis-1.3.04.jar:/usr/lib/hadoop-hdfs/lib/commons-logging-1.1.3.jar:/usr/lib/hadoop-hdfs/lib/log4j-1.2.17.jar:/usr/lib/hadoop-hdfs/lib/commons-lang-2.6.jar:/usr/lib/hadoop-hdfs/lib/commons-cli-1.2.jar:/usr/lib/hadoop-hdfs/lib/commons-io-2.4.jar:/usr/lib/hadoop-hdfs/lib/jetty-util-6.1.26.jar:/usr/lib/hadoop-hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/lib/hadoop-hdfs/lib/htrace-core-3.1.0-incubating.jar:/usr/lib/hadoop-hdfs/lib/xmlenc-0.52.jar:/usr/lib/hadoop-hdfs/lib/jersey-server-1.9.jar:/usr/lib/hadoop-hdfs/lib/jetty-6.1.26.jar:/usr/lib/hadoop-hdfs/lib/commons-daemon-1.0.13.jar:/usr/lib/hadoop-hdfs/lib/servlet-api-2.5.jar:/usr/lib/hadoop-hdfs/lib/protobuf-java-2.5.0.jar:/usr/lib/hadoop-hdfs/lib/jersey-core-1.9.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs-nfs.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs-2.7.3-tests.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs-nfs-2.7.3.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs-2.7.3.jar:/usr/lib/hadoop-yarn/lib/asm-3.2.jar:/usr/lib/hadoop-yarn/lib/jackson-jaxrs-1.9.13.jar:/usr/lib/hadoop-yarn/lib/jersey-json-1.9.jar:/usr/lib/hadoop-yarn/lib/jersey-client-1.9.jar:/usr/lib/hadoop-yarn/lib/guava-11.0.2.jar:/usr/lib/hadoop-yarn/lib/jersey-guice-1.9.jar:/usr/lib/hadoop-yarn/lib/commons-compress-1.4.1.jar:/usr/lib/hadoop-yarn/lib/activation-1.1.jar:/usr/lib/hadoop-yarn/lib/guice-servlet-3.0.jar:/usr/lib/hadoop-yarn/lib/zookeeper-3.4.6-tests.jar:/usr/lib/hadoop-yarn/lib/jackson-core-asl-1.9.13.jar:/usr/lib/hadoop-yarn/lib/jsr305-3.0.0.jar:/usr/lib/hadoop-yarn/lib/jackson-xc-1.9.13.jar:/usr/lib/hadoop-yarn/lib/leveldbjni-all-1.8.jar:/usr/lib/hadoop-yarn/lib/jaxb-api-2.2.2.jar:/usr/lib/hadoop-yarn/lib/netty-3.6.2.Final.jar:/usr/lib/hadoop-yarn/lib/javax.inject-1.jar:/usr/lib/hadoop-yarn/lib/commons-codec-1.4.jar:/usr/lib/hadoop-yarn/lib/jettison-1.1.jar:/usr/lib/hadoop-yarn/lib/guice-3.0.jar:/usr/lib/hadoop-yarn/lib/xz-1.0.jar:/usr/lib/hadoop-yarn/lib/commons-logging-1.1.3.jar:/usr/lib/hadoop-yarn/lib/log4j-1.2.17.jar:/usr/lib/hadoop-yarn/lib/zookeeper-3.4.6.jar:/usr/lib/hadoop-yarn/lib/commons-lang-2.6.jar:/usr/lib/hadoop-yarn/lib/commons-cli-1.2.jar:/usr/lib/hadoop-yarn/lib/commons-io-2.4.jar:/usr/lib/hadoop-yarn/lib/jetty-util-6.1.26.jar:/usr/lib/hadoop-yarn/lib/jackson-mapper-asl-1.9.13.jar:/usr/lib/hadoop-yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/lib/hadoop-yarn/lib/jersey-server-1.9.jar:/usr/lib/hadoop-yarn/lib/aopalliance-1.0.jar:/usr/lib/hadoop-yarn/lib/jetty-6.1.26.jar:/usr/lib/hadoop-yarn/lib/servlet-api-2.5.jar:/usr/lib/hadoop-yarn/lib/protobuf-java-2.5.0.jar:/usr/lib/hadoop-yarn/lib/jersey-core-1.9.jar:/usr/lib/hadoop-yarn/lib/stax-api-1.0-2.jar:/usr/lib/hadoop-yarn/lib/commons-collections-3.2.2.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-resourcemanager.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-resourcemanager-2.7.3.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-applicationhistoryservice-2.7.3.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-registry.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-tests.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-common.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-common-2.7.3.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-applications-distributedshell.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-client.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-common-2.7.3.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-applications-unmanaged-am-launcher.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-web-proxy.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-api.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-tests-2.7.3.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-nodemanager-2.7.3.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-api-2.7.3.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-sharedcachemanager-2.7.3.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-common.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-client-2.7.3.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-nodemanager.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-sharedcachemanager.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-registry-2.7.3.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-applications-unmanaged-am-launcher-2.7.3.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-web-proxy-2.7.3.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-applicationhistoryservice.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-applications-distributedshell-2.7.3.jar:/usr/lib/hadoop-mapreduce/lib/asm-3.2.jar:/usr/lib/hadoop-mapreduce/lib/jersey-guice-1.9.jar:/usr/lib/hadoop-mapreduce/lib/snappy-java-1.0.4.1.jar:/usr/lib/hadoop-mapreduce/lib/commons-compress-1.4.1.jar:/usr/lib/hadoop-mapreduce/lib/guice-servlet-3.0.jar:/usr/lib/hadoop-mapreduce/lib/jackson-core-asl-1.9.13.jar:/usr/lib/hadoop-mapreduce/lib/avro-1.7.4.jar:/usr/lib/hadoop-mapreduce/lib/leveldbjni-all-1.8.jar:/usr/lib/hadoop-mapreduce/lib/netty-3.6.2.Final.jar:/usr/lib/hadoop-mapreduce/lib/javax.inject-1.jar:/usr/lib/hadoop-mapreduce/lib/guice-3.0.jar:/usr/lib/hadoop-mapreduce/lib/xz-1.0.jar:/usr/lib/hadoop-mapreduce/lib/log4j-1.2.17.jar:/usr/lib/hadoop-mapreduce/lib/hamcrest-core-1.3.jar:/usr/lib/hadoop-mapreduce/lib/commons-io-2.4.jar:/usr/lib/hadoop-mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/usr/lib/hadoop-mapreduce/lib/paranamer-2.3.jar:/usr/lib/hadoop-mapreduce/lib/jersey-server-1.9.jar:/usr/lib/hadoop-mapreduce/lib/aopalliance-1.0.jar:/usr/lib/hadoop-mapreduce/lib/junit-4.11.jar:/usr/lib/hadoop-mapreduce/lib/protobuf-java-2.5.0.jar:/usr/lib/hadoop-mapreduce/lib/jersey-core-1.9.jar:/usr/lib/hadoop-mapreduce/.//jackson-core-2.2.3.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-jobclient-2.7.3-tests.jar:/usr/lib/hadoop-mapreduce/.//azure-storage-2.0.0.jar:/usr/lib/hadoop-mapreduce/.//metrics-core-3.0.1.jar:/usr/lib/hadoop-mapreduce/.//asm-3.2.jar:/usr/lib/hadoop-mapreduce/.//jackson-jaxrs-1.9.13.jar:/usr/lib/hadoop-mapreduce/.//hadoop-sls-2.7.3.jar:/usr/lib/hadoop-mapreduce/.//api-asn1-api-1.0.0-M20.jar:/usr/lib/hadoop-mapreduce/.//jersey-json-1.9.jar:/usr/lib/hadoop-mapreduce/.//gson-2.2.4.jar:/usr/lib/hadoop-mapreduce/.//commons-net-3.1.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-app-2.7.3.jar:/usr/lib/hadoop-mapreduce/.//commons-digester-1.8.jar:/usr/lib/hadoop-mapreduce/.//guava-11.0.2.jar:/usr/lib/hadoop-mapreduce/.//api-util-1.0.0-M20.jar:/usr/lib/hadoop-mapreduce/.//jets3t-0.9.0.jar:/usr/lib/hadoop-mapreduce/.//snappy-java-1.0.4.1.jar:/usr/lib/hadoop-mapreduce/.//hadoop-streaming-2.7.3.jar:/usr/lib/hadoop-mapreduce/.//commons-compress-1.4.1.jar:/usr/lib/hadoop-mapreduce/.//activation-1.1.jar:/usr/lib/hadoop-mapreduce/.//curator-framework-2.7.1.jar:/usr/lib/hadoop-mapreduce/.//hadoop-archives.jar:/usr/lib/hadoop-mapreduce/.//hadoop-aws.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-core.jar:/usr/lib/hadoop-mapreduce/.//jackson-core-asl-1.9.13.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-hs.jar:/usr/lib/hadoop-mapreduce/.//commons-beanutils-1.7.0.jar:/usr/lib/hadoop-mapreduce/.//curator-client-2.7.1.jar:/usr/lib/hadoop-mapreduce/.//hadoop-azure-2.7.3.jar:/usr/lib/hadoop-mapreduce/.//jsr305-3.0.0.jar:/usr/lib/hadoop-mapreduce/.//avro-1.7.4.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-jobclient.jar:/usr/lib/hadoop-mapreduce/.//hadoop-gridmix.jar:/usr/lib/hadoop-mapreduce/.//hadoop-distcp.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-app.jar:/usr/lib/hadoop-mapreduce/.//jackson-xc-1.9.13.jar:/usr/lib/hadoop-mapreduce/.//hadoop-auth-2.7.3.jar:/usr/lib/hadoop-mapreduce/.//commons-configuration-1.6.jar:/usr/lib/hadoop-mapreduce/.//commons-math3-3.1.1.jar:/usr/lib/hadoop-mapreduce/.//hadoop-datajoin-2.7.3.jar:/usr/lib/hadoop-mapreduce/.//apacheds-kerberos-codec-2.0.0-M15.jar:/usr/lib/hadoop-mapreduce/.//hadoop-gridmix-2.7.3.jar:/usr/lib/hadoop-mapreduce/.//hadoop-ant.jar:/usr/lib/hadoop-mapreduce/.//hadoop-auth.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-shuffle-2.7.3.jar:/usr/lib/hadoop-mapreduce/.//jaxb-api-2.2.2.jar:/usr/lib/hadoop-mapreduce/.//netty-3.6.2.Final.jar:/usr/lib/hadoop-mapreduce/.//curator-recipes-2.7.1.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-hs-plugins.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-common-2.7.3.jar:/usr/lib/hadoop-mapreduce/.//mockito-all-1.8.5.jar:/usr/lib/hadoop-mapreduce/.//joda-time-2.9.9.jar:/usr/lib/hadoop-mapreduce/.//hadoop-openstack.jar:/usr/lib/hadoop-mapreduce/.//jackson-annotations-2.2.3.jar:/usr/lib/hadoop-mapreduce/.//commons-codec-1.4.jar:/usr/lib/hadoop-mapreduce/.//hadoop-extras-2.7.3.jar:/usr/lib/hadoop-mapreduce/.//jettison-1.1.jar:/usr/lib/hadoop-mapreduce/.//hadoop-distcp-2.7.3.jar:/usr/lib/hadoop-mapreduce/.//commons-httpclient-3.1.jar:/usr/lib/hadoop-mapreduce/.//jsch-0.1.42.jar:/usr/lib/hadoop-mapreduce/.//hadoop-sls.jar:/usr/lib/hadoop-mapreduce/.//jackson-databind-2.2.3.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-hs-2.7.3.jar:/usr/lib/hadoop-mapreduce/.//java-xmlbuilder-0.4.jar:/usr/lib/hadoop-mapreduce/.//aws-java-sdk-1.7.4.jar:/usr/lib/hadoop-mapreduce/.//hadoop-aws-2.7.3.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-examples-2.7.3.jar:/usr/lib/hadoop-mapreduce/.//xz-1.0.jar:/usr/lib/hadoop-mapreduce/.//hadoop-rumen.jar:/usr/lib/hadoop-mapreduce/.//commons-logging-1.1.3.jar:/usr/lib/hadoop-mapreduce/.//log4j-1.2.17.jar:/usr/lib/hadoop-mapreduce/.//zookeeper-3.4.6.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-core-2.7.3.jar:/usr/lib/hadoop-mapreduce/.//hadoop-datajoin.jar:/usr/lib/hadoop-mapreduce/.//commons-lang-2.6.jar:/usr/lib/hadoop-mapreduce/.//commons-lang3-3.3.2.jar:/usr/lib/hadoop-mapreduce/.//hamcrest-core-1.3.jar:/usr/lib/hadoop-mapreduce/.//httpclient-4.2.5.jar:/usr/lib/hadoop-mapreduce/.//commons-cli-1.2.jar:/usr/lib/hadoop-mapreduce/.//commons-io-2.4.jar:/usr/lib/hadoop-mapreduce/.//apacheds-i18n-2.0.0-M15.jar:/usr/lib/hadoop-mapreduce/.//jetty-util-6.1.26.jar:/usr/lib/hadoop-mapreduce/.//jackson-mapper-asl-1.9.13.jar:/usr/lib/hadoop-mapreduce/.//hadoop-archives-2.7.3.jar:/usr/lib/hadoop-mapreduce/.//htrace-core-3.1.0-incubating.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-common.jar:/usr/lib/hadoop-mapreduce/.//paranamer-2.3.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-jobclient-2.7.3.jar:/usr/lib/hadoop-mapreduce/.//hadoop-extras.jar:/usr/lib/hadoop-mapreduce/.//xmlenc-0.52.jar:/usr/lib/hadoop-mapreduce/.//hadoop-openstack-2.7.3.jar:/usr/lib/hadoop-mapreduce/.//jaxb-impl-2.2.3-1.jar:/usr/lib/hadoop-mapreduce/.//commons-beanutils-core-1.8.0.jar:/usr/lib/hadoop-mapreduce/.//jersey-server-1.9.jar:/usr/lib/hadoop-mapreduce/.//jsp-api-2.1.jar:/usr/lib/hadoop-mapreduce/.//jetty-6.1.26.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-hs-plugins-2.7.3.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-examples.jar:/usr/lib/hadoop-mapreduce/.//junit-4.11.jar:/usr/lib/hadoop-mapreduce/.//hadoop-azure.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-shuffle.jar:/usr/lib/hadoop-mapreduce/.//hadoop-streaming.jar:/usr/lib/hadoop-mapreduce/.//hadoop-ant-2.7.3.jar:/usr/lib/hadoop-mapreduce/.//servlet-api-2.5.jar:/usr/lib/hadoop-mapreduce/.//httpcore-4.2.5.jar:/usr/lib/hadoop-mapreduce/.//hadoop-rumen-2.7.3.jar:/usr/lib/hadoop-mapreduce/.//protobuf-java-2.5.0.jar:/usr/lib/hadoop-mapreduce/.//jersey-core-1.9.jar:/usr/lib/hadoop-mapreduce/.//stax-api-1.0-2.jar:/usr/lib/hadoop-mapreduce/.//commons-collections-3.2.2.jar:/usr/lib/hadoop/contrib/capacity-scheduler/*.jar:/usr/lib/hadoop/contrib/capacity-scheduler/*.jar:/usr/lib/hadoop/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/bigtop.git -r 2365207dc0440bb884e41d4ffe32a37ad0d0ed28; compiled by 'jenkins' on 2017-10-05T21:00Z
STARTUP_MSG:   java = 1.8.0_181
************************************************************/
2018-12-08 02:53:02,215 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2018-12-08 02:53:02,224 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: createNameNode []
2018-12-08 02:53:02,610 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2018-12-08 02:53:02,747 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2018-12-08 02:53:02,748 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NameNode metrics system started
2018-12-08 02:53:02,752 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: fs.defaultFS is hdfs://bootcamp.local:9000
2018-12-08 02:53:02,753 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Clients are to use bootcamp.local:9000 to access this namenode/service.
2018-12-08 02:53:02,959 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for hdfs at: http://0.0.0.0:50070
2018-12-08 02:53:03,038 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2018-12-08 02:53:03,049 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2018-12-08 02:53:03,059 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.namenode is not defined
2018-12-08 02:53:03,068 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2018-12-08 02:53:03,072 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2018-12-08 02:53:03,073 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2018-12-08 02:53:03,073 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2018-12-08 02:53:03,283 INFO org.apache.hadoop.http.HttpServer2: Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2018-12-08 02:53:03,287 INFO org.apache.hadoop.http.HttpServer2: addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2018-12-08 02:53:03,317 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50070
2018-12-08 02:53:03,317 INFO org.mortbay.log: jetty-6.1.26
2018-12-08 02:53:03,502 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:50070
2018-12-08 02:53:03,556 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one image storage directory (dfs.namenode.name.dir) configured. Beware of data loss due to lack of redundant storage directories!
2018-12-08 02:53:03,556 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one namespace edits storage directory (dfs.namenode.edits.dir) configured. Beware of data loss due to lack of redundant storage directories!
2018-12-08 02:53:03,617 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: No KeyProvider found.
2018-12-08 02:53:03,618 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair:true
2018-12-08 02:53:03,705 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2018-12-08 02:53:03,706 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2018-12-08 02:53:03,708 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2018-12-08 02:53:03,709 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2018 Dec 08 02:53:03
2018-12-08 02:53:03,712 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2018-12-08 02:53:03,713 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2018-12-08 02:53:03,717 INFO org.apache.hadoop.util.GSet: 2.0% max memory 889 MB = 17.8 MB
2018-12-08 02:53:03,717 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2018-12-08 02:53:03,726 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2018-12-08 02:53:03,727 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 1
2018-12-08 02:53:03,727 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2018-12-08 02:53:03,728 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2018-12-08 02:53:03,730 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2018-12-08 02:53:03,730 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2018-12-08 02:53:03,731 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2018-12-08 02:53:03,731 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2018-12-08 02:53:03,743 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = hdfs (auth:SIMPLE)
2018-12-08 02:53:03,744 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2018-12-08 02:53:03,744 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2018-12-08 02:53:03,745 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2018-12-08 02:53:03,747 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2018-12-08 02:53:03,844 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2018-12-08 02:53:03,844 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2018-12-08 02:53:03,845 INFO org.apache.hadoop.util.GSet: 1.0% max memory 889 MB = 8.9 MB
2018-12-08 02:53:03,845 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2018-12-08 02:53:03,846 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: ACLs enabled? false
2018-12-08 02:53:03,847 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: XAttrs enabled? true
2018-12-08 02:53:03,847 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Maximum size of an xattr: 16384
2018-12-08 02:53:03,848 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times
2018-12-08 02:53:03,857 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2018-12-08 02:53:03,857 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2018-12-08 02:53:03,858 INFO org.apache.hadoop.util.GSet: 0.25% max memory 889 MB = 2.2 MB
2018-12-08 02:53:03,858 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2018-12-08 02:53:03,860 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2018-12-08 02:53:03,860 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2018-12-08 02:53:03,861 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2018-12-08 02:53:03,865 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.window.num.buckets = 10
2018-12-08 02:53:03,866 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.num.users = 10
2018-12-08 02:53:03,866 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2018-12-08 02:53:03,868 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache on namenode is enabled
2018-12-08 02:53:03,868 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2018-12-08 02:53:03,871 INFO org.apache.hadoop.util.GSet: Computing capacity for map NameNodeRetryCache
2018-12-08 02:53:03,872 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2018-12-08 02:53:03,872 INFO org.apache.hadoop.util.GSet: 0.029999999329447746% max memory 889 MB = 273.1 KB
2018-12-08 02:53:03,873 INFO org.apache.hadoop.util.GSet: capacity      = 2^15 = 32768 entries
2018-12-08 02:53:03,892 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /data/name/in_use.lock acquired by nodename 756@bootcamp.local
2018-12-08 02:53:03,940 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Recovering unfinalized segments in /data/name/current
2018-12-08 02:53:04,103 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /data/name/current/edits_inprogress_0000000000000000842 -> /data/name/current/edits_0000000000000000842-0000000000000000925
2018-12-08 02:53:04,111 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Planning to load image: FSImageFile(file=/data/name/current/fsimage_0000000000000000841, cpktTxId=0000000000000000841)
2018-12-08 02:53:04,154 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Loading 126 INodes.
2018-12-08 02:53:04,222 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Loaded FSImage in 0 seconds.
2018-12-08 02:53:04,222 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 841 from /data/name/current/fsimage_0000000000000000841
2018-12-08 02:53:04,223 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@2262b621 expecting start txid #842
2018-12-08 02:53:04,224 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /data/name/current/edits_0000000000000000842-0000000000000000925
2018-12-08 02:53:04,227 INFO org.apache.hadoop.hdfs.server.namenode.EditLogInputStream: Fast-forwarding stream '/data/name/current/edits_0000000000000000842-0000000000000000925' to transaction ID 842
2018-12-08 02:53:04,299 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /data/name/current/edits_0000000000000000842-0000000000000000925 of size 1048576 edits # 84 loaded in 0 seconds
2018-12-08 02:53:04,301 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Need to save fs image? true (staleImage=true, haEnabled=false, isRollingUpgrade=false)
2018-12-08 02:53:04,301 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Save namespace ...
2018-12-08 02:53:04,310 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /data/name/current/fsimage.ckpt_0000000000000000925 using no compression
2018-12-08 02:53:04,366 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /data/name/current/fsimage.ckpt_0000000000000000925 of size 10234 bytes saved in 0 seconds.
2018-12-08 02:53:04,373 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 841
2018-12-08 02:53:04,374 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/data/name/current/fsimage_0000000000000000014, cpktTxId=0000000000000000014)
2018-12-08 02:53:04,387 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 926
2018-12-08 02:53:04,492 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2018-12-08 02:53:04,493 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Finished loading FSImage in 616 msecs
2018-12-08 02:53:04,807 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: RPC server is binding to bootcamp.local:9000
2018-12-08 02:53:04,815 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2018-12-08 02:53:04,830 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 9000
2018-12-08 02:53:04,861 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Registered FSNamesystemState MBean
2018-12-08 02:53:04,874 INFO org.apache.hadoop.hdfs.server.namenode.LeaseManager: Number of blocks under construction: 2
2018-12-08 02:53:04,875 INFO org.apache.hadoop.hdfs.server.namenode.LeaseManager: Number of blocks under construction: 2
2018-12-08 02:53:04,876 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode ON. 
The reported blocks 0 needs additional 47 blocks to reach the threshold 0.9990 of total blocks 47.
The number of live datanodes 0 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached.
2018-12-08 02:53:04,885 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Number of failed storage changes from 0 to 0
2018-12-08 02:53:04,921 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2018-12-08 02:53:04,921 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 9000: starting
2018-12-08 02:53:04,926 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: NameNode RPC up at: bootcamp.local/172.18.0.2:9000
2018-12-08 02:53:04,926 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Starting services required for active state
2018-12-08 02:53:04,932 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Starting CacheReplicationMonitor with interval 30000 milliseconds
2018-12-08 02:53:13,887 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(172.18.0.2:50010, datanodeUuid=47ecd31e-43cd-4989-84ba-314b1664d0de, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-747ab8c6-1ec4-46a0-9dee-c8151846aca5;nsid=199960936;c=0) storage 47ecd31e-43cd-4989-84ba-314b1664d0de
2018-12-08 02:53:13,888 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Number of failed storage changes from 0 to 0
2018-12-08 02:53:13,890 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/172.18.0.2:50010
2018-12-08 02:53:14,002 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Number of failed storage changes from 0 to 0
2018-12-08 02:53:14,003 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Adding new storage ID DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5 for DN 172.18.0.2:50010
2018-12-08 02:53:14,066 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode extension entered. 
The reported blocks 46 has reached the threshold 0.9990 of total blocks 47. The number of live datanodes 1 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 29 seconds.
2018-12-08 02:53:14,067 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: initializing replication queues
2018-12-08 02:53:14,070 INFO BlockStateChange: BLOCK* processReport: from storage DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5 node DatanodeRegistration(172.18.0.2:50010, datanodeUuid=47ecd31e-43cd-4989-84ba-314b1664d0de, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-747ab8c6-1ec4-46a0-9dee-c8151846aca5;nsid=199960936;c=0), blocks: 49, hasStaleStorage: false, processing time: 10 msecs
2018-12-08 02:53:14,085 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Total number of blocks            = 49
2018-12-08 02:53:14,089 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of invalid blocks          = 0
2018-12-08 02:53:14,089 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of under-replicated blocks = 0
2018-12-08 02:53:14,090 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of  over-replicated blocks = 0
2018-12-08 02:53:14,090 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of blocks being written    = 2
2018-12-08 02:53:14,092 INFO org.apache.hadoop.hdfs.StateChange: STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 24 msec
2018-12-08 02:53:35,060 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode ON, in safe mode extension. 
The reported blocks 47 has reached the threshold 0.9990 of total blocks 47. The number of live datanodes 1 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 8 seconds.
2018-12-08 02:53:44,069 INFO org.apache.hadoop.hdfs.StateChange: STATE* Leaving safe mode after 40 secs
2018-12-08 02:53:44,070 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode is OFF
2018-12-08 02:53:44,070 INFO org.apache.hadoop.hdfs.StateChange: STATE* Network topology has 1 racks and 1 datanodes
2018-12-08 02:53:44,071 INFO org.apache.hadoop.hdfs.StateChange: STATE* UnderReplicatedBlocks has 0 blocks
2018-12-08 02:53:48,327 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: recoverLease: [Lease.  Holder: DFSClient_NONMAPREDUCE_332982891_1, pendingcreates: 1], src=/app/hbase/MasterProcWALs/state-00000000000000000003.log from client DFSClient_NONMAPREDUCE_332982891_1
2018-12-08 02:53:48,328 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Recovering [Lease.  Holder: DFSClient_NONMAPREDUCE_332982891_1, pendingcreates: 1], src=/app/hbase/MasterProcWALs/state-00000000000000000003.log
2018-12-08 02:53:48,329 WARN org.apache.hadoop.hdfs.StateChange: BLOCK* internalReleaseLease: All existing blocks are COMPLETE, lease removed, file closed.
2018-12-08 02:53:50,280 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741906_1082{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /app/hbase/WALs/bootcamp.local,16020,1544237612204/bootcamp.local%2C16020%2C1544237612204.default.1544237630182
2018-12-08 02:53:50,457 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* fsync: /app/hbase/WALs/bootcamp.local,16020,1544237612204/bootcamp.local%2C16020%2C1544237612204.default.1544237630182 for DFSClient_NONMAPREDUCE_1857500738_1
2018-12-08 02:53:53,086 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: recoverLease: [Lease.  Holder: DFSClient_NONMAPREDUCE_-1157747464_1, pendingcreates: 2], src=/app/hbase/WALs/bootcamp.local,16020,1544233405155-splitting/bootcamp.local%2C16020%2C1544233405155..meta.1544237032268.meta from client DFSClient_NONMAPREDUCE_-1157747464_1
2018-12-08 02:53:53,086 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Recovering [Lease.  Holder: DFSClient_NONMAPREDUCE_-1157747464_1, pendingcreates: 2], src=/app/hbase/WALs/bootcamp.local,16020,1544233405155-splitting/bootcamp.local%2C16020%2C1544233405155..meta.1544237032268.meta
2018-12-08 02:53:53,088 INFO BlockStateChange: BLOCK* blk_1073741905_1081{UCState=UNDER_RECOVERY, truncateBlock=null, primaryNodeIndex=0, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RWR]]} recovery started, primary=ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RWR]
2018-12-08 02:53:53,089 WARN org.apache.hadoop.hdfs.StateChange: DIR* NameSystem.internalReleaseLease: File /app/hbase/WALs/bootcamp.local,16020,1544233405155-splitting/bootcamp.local%2C16020%2C1544233405155..meta.1544237032268.meta has not been closed. Lease recovery is in progress. RecoveryId = 1083 for block blk_1073741905_1081{UCState=UNDER_RECOVERY, truncateBlock=null, primaryNodeIndex=0, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RWR]]}
2018-12-08 02:53:55,874 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741905_1081{UCState=UNDER_RECOVERY, truncateBlock=null, primaryNodeIndex=0, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RWR]]} size 83
2018-12-08 02:53:55,883 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: commitBlockSynchronization(oldBlock=BP-1288371730-172.17.0.2-1536728332297:blk_1073741905_1081, newgenerationstamp=1083, newlength=83, newtargets=[172.18.0.2:50010], closeFile=true, deleteBlock=false)
2018-12-08 02:53:55,890 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: commitBlockSynchronization(oldBlock=BP-1288371730-172.17.0.2-1536728332297:blk_1073741905_1081, file=/app/hbase/WALs/bootcamp.local,16020,1544233405155-splitting/bootcamp.local%2C16020%2C1544233405155..meta.1544237032268.meta, newgenerationstamp=1083, newlength=83, newtargets=[172.18.0.2:50010]) successful
2018-12-08 02:53:57,241 INFO org.apache.hadoop.ipc.Server: IPC Server handler 8 on 9000, call org.apache.hadoop.hdfs.protocol.ClientProtocol.delete from 172.18.0.2:57700 Call#53 Retry#0
org.apache.hadoop.fs.PathIsNotEmptyDirectoryException: `/app/hbase/WALs/bootcamp.local,16020,1544233405155-splitting is non empty': Directory is not empty
	at org.apache.hadoop.hdfs.server.namenode.FSDirDeleteOp.delete(FSDirDeleteOp.java:85)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:3714)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.delete(NameNodeRpcServer.java:953)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.delete(ClientNamenodeProtocolServerSideTranslatorPB.java:611)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2049)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2045)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2045)
2018-12-08 02:53:57,383 INFO org.apache.hadoop.ipc.Server: IPC Server handler 4 on 9000, call org.apache.hadoop.hdfs.protocol.ClientProtocol.delete from 172.18.0.2:57700 Call#60 Retry#0
org.apache.hadoop.fs.PathIsNotEmptyDirectoryException: `/app/hbase/WALs/bootcamp.local,16020,1544233405155-splitting is non empty': Directory is not empty
	at org.apache.hadoop.hdfs.server.namenode.FSDirDeleteOp.delete(FSDirDeleteOp.java:85)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:3714)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.delete(NameNodeRpcServer.java:953)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.delete(ClientNamenodeProtocolServerSideTranslatorPB.java:611)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2049)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2045)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2045)
2018-12-08 02:53:57,509 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741907_1084{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /app/hbase/WALs/bootcamp.local,16020,1544237612204/bootcamp.local%2C16020%2C1544237612204..meta.1544237637500.meta
2018-12-08 02:53:57,523 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* fsync: /app/hbase/WALs/bootcamp.local,16020,1544237612204/bootcamp.local%2C16020%2C1544237612204..meta.1544237637500.meta for DFSClient_NONMAPREDUCE_1857500738_1
2018-12-08 02:53:57,964 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /app/hbase/data/hbase/meta/1588230740/recovered.edits/17.seqid is closed by DFSClient_NONMAPREDUCE_1857500738_1
2018-12-08 02:53:58,288 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: recoverLease: [Lease.  Holder: DFSClient_NONMAPREDUCE_-1157747464_1, pendingcreates: 1], src=/app/hbase/WALs/bootcamp.local,16020,1544233405155-splitting/bootcamp.local%2C16020%2C1544233405155.default.1544237009201 from client DFSClient_NONMAPREDUCE_-1157747464_1
2018-12-08 02:53:58,289 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Recovering [Lease.  Holder: DFSClient_NONMAPREDUCE_-1157747464_1, pendingcreates: 1], src=/app/hbase/WALs/bootcamp.local,16020,1544233405155-splitting/bootcamp.local%2C16020%2C1544233405155.default.1544237009201
2018-12-08 02:53:58,289 INFO BlockStateChange: BLOCK* blk_1073741904_1080{UCState=UNDER_RECOVERY, truncateBlock=null, primaryNodeIndex=0, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RWR]]} recovery started, primary=ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RWR]
2018-12-08 02:53:58,290 WARN org.apache.hadoop.hdfs.StateChange: DIR* NameSystem.internalReleaseLease: File /app/hbase/WALs/bootcamp.local,16020,1544233405155-splitting/bootcamp.local%2C16020%2C1544233405155.default.1544237009201 has not been closed. Lease recovery is in progress. RecoveryId = 1085 for block blk_1073741904_1080{UCState=UNDER_RECOVERY, truncateBlock=null, primaryNodeIndex=0, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RWR]]}
2018-12-08 02:53:58,859 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: commitBlockSynchronization(oldBlock=BP-1288371730-172.17.0.2-1536728332297:blk_1073741904_1080, newgenerationstamp=1085, newlength=83, newtargets=[172.18.0.2:50010], closeFile=true, deleteBlock=false)
2018-12-08 02:53:58,861 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: commitBlockSynchronization(oldBlock=BP-1288371730-172.17.0.2-1536728332297:blk_1073741904_1080, file=/app/hbase/WALs/bootcamp.local,16020,1544233405155-splitting/bootcamp.local%2C16020%2C1544233405155.default.1544237009201, newgenerationstamp=1085, newlength=83, newtargets=[172.18.0.2:50010]) successful
2018-12-08 02:54:02,466 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /app/hbase/data/hbase/namespace/00cd1087428e356f701fbc2cacd741e9/recovered.edits/9.seqid is closed by DFSClient_NONMAPREDUCE_1857500738_1
2018-12-08 02:57:52,257 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NameNode
STARTUP_MSG:   host = bootcamp.local/172.18.0.2
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.3
STARTUP_MSG:   classpath = /etc/hadoop/conf:/usr/lib/hadoop/lib/asm-3.2.jar:/usr/lib/hadoop/lib/jackson-jaxrs-1.9.13.jar:/usr/lib/hadoop/lib/api-asn1-api-1.0.0-M20.jar:/usr/lib/hadoop/lib/jersey-json-1.9.jar:/usr/lib/hadoop/lib/gson-2.2.4.jar:/usr/lib/hadoop/lib/commons-net-3.1.jar:/usr/lib/hadoop/lib/commons-digester-1.8.jar:/usr/lib/hadoop/lib/guava-11.0.2.jar:/usr/lib/hadoop/lib/api-util-1.0.0-M20.jar:/usr/lib/hadoop/lib/jets3t-0.9.0.jar:/usr/lib/hadoop/lib/snappy-java-1.0.4.1.jar:/usr/lib/hadoop/lib/commons-compress-1.4.1.jar:/usr/lib/hadoop/lib/activation-1.1.jar:/usr/lib/hadoop/lib/slf4j-log4j12-1.7.10.jar:/usr/lib/hadoop/lib/curator-framework-2.7.1.jar:/usr/lib/hadoop/lib/jackson-core-asl-1.9.13.jar:/usr/lib/hadoop/lib/commons-beanutils-1.7.0.jar:/usr/lib/hadoop/lib/curator-client-2.7.1.jar:/usr/lib/hadoop/lib/jsr305-3.0.0.jar:/usr/lib/hadoop/lib/avro-1.7.4.jar:/usr/lib/hadoop/lib/jackson-xc-1.9.13.jar:/usr/lib/hadoop/lib/commons-configuration-1.6.jar:/usr/lib/hadoop/lib/commons-math3-3.1.1.jar:/usr/lib/hadoop/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/lib/hadoop/lib/jaxb-api-2.2.2.jar:/usr/lib/hadoop/lib/netty-3.6.2.Final.jar:/usr/lib/hadoop/lib/curator-recipes-2.7.1.jar:/usr/lib/hadoop/lib/mockito-all-1.8.5.jar:/usr/lib/hadoop/lib/commons-codec-1.4.jar:/usr/lib/hadoop/lib/jettison-1.1.jar:/usr/lib/hadoop/lib/commons-httpclient-3.1.jar:/usr/lib/hadoop/lib/jsch-0.1.42.jar:/usr/lib/hadoop/lib/java-xmlbuilder-0.4.jar:/usr/lib/hadoop/lib/xz-1.0.jar:/usr/lib/hadoop/lib/commons-logging-1.1.3.jar:/usr/lib/hadoop/lib/log4j-1.2.17.jar:/usr/lib/hadoop/lib/zookeeper-3.4.6.jar:/usr/lib/hadoop/lib/commons-lang-2.6.jar:/usr/lib/hadoop/lib/hamcrest-core-1.3.jar:/usr/lib/hadoop/lib/httpclient-4.2.5.jar:/usr/lib/hadoop/lib/commons-cli-1.2.jar:/usr/lib/hadoop/lib/commons-io-2.4.jar:/usr/lib/hadoop/lib/apacheds-i18n-2.0.0-M15.jar:/usr/lib/hadoop/lib/jetty-util-6.1.26.jar:/usr/lib/hadoop/lib/jackson-mapper-asl-1.9.13.jar:/usr/lib/hadoop/lib/htrace-core-3.1.0-incubating.jar:/usr/lib/hadoop/lib/paranamer-2.3.jar:/usr/lib/hadoop/lib/xmlenc-0.52.jar:/usr/lib/hadoop/lib/jaxb-impl-2.2.3-1.jar:/usr/lib/hadoop/lib/commons-beanutils-core-1.8.0.jar:/usr/lib/hadoop/lib/jersey-server-1.9.jar:/usr/lib/hadoop/lib/slf4j-api-1.7.10.jar:/usr/lib/hadoop/lib/jsp-api-2.1.jar:/usr/lib/hadoop/lib/jetty-6.1.26.jar:/usr/lib/hadoop/lib/junit-4.11.jar:/usr/lib/hadoop/lib/servlet-api-2.5.jar:/usr/lib/hadoop/lib/httpcore-4.2.5.jar:/usr/lib/hadoop/lib/protobuf-java-2.5.0.jar:/usr/lib/hadoop/lib/jersey-core-1.9.jar:/usr/lib/hadoop/lib/stax-api-1.0-2.jar:/usr/lib/hadoop/lib/commons-collections-3.2.2.jar:/usr/lib/hadoop/.//hadoop-nfs.jar:/usr/lib/hadoop/.//hadoop-common.jar:/usr/lib/hadoop/.//hadoop-auth-2.7.3.jar:/usr/lib/hadoop/.//hadoop-common-2.7.3-tests.jar:/usr/lib/hadoop/.//hadoop-common-2.7.3.jar:/usr/lib/hadoop/.//hadoop-auth.jar:/usr/lib/hadoop/.//hadoop-annotations.jar:/usr/lib/hadoop/.//hadoop-annotations-2.7.3.jar:/usr/lib/hadoop/.//hadoop-nfs-2.7.3.jar:/usr/lib/hadoop-hdfs/./:/usr/lib/hadoop-hdfs/lib/asm-3.2.jar:/usr/lib/hadoop-hdfs/lib/xercesImpl-2.9.1.jar:/usr/lib/hadoop-hdfs/lib/guava-11.0.2.jar:/usr/lib/hadoop-hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/lib/hadoop-hdfs/lib/jsr305-3.0.0.jar:/usr/lib/hadoop-hdfs/lib/leveldbjni-all-1.8.jar:/usr/lib/hadoop-hdfs/lib/netty-3.6.2.Final.jar:/usr/lib/hadoop-hdfs/lib/netty-all-4.0.23.Final.jar:/usr/lib/hadoop-hdfs/lib/commons-codec-1.4.jar:/usr/lib/hadoop-hdfs/lib/xml-apis-1.3.04.jar:/usr/lib/hadoop-hdfs/lib/commons-logging-1.1.3.jar:/usr/lib/hadoop-hdfs/lib/log4j-1.2.17.jar:/usr/lib/hadoop-hdfs/lib/commons-lang-2.6.jar:/usr/lib/hadoop-hdfs/lib/commons-cli-1.2.jar:/usr/lib/hadoop-hdfs/lib/commons-io-2.4.jar:/usr/lib/hadoop-hdfs/lib/jetty-util-6.1.26.jar:/usr/lib/hadoop-hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/lib/hadoop-hdfs/lib/htrace-core-3.1.0-incubating.jar:/usr/lib/hadoop-hdfs/lib/xmlenc-0.52.jar:/usr/lib/hadoop-hdfs/lib/jersey-server-1.9.jar:/usr/lib/hadoop-hdfs/lib/jetty-6.1.26.jar:/usr/lib/hadoop-hdfs/lib/commons-daemon-1.0.13.jar:/usr/lib/hadoop-hdfs/lib/servlet-api-2.5.jar:/usr/lib/hadoop-hdfs/lib/protobuf-java-2.5.0.jar:/usr/lib/hadoop-hdfs/lib/jersey-core-1.9.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs-nfs.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs-2.7.3-tests.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs-nfs-2.7.3.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs-2.7.3.jar:/usr/lib/hadoop-yarn/lib/asm-3.2.jar:/usr/lib/hadoop-yarn/lib/jackson-jaxrs-1.9.13.jar:/usr/lib/hadoop-yarn/lib/jersey-json-1.9.jar:/usr/lib/hadoop-yarn/lib/jersey-client-1.9.jar:/usr/lib/hadoop-yarn/lib/guava-11.0.2.jar:/usr/lib/hadoop-yarn/lib/jersey-guice-1.9.jar:/usr/lib/hadoop-yarn/lib/commons-compress-1.4.1.jar:/usr/lib/hadoop-yarn/lib/activation-1.1.jar:/usr/lib/hadoop-yarn/lib/guice-servlet-3.0.jar:/usr/lib/hadoop-yarn/lib/zookeeper-3.4.6-tests.jar:/usr/lib/hadoop-yarn/lib/jackson-core-asl-1.9.13.jar:/usr/lib/hadoop-yarn/lib/jsr305-3.0.0.jar:/usr/lib/hadoop-yarn/lib/jackson-xc-1.9.13.jar:/usr/lib/hadoop-yarn/lib/leveldbjni-all-1.8.jar:/usr/lib/hadoop-yarn/lib/jaxb-api-2.2.2.jar:/usr/lib/hadoop-yarn/lib/netty-3.6.2.Final.jar:/usr/lib/hadoop-yarn/lib/javax.inject-1.jar:/usr/lib/hadoop-yarn/lib/commons-codec-1.4.jar:/usr/lib/hadoop-yarn/lib/jettison-1.1.jar:/usr/lib/hadoop-yarn/lib/guice-3.0.jar:/usr/lib/hadoop-yarn/lib/xz-1.0.jar:/usr/lib/hadoop-yarn/lib/commons-logging-1.1.3.jar:/usr/lib/hadoop-yarn/lib/log4j-1.2.17.jar:/usr/lib/hadoop-yarn/lib/zookeeper-3.4.6.jar:/usr/lib/hadoop-yarn/lib/commons-lang-2.6.jar:/usr/lib/hadoop-yarn/lib/commons-cli-1.2.jar:/usr/lib/hadoop-yarn/lib/commons-io-2.4.jar:/usr/lib/hadoop-yarn/lib/jetty-util-6.1.26.jar:/usr/lib/hadoop-yarn/lib/jackson-mapper-asl-1.9.13.jar:/usr/lib/hadoop-yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/lib/hadoop-yarn/lib/jersey-server-1.9.jar:/usr/lib/hadoop-yarn/lib/aopalliance-1.0.jar:/usr/lib/hadoop-yarn/lib/jetty-6.1.26.jar:/usr/lib/hadoop-yarn/lib/servlet-api-2.5.jar:/usr/lib/hadoop-yarn/lib/protobuf-java-2.5.0.jar:/usr/lib/hadoop-yarn/lib/jersey-core-1.9.jar:/usr/lib/hadoop-yarn/lib/stax-api-1.0-2.jar:/usr/lib/hadoop-yarn/lib/commons-collections-3.2.2.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-resourcemanager.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-resourcemanager-2.7.3.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-applicationhistoryservice-2.7.3.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-registry.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-tests.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-common.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-common-2.7.3.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-applications-distributedshell.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-client.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-common-2.7.3.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-applications-unmanaged-am-launcher.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-web-proxy.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-api.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-tests-2.7.3.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-nodemanager-2.7.3.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-api-2.7.3.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-sharedcachemanager-2.7.3.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-common.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-client-2.7.3.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-nodemanager.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-sharedcachemanager.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-registry-2.7.3.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-applications-unmanaged-am-launcher-2.7.3.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-web-proxy-2.7.3.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-applicationhistoryservice.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-applications-distributedshell-2.7.3.jar:/usr/lib/hadoop-mapreduce/lib/asm-3.2.jar:/usr/lib/hadoop-mapreduce/lib/jersey-guice-1.9.jar:/usr/lib/hadoop-mapreduce/lib/snappy-java-1.0.4.1.jar:/usr/lib/hadoop-mapreduce/lib/commons-compress-1.4.1.jar:/usr/lib/hadoop-mapreduce/lib/guice-servlet-3.0.jar:/usr/lib/hadoop-mapreduce/lib/jackson-core-asl-1.9.13.jar:/usr/lib/hadoop-mapreduce/lib/avro-1.7.4.jar:/usr/lib/hadoop-mapreduce/lib/leveldbjni-all-1.8.jar:/usr/lib/hadoop-mapreduce/lib/netty-3.6.2.Final.jar:/usr/lib/hadoop-mapreduce/lib/javax.inject-1.jar:/usr/lib/hadoop-mapreduce/lib/guice-3.0.jar:/usr/lib/hadoop-mapreduce/lib/xz-1.0.jar:/usr/lib/hadoop-mapreduce/lib/log4j-1.2.17.jar:/usr/lib/hadoop-mapreduce/lib/hamcrest-core-1.3.jar:/usr/lib/hadoop-mapreduce/lib/commons-io-2.4.jar:/usr/lib/hadoop-mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/usr/lib/hadoop-mapreduce/lib/paranamer-2.3.jar:/usr/lib/hadoop-mapreduce/lib/jersey-server-1.9.jar:/usr/lib/hadoop-mapreduce/lib/aopalliance-1.0.jar:/usr/lib/hadoop-mapreduce/lib/junit-4.11.jar:/usr/lib/hadoop-mapreduce/lib/protobuf-java-2.5.0.jar:/usr/lib/hadoop-mapreduce/lib/jersey-core-1.9.jar:/usr/lib/hadoop-mapreduce/.//jackson-core-2.2.3.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-jobclient-2.7.3-tests.jar:/usr/lib/hadoop-mapreduce/.//azure-storage-2.0.0.jar:/usr/lib/hadoop-mapreduce/.//metrics-core-3.0.1.jar:/usr/lib/hadoop-mapreduce/.//asm-3.2.jar:/usr/lib/hadoop-mapreduce/.//jackson-jaxrs-1.9.13.jar:/usr/lib/hadoop-mapreduce/.//hadoop-sls-2.7.3.jar:/usr/lib/hadoop-mapreduce/.//api-asn1-api-1.0.0-M20.jar:/usr/lib/hadoop-mapreduce/.//jersey-json-1.9.jar:/usr/lib/hadoop-mapreduce/.//gson-2.2.4.jar:/usr/lib/hadoop-mapreduce/.//commons-net-3.1.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-app-2.7.3.jar:/usr/lib/hadoop-mapreduce/.//commons-digester-1.8.jar:/usr/lib/hadoop-mapreduce/.//guava-11.0.2.jar:/usr/lib/hadoop-mapreduce/.//api-util-1.0.0-M20.jar:/usr/lib/hadoop-mapreduce/.//jets3t-0.9.0.jar:/usr/lib/hadoop-mapreduce/.//snappy-java-1.0.4.1.jar:/usr/lib/hadoop-mapreduce/.//hadoop-streaming-2.7.3.jar:/usr/lib/hadoop-mapreduce/.//commons-compress-1.4.1.jar:/usr/lib/hadoop-mapreduce/.//activation-1.1.jar:/usr/lib/hadoop-mapreduce/.//curator-framework-2.7.1.jar:/usr/lib/hadoop-mapreduce/.//hadoop-archives.jar:/usr/lib/hadoop-mapreduce/.//hadoop-aws.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-core.jar:/usr/lib/hadoop-mapreduce/.//jackson-core-asl-1.9.13.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-hs.jar:/usr/lib/hadoop-mapreduce/.//commons-beanutils-1.7.0.jar:/usr/lib/hadoop-mapreduce/.//curator-client-2.7.1.jar:/usr/lib/hadoop-mapreduce/.//hadoop-azure-2.7.3.jar:/usr/lib/hadoop-mapreduce/.//jsr305-3.0.0.jar:/usr/lib/hadoop-mapreduce/.//avro-1.7.4.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-jobclient.jar:/usr/lib/hadoop-mapreduce/.//hadoop-gridmix.jar:/usr/lib/hadoop-mapreduce/.//hadoop-distcp.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-app.jar:/usr/lib/hadoop-mapreduce/.//jackson-xc-1.9.13.jar:/usr/lib/hadoop-mapreduce/.//hadoop-auth-2.7.3.jar:/usr/lib/hadoop-mapreduce/.//commons-configuration-1.6.jar:/usr/lib/hadoop-mapreduce/.//commons-math3-3.1.1.jar:/usr/lib/hadoop-mapreduce/.//hadoop-datajoin-2.7.3.jar:/usr/lib/hadoop-mapreduce/.//apacheds-kerberos-codec-2.0.0-M15.jar:/usr/lib/hadoop-mapreduce/.//hadoop-gridmix-2.7.3.jar:/usr/lib/hadoop-mapreduce/.//hadoop-ant.jar:/usr/lib/hadoop-mapreduce/.//hadoop-auth.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-shuffle-2.7.3.jar:/usr/lib/hadoop-mapreduce/.//jaxb-api-2.2.2.jar:/usr/lib/hadoop-mapreduce/.//netty-3.6.2.Final.jar:/usr/lib/hadoop-mapreduce/.//curator-recipes-2.7.1.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-hs-plugins.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-common-2.7.3.jar:/usr/lib/hadoop-mapreduce/.//mockito-all-1.8.5.jar:/usr/lib/hadoop-mapreduce/.//joda-time-2.9.9.jar:/usr/lib/hadoop-mapreduce/.//hadoop-openstack.jar:/usr/lib/hadoop-mapreduce/.//jackson-annotations-2.2.3.jar:/usr/lib/hadoop-mapreduce/.//commons-codec-1.4.jar:/usr/lib/hadoop-mapreduce/.//hadoop-extras-2.7.3.jar:/usr/lib/hadoop-mapreduce/.//jettison-1.1.jar:/usr/lib/hadoop-mapreduce/.//hadoop-distcp-2.7.3.jar:/usr/lib/hadoop-mapreduce/.//commons-httpclient-3.1.jar:/usr/lib/hadoop-mapreduce/.//jsch-0.1.42.jar:/usr/lib/hadoop-mapreduce/.//hadoop-sls.jar:/usr/lib/hadoop-mapreduce/.//jackson-databind-2.2.3.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-hs-2.7.3.jar:/usr/lib/hadoop-mapreduce/.//java-xmlbuilder-0.4.jar:/usr/lib/hadoop-mapreduce/.//aws-java-sdk-1.7.4.jar:/usr/lib/hadoop-mapreduce/.//hadoop-aws-2.7.3.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-examples-2.7.3.jar:/usr/lib/hadoop-mapreduce/.//xz-1.0.jar:/usr/lib/hadoop-mapreduce/.//hadoop-rumen.jar:/usr/lib/hadoop-mapreduce/.//commons-logging-1.1.3.jar:/usr/lib/hadoop-mapreduce/.//log4j-1.2.17.jar:/usr/lib/hadoop-mapreduce/.//zookeeper-3.4.6.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-core-2.7.3.jar:/usr/lib/hadoop-mapreduce/.//hadoop-datajoin.jar:/usr/lib/hadoop-mapreduce/.//commons-lang-2.6.jar:/usr/lib/hadoop-mapreduce/.//commons-lang3-3.3.2.jar:/usr/lib/hadoop-mapreduce/.//hamcrest-core-1.3.jar:/usr/lib/hadoop-mapreduce/.//httpclient-4.2.5.jar:/usr/lib/hadoop-mapreduce/.//commons-cli-1.2.jar:/usr/lib/hadoop-mapreduce/.//commons-io-2.4.jar:/usr/lib/hadoop-mapreduce/.//apacheds-i18n-2.0.0-M15.jar:/usr/lib/hadoop-mapreduce/.//jetty-util-6.1.26.jar:/usr/lib/hadoop-mapreduce/.//jackson-mapper-asl-1.9.13.jar:/usr/lib/hadoop-mapreduce/.//hadoop-archives-2.7.3.jar:/usr/lib/hadoop-mapreduce/.//htrace-core-3.1.0-incubating.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-common.jar:/usr/lib/hadoop-mapreduce/.//paranamer-2.3.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-jobclient-2.7.3.jar:/usr/lib/hadoop-mapreduce/.//hadoop-extras.jar:/usr/lib/hadoop-mapreduce/.//xmlenc-0.52.jar:/usr/lib/hadoop-mapreduce/.//hadoop-openstack-2.7.3.jar:/usr/lib/hadoop-mapreduce/.//jaxb-impl-2.2.3-1.jar:/usr/lib/hadoop-mapreduce/.//commons-beanutils-core-1.8.0.jar:/usr/lib/hadoop-mapreduce/.//jersey-server-1.9.jar:/usr/lib/hadoop-mapreduce/.//jsp-api-2.1.jar:/usr/lib/hadoop-mapreduce/.//jetty-6.1.26.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-hs-plugins-2.7.3.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-examples.jar:/usr/lib/hadoop-mapreduce/.//junit-4.11.jar:/usr/lib/hadoop-mapreduce/.//hadoop-azure.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-shuffle.jar:/usr/lib/hadoop-mapreduce/.//hadoop-streaming.jar:/usr/lib/hadoop-mapreduce/.//hadoop-ant-2.7.3.jar:/usr/lib/hadoop-mapreduce/.//servlet-api-2.5.jar:/usr/lib/hadoop-mapreduce/.//httpcore-4.2.5.jar:/usr/lib/hadoop-mapreduce/.//hadoop-rumen-2.7.3.jar:/usr/lib/hadoop-mapreduce/.//protobuf-java-2.5.0.jar:/usr/lib/hadoop-mapreduce/.//jersey-core-1.9.jar:/usr/lib/hadoop-mapreduce/.//stax-api-1.0-2.jar:/usr/lib/hadoop-mapreduce/.//commons-collections-3.2.2.jar:/usr/lib/hadoop/contrib/capacity-scheduler/*.jar:/usr/lib/hadoop/contrib/capacity-scheduler/*.jar:/usr/lib/hadoop/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/bigtop.git -r 2365207dc0440bb884e41d4ffe32a37ad0d0ed28; compiled by 'jenkins' on 2017-10-05T21:00Z
STARTUP_MSG:   java = 1.8.0_181
************************************************************/
2018-12-08 02:57:52,267 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2018-12-08 02:57:52,271 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: createNameNode []
2018-12-08 02:57:52,540 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2018-12-08 02:57:52,616 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2018-12-08 02:57:52,617 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NameNode metrics system started
2018-12-08 02:57:52,619 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: fs.defaultFS is hdfs://bootcamp.local:9000
2018-12-08 02:57:52,621 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Clients are to use bootcamp.local:9000 to access this namenode/service.
2018-12-08 02:57:52,766 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for hdfs at: http://0.0.0.0:50070
2018-12-08 02:57:52,835 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2018-12-08 02:57:52,842 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2018-12-08 02:57:52,847 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.namenode is not defined
2018-12-08 02:57:52,855 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2018-12-08 02:57:52,857 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2018-12-08 02:57:52,858 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2018-12-08 02:57:52,858 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2018-12-08 02:57:52,987 INFO org.apache.hadoop.http.HttpServer2: Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2018-12-08 02:57:52,990 INFO org.apache.hadoop.http.HttpServer2: addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2018-12-08 02:57:53,007 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50070
2018-12-08 02:57:53,007 INFO org.mortbay.log: jetty-6.1.26
2018-12-08 02:57:53,149 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:50070
2018-12-08 02:57:53,195 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one image storage directory (dfs.namenode.name.dir) configured. Beware of data loss due to lack of redundant storage directories!
2018-12-08 02:57:53,195 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one namespace edits storage directory (dfs.namenode.edits.dir) configured. Beware of data loss due to lack of redundant storage directories!
2018-12-08 02:57:53,244 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: No KeyProvider found.
2018-12-08 02:57:53,245 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair:true
2018-12-08 02:57:53,314 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2018-12-08 02:57:53,315 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2018-12-08 02:57:53,316 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2018-12-08 02:57:53,317 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2018 Dec 08 02:57:53
2018-12-08 02:57:53,319 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2018-12-08 02:57:53,319 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2018-12-08 02:57:53,322 INFO org.apache.hadoop.util.GSet: 2.0% max memory 889 MB = 17.8 MB
2018-12-08 02:57:53,322 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2018-12-08 02:57:53,328 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2018-12-08 02:57:53,329 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 1
2018-12-08 02:57:53,330 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2018-12-08 02:57:53,330 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2018-12-08 02:57:53,330 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2018-12-08 02:57:53,331 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2018-12-08 02:57:53,331 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2018-12-08 02:57:53,331 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2018-12-08 02:57:53,337 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = hdfs (auth:SIMPLE)
2018-12-08 02:57:53,338 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2018-12-08 02:57:53,338 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2018-12-08 02:57:53,339 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2018-12-08 02:57:53,340 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2018-12-08 02:57:53,406 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2018-12-08 02:57:53,407 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2018-12-08 02:57:53,407 INFO org.apache.hadoop.util.GSet: 1.0% max memory 889 MB = 8.9 MB
2018-12-08 02:57:53,408 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2018-12-08 02:57:53,409 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: ACLs enabled? false
2018-12-08 02:57:53,409 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: XAttrs enabled? true
2018-12-08 02:57:53,410 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Maximum size of an xattr: 16384
2018-12-08 02:57:53,410 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times
2018-12-08 02:57:53,417 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2018-12-08 02:57:53,418 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2018-12-08 02:57:53,419 INFO org.apache.hadoop.util.GSet: 0.25% max memory 889 MB = 2.2 MB
2018-12-08 02:57:53,419 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2018-12-08 02:57:53,420 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2018-12-08 02:57:53,421 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2018-12-08 02:57:53,421 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2018-12-08 02:57:53,425 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.window.num.buckets = 10
2018-12-08 02:57:53,425 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.num.users = 10
2018-12-08 02:57:53,426 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2018-12-08 02:57:53,427 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache on namenode is enabled
2018-12-08 02:57:53,428 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2018-12-08 02:57:53,430 INFO org.apache.hadoop.util.GSet: Computing capacity for map NameNodeRetryCache
2018-12-08 02:57:53,430 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2018-12-08 02:57:53,431 INFO org.apache.hadoop.util.GSet: 0.029999999329447746% max memory 889 MB = 273.1 KB
2018-12-08 02:57:53,431 INFO org.apache.hadoop.util.GSet: capacity      = 2^15 = 32768 entries
2018-12-08 02:57:53,444 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /data/name/in_use.lock acquired by nodename 751@bootcamp.local
2018-12-08 02:57:53,486 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Recovering unfinalized segments in /data/name/current
2018-12-08 02:57:53,636 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /data/name/current/edits_inprogress_0000000000000000001 -> /data/name/current/edits_0000000000000000001-0000000000000000014
2018-12-08 02:57:53,648 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Planning to load image: FSImageFile(file=/data/name/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2018-12-08 02:57:53,676 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Loading 1 INodes.
2018-12-08 02:57:53,699 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Loaded FSImage in 0 seconds.
2018-12-08 02:57:53,700 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 0 from /data/name/current/fsimage_0000000000000000000
2018-12-08 02:57:53,701 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@2cae1042 expecting start txid #1
2018-12-08 02:57:53,701 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /data/name/current/edits_0000000000000000001-0000000000000000014
2018-12-08 02:57:53,703 INFO org.apache.hadoop.hdfs.server.namenode.EditLogInputStream: Fast-forwarding stream '/data/name/current/edits_0000000000000000001-0000000000000000014' to transaction ID 1
2018-12-08 02:57:53,721 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /data/name/current/edits_0000000000000000001-0000000000000000014 of size 1048576 edits # 14 loaded in 0 seconds
2018-12-08 02:57:53,722 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Need to save fs image? true (staleImage=true, haEnabled=false, isRollingUpgrade=false)
2018-12-08 02:57:53,722 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Save namespace ...
2018-12-08 02:57:53,727 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /data/name/current/fsimage.ckpt_0000000000000000014 using no compression
2018-12-08 02:57:53,755 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /data/name/current/fsimage.ckpt_0000000000000000014 of size 804 bytes saved in 0 seconds.
2018-12-08 02:57:53,764 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 0
2018-12-08 02:57:53,770 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 15
2018-12-08 02:57:53,864 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2018-12-08 02:57:53,865 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Finished loading FSImage in 430 msecs
2018-12-08 02:57:54,100 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: RPC server is binding to bootcamp.local:9000
2018-12-08 02:57:54,105 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2018-12-08 02:57:54,115 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 9000
2018-12-08 02:57:54,136 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Registered FSNamesystemState MBean
2018-12-08 02:57:54,148 INFO org.apache.hadoop.hdfs.server.namenode.LeaseManager: Number of blocks under construction: 0
2018-12-08 02:57:54,148 INFO org.apache.hadoop.hdfs.server.namenode.LeaseManager: Number of blocks under construction: 0
2018-12-08 02:57:54,149 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: initializing replication queues
2018-12-08 02:57:54,149 INFO org.apache.hadoop.hdfs.StateChange: STATE* Leaving safe mode after 0 secs
2018-12-08 02:57:54,150 INFO org.apache.hadoop.hdfs.StateChange: STATE* Network topology has 0 racks and 0 datanodes
2018-12-08 02:57:54,150 INFO org.apache.hadoop.hdfs.StateChange: STATE* UnderReplicatedBlocks has 0 blocks
2018-12-08 02:57:54,155 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Number of failed storage changes from 0 to 0
2018-12-08 02:57:54,157 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Total number of blocks            = 0
2018-12-08 02:57:54,157 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of invalid blocks          = 0
2018-12-08 02:57:54,157 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of under-replicated blocks = 0
2018-12-08 02:57:54,158 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of  over-replicated blocks = 0
2018-12-08 02:57:54,158 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of blocks being written    = 0
2018-12-08 02:57:54,158 INFO org.apache.hadoop.hdfs.StateChange: STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 9 msec
2018-12-08 02:57:54,182 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2018-12-08 02:57:54,183 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 9000: starting
2018-12-08 02:57:54,187 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: NameNode RPC up at: bootcamp.local/172.18.0.2:9000
2018-12-08 02:57:54,187 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Starting services required for active state
2018-12-08 02:57:54,192 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Starting CacheReplicationMonitor with interval 30000 milliseconds
2018-12-08 02:58:03,256 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(172.18.0.2:50010, datanodeUuid=47ecd31e-43cd-4989-84ba-314b1664d0de, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-747ab8c6-1ec4-46a0-9dee-c8151846aca5;nsid=199960936;c=0) storage 47ecd31e-43cd-4989-84ba-314b1664d0de
2018-12-08 02:58:03,256 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Number of failed storage changes from 0 to 0
2018-12-08 02:58:03,257 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/172.18.0.2:50010
2018-12-08 02:58:03,350 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Number of failed storage changes from 0 to 0
2018-12-08 02:58:03,351 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Adding new storage ID DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5 for DN 172.18.0.2:50010
2018-12-08 02:58:03,427 INFO BlockStateChange: BLOCK* processReport: from storage DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5 node DatanodeRegistration(172.18.0.2:50010, datanodeUuid=47ecd31e-43cd-4989-84ba-314b1664d0de, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-747ab8c6-1ec4-46a0-9dee-c8151846aca5;nsid=199960936;c=0), blocks: 0, hasStaleStorage: false, processing time: 1 msecs
2018-12-08 02:58:28,576 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741825_1001{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /app/hbase/.tmp/hbase.version
2018-12-08 02:58:28,813 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* blk_1073741825_1001{UCState=COMMITTED, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} is not COMPLETE (ucState = COMMITTED, replication# = 0 <  minimum = 1) in file /app/hbase/.tmp/hbase.version
2018-12-08 02:58:28,820 INFO org.apache.hadoop.hdfs.server.namenode.EditLogFileOutputStream: Nothing to flush
2018-12-08 02:58:28,837 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741825_1001{UCState=COMMITTED, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 7
2018-12-08 02:58:29,229 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /app/hbase/.tmp/hbase.version is closed by DFSClient_NONMAPREDUCE_-596810310_1
2018-12-08 02:58:29,257 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741826_1002{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /app/hbase/.tmp/hbase.id
2018-12-08 02:58:29,271 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741826_1002{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 0
2018-12-08 02:58:29,275 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /app/hbase/.tmp/hbase.id is closed by DFSClient_NONMAPREDUCE_-596810310_1
2018-12-08 02:58:29,396 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741827_1003{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /app/hbase/data/hbase/meta/1588230740/.regioninfo
2018-12-08 02:58:29,405 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741827_1003{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 0
2018-12-08 02:58:29,411 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /app/hbase/data/hbase/meta/1588230740/.regioninfo is closed by DFSClient_NONMAPREDUCE_-596810310_1
2018-12-08 02:58:29,552 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /app/hbase/data/hbase/meta/1588230740/recovered.edits/2.seqid is closed by DFSClient_NONMAPREDUCE_-596810310_1
2018-12-08 02:58:29,580 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741828_1004{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /app/hbase/data/hbase/meta/.tmp/.tableinfo.0000000001
2018-12-08 02:58:29,598 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741828_1004{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 0
2018-12-08 02:58:29,601 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /app/hbase/data/hbase/meta/.tmp/.tableinfo.0000000001 is closed by DFSClient_NONMAPREDUCE_-596810310_1
2018-12-08 02:58:30,333 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741829_1005{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /app/hbase/WALs/bootcamp.local,16020,1544237905210/bootcamp.local%2C16020%2C1544237905210.default.1544237910276
2018-12-08 02:58:30,449 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* fsync: /app/hbase/WALs/bootcamp.local,16020,1544237905210/bootcamp.local%2C16020%2C1544237905210.default.1544237910276 for DFSClient_NONMAPREDUCE_-264580976_1
2018-12-08 02:58:35,383 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741830_1006{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /app/hbase/WALs/bootcamp.local,16020,1544237905210/bootcamp.local%2C16020%2C1544237905210..meta.1544237915370.meta
2018-12-08 02:58:35,404 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* fsync: /app/hbase/WALs/bootcamp.local,16020,1544237905210/bootcamp.local%2C16020%2C1544237905210..meta.1544237915370.meta for DFSClient_NONMAPREDUCE_-264580976_1
2018-12-08 02:58:35,642 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /app/hbase/data/hbase/meta/1588230740/recovered.edits/3.seqid is closed by DFSClient_NONMAPREDUCE_-264580976_1
2018-12-08 02:58:36,077 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741831_1007{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /app/hbase/MasterProcWALs/state-00000000000000000001.log
2018-12-08 02:58:36,096 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* fsync: /app/hbase/MasterProcWALs/state-00000000000000000001.log for DFSClient_NONMAPREDUCE_-596810310_1
2018-12-08 02:58:36,253 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741832_1008{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /app/hbase/.tmp/data/hbase/namespace/.tmp/.tableinfo.0000000001
2018-12-08 02:58:36,272 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741832_1008{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 0
2018-12-08 02:58:36,274 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /app/hbase/.tmp/data/hbase/namespace/.tmp/.tableinfo.0000000001 is closed by DFSClient_NONMAPREDUCE_-596810310_1
2018-12-08 02:58:36,297 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741833_1009{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /app/hbase/.tmp/data/hbase/namespace/6176ac21ad3eda4d118c53c85b956cf6/.regioninfo
2018-12-08 02:58:36,313 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741833_1009{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 0
2018-12-08 02:58:36,317 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /app/hbase/.tmp/data/hbase/namespace/6176ac21ad3eda4d118c53c85b956cf6/.regioninfo is closed by DFSClient_NONMAPREDUCE_-596810310_1
2018-12-08 02:58:36,745 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /app/hbase/data/hbase/namespace/6176ac21ad3eda4d118c53c85b956cf6/recovered.edits/2.seqid is closed by DFSClient_NONMAPREDUCE_-264580976_1
2018-12-08 03:03:47,837 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 90 Total time for transactions(ms): 9 Number of transactions batched in Syncs: 8 Number of syncs: 57 SyncTimes(ms): 61 
2018-12-08 03:03:47,880 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741834_1010{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /app/hbase/data/hbase/meta/1588230740/.tmp/32e17529c19248218b97d1c93158f452
2018-12-08 03:03:47,897 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741834_1010{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 0
2018-12-08 03:03:47,899 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /app/hbase/data/hbase/meta/1588230740/.tmp/32e17529c19248218b97d1c93158f452 is closed by DFSClient_NONMAPREDUCE_-264580976_1
2018-12-08 03:13:59,368 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 97 Total time for transactions(ms): 10 Number of transactions batched in Syncs: 8 Number of syncs: 62 SyncTimes(ms): 69 
2018-12-08 03:13:59,378 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741831_1007{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 469
2018-12-08 03:13:59,381 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /app/hbase/MasterProcWALs/state-00000000000000000001.log is closed by DFSClient_NONMAPREDUCE_-596810310_1
2018-12-08 03:13:59,386 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741831_1007 172.18.0.2:50010 
2018-12-08 03:14:00,188 INFO BlockStateChange: BLOCK* BlockManager: ask 172.18.0.2:50010 to delete [blk_1073741831_1007]
2018-12-08 03:52:46,923 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 100 Total time for transactions(ms): 12 Number of transactions batched in Syncs: 8 Number of syncs: 65 SyncTimes(ms): 73 
2018-12-08 03:57:19,332 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 104 Total time for transactions(ms): 13 Number of transactions batched in Syncs: 8 Number of syncs: 69 SyncTimes(ms): 77 
2018-12-08 03:58:20,725 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 112 Total time for transactions(ms): 13 Number of transactions batched in Syncs: 8 Number of syncs: 76 SyncTimes(ms): 102 
2018-12-08 03:58:28,640 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741835_1011{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /app/hbase/WALs/bootcamp.local,16020,1544237905210/bootcamp.local%2C16020%2C1544237905210.default.1544241508611
2018-12-08 03:58:28,680 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* fsync: /app/hbase/WALs/bootcamp.local,16020,1544237905210/bootcamp.local%2C16020%2C1544237905210.default.1544241508611 for DFSClient_NONMAPREDUCE_-264580976_1
2018-12-08 03:58:28,716 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741829_1005{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 83
2018-12-08 03:58:28,720 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /app/hbase/WALs/bootcamp.local,16020,1544237905210/bootcamp.local%2C16020%2C1544237905210.default.1544237910276 is closed by DFSClient_NONMAPREDUCE_-264580976_1
2018-12-08 03:58:43,543 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741836_1012{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /app/hbase/WALs/bootcamp.local,16020,1544237905210/bootcamp.local%2C16020%2C1544237905210..meta.1544241523528.meta
2018-12-08 03:58:43,552 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* fsync: /app/hbase/WALs/bootcamp.local,16020,1544237905210/bootcamp.local%2C16020%2C1544237905210..meta.1544241523528.meta for DFSClient_NONMAPREDUCE_-264580976_1
2018-12-08 03:58:43,563 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741830_1006{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 83
2018-12-08 03:58:43,566 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /app/hbase/WALs/bootcamp.local,16020,1544237905210/bootcamp.local%2C16020%2C1544237905210..meta.1544237915370.meta is closed by DFSClient_NONMAPREDUCE_-264580976_1
2018-12-08 03:58:52,963 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741837_1013{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /app/hbase/data/hbase/namespace/6176ac21ad3eda4d118c53c85b956cf6/.tmp/f979e5f4fc444a9784e5de083d80ef02
2018-12-08 03:58:52,977 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741837_1013{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 0
2018-12-08 03:58:52,980 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /app/hbase/data/hbase/namespace/6176ac21ad3eda4d118c53c85b956cf6/.tmp/f979e5f4fc444a9784e5de083d80ef02 is closed by DFSClient_NONMAPREDUCE_-264580976_1
2018-12-08 03:59:21,557 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 195 Total time for transactions(ms): 20 Number of transactions batched in Syncs: 8 Number of syncs: 151 SyncTimes(ms): 209 
2018-12-08 03:59:23,517 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741838_1014{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /mimic/admissions/ADMISSIONS.csv._COPYING_
2018-12-08 03:59:23,630 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741838_1014{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 0
2018-12-08 03:59:23,635 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /mimic/admissions/ADMISSIONS.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_1006157666_1
2018-12-08 03:59:25,651 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741839_1015{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /mimic/callout/CALLOUT.csv._COPYING_
2018-12-08 03:59:25,748 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741839_1015{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 0
2018-12-08 03:59:25,754 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /mimic/callout/CALLOUT.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_1912720602_1
2018-12-08 03:59:27,585 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741840_1016{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /mimic/caregivers/CAREGIVERS.csv._COPYING_
2018-12-08 03:59:27,671 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741840_1016{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 0
2018-12-08 03:59:27,676 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /mimic/caregivers/CAREGIVERS.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1279041807_1
2018-12-08 03:59:29,584 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741841_1017{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /mimic/chartevents/CHARTEVENTS.csv._COPYING_
2018-12-08 03:59:29,722 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741841_1017{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 0
2018-12-08 03:59:29,732 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /mimic/chartevents/CHARTEVENTS.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_1174838802_1
2018-12-08 03:59:31,631 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741842_1018{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /mimic/cptevents/CPTEVENTS.csv._COPYING_
2018-12-08 03:59:31,742 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741842_1018{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 0
2018-12-08 03:59:31,745 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /mimic/cptevents/CPTEVENTS.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_1926770312_1
2018-12-08 03:59:33,564 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741843_1019{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /mimic/datetimeevents/DATETIMEEVENTS.csv._COPYING_
2018-12-08 03:59:33,666 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741843_1019{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 0
2018-12-08 03:59:33,672 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /mimic/datetimeevents/DATETIMEEVENTS.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1386288429_1
2018-12-08 03:59:35,628 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741844_1020{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /mimic/diagnoses_icd/DIAGNOSES_ICD.csv._COPYING_
2018-12-08 03:59:35,727 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741844_1020{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 0
2018-12-08 03:59:35,733 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /mimic/diagnoses_icd/DIAGNOSES_ICD.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1967969403_1
2018-12-08 03:59:37,725 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741845_1021{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /mimic/drgcodes/DRGCODES.csv._COPYING_
2018-12-08 03:59:37,837 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741845_1021{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 0
2018-12-08 03:59:37,842 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /mimic/drgcodes/DRGCODES.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_558305590_1
2018-12-08 03:59:39,831 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741846_1022{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /mimic/d_cpt/D_CPT.csv._COPYING_
2018-12-08 03:59:39,927 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741846_1022{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 0
2018-12-08 03:59:39,938 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /mimic/d_cpt/D_CPT.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_566030637_1
2018-12-08 03:59:41,917 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741847_1023{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /mimic/d_icd_diagnoses/D_ICD_DIAGNOSES.csv._COPYING_
2018-12-08 03:59:42,025 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741847_1023{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 0
2018-12-08 03:59:42,031 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /mimic/d_icd_diagnoses/D_ICD_DIAGNOSES.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_2091209816_1
2018-12-08 03:59:43,845 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741848_1024{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /mimic/d_icd_procedures/D_ICD_PROCEDURES.csv._COPYING_
2018-12-08 03:59:43,949 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741848_1024{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 0
2018-12-08 03:59:43,956 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /mimic/d_icd_procedures/D_ICD_PROCEDURES.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_1403604343_1
2018-12-08 03:59:45,931 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741849_1025{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /mimic/d_items/D_ITEMS.csv._COPYING_
2018-12-08 03:59:46,024 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741849_1025{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 0
2018-12-08 03:59:46,029 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /mimic/d_items/D_ITEMS.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_-799131507_1
2018-12-08 03:59:47,940 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741850_1026{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /mimic/d_labitems/D_LABITEMS.csv._COPYING_
2018-12-08 03:59:48,036 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741850_1026{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 0
2018-12-08 03:59:48,041 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /mimic/d_labitems/D_LABITEMS.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_1184773680_1
2018-12-08 03:59:49,955 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741851_1027{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /mimic/icustays/ICUSTAYS.csv._COPYING_
2018-12-08 03:59:50,041 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741851_1027{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 0
2018-12-08 03:59:50,047 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /mimic/icustays/ICUSTAYS.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_565258631_1
2018-12-08 03:59:52,014 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741852_1028{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /mimic/inputevents_cv/INPUTEVENTS_CV.csv._COPYING_
2018-12-08 03:59:52,107 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741852_1028{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 0
2018-12-08 03:59:52,112 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /mimic/inputevents_cv/INPUTEVENTS_CV.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_-114131301_1
2018-12-08 03:59:54,031 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741853_1029{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /mimic/inputevents_mv/INPUTEVENTS_MV.csv._COPYING_
2018-12-08 03:59:54,131 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741853_1029{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 0
2018-12-08 03:59:54,137 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /mimic/inputevents_mv/INPUTEVENTS_MV.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_1577708737_1
2018-12-08 03:59:56,022 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741854_1030{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /mimic/labevents/LABEVENTS.csv._COPYING_
2018-12-08 03:59:56,150 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741854_1030{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 0
2018-12-08 03:59:56,155 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /mimic/labevents/LABEVENTS.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_1594397480_1
2018-12-08 03:59:58,067 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741855_1031{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /mimic/microbiologyevents/MICROBIOLOGYEVENTS.csv._COPYING_
2018-12-08 03:59:58,152 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741855_1031{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 0
2018-12-08 03:59:58,158 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /mimic/microbiologyevents/MICROBIOLOGYEVENTS.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_-905187923_1
2018-12-08 04:00:00,019 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741856_1032{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /mimic/noteevents/NOTEEVENTS.csv._COPYING_
2018-12-08 04:00:00,187 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741856_1032{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 0
2018-12-08 04:00:00,190 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /mimic/noteevents/NOTEEVENTS.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_147139473_1
2018-12-08 04:00:02,092 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741857_1033{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /mimic/outputevents/OUTPUTEVENTS.csv._COPYING_
2018-12-08 04:00:02,177 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741857_1033{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 0
2018-12-08 04:00:02,182 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /mimic/outputevents/OUTPUTEVENTS.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1202415022_1
2018-12-08 04:00:04,067 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741858_1034{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /mimic/patients/PATIENTS.csv._COPYING_
2018-12-08 04:00:04,170 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741858_1034{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 0
2018-12-08 04:00:04,175 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /mimic/patients/PATIENTS.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_-725685554_1
2018-12-08 04:00:06,013 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741859_1035{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /mimic/prescriptions/PRESCRIPTIONS.csv._COPYING_
2018-12-08 04:00:06,098 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741859_1035{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 0
2018-12-08 04:00:06,103 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /mimic/prescriptions/PRESCRIPTIONS.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1386326094_1
2018-12-08 04:00:08,058 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741860_1036{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /mimic/procedureevents_mv/PROCEDUREEVENTS_MV.csv._COPYING_
2018-12-08 04:00:08,153 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741860_1036{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 0
2018-12-08 04:00:08,158 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /mimic/procedureevents_mv/PROCEDUREEVENTS_MV.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1642440243_1
2018-12-08 04:00:09,966 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741861_1037{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /mimic/procedures_icd/PROCEDURES_ICD.csv._COPYING_
2018-12-08 04:00:10,055 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741861_1037{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 0
2018-12-08 04:00:10,061 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /mimic/procedures_icd/PROCEDURES_ICD.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1190478552_1
2018-12-08 04:00:12,004 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741862_1038{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /mimic/services/SERVICES.csv._COPYING_
2018-12-08 04:00:12,087 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741862_1038{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 0
2018-12-08 04:00:12,093 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /mimic/services/SERVICES.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1932672332_1
2018-12-08 04:00:14,003 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741863_1039{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /mimic/transfers/TRANSFERS.csv._COPYING_
2018-12-08 04:00:14,091 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741863_1039{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 0
2018-12-08 04:00:14,096 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /mimic/transfers/TRANSFERS.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1967699691_1
2018-12-08 04:00:16,010 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741864_1040{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /ccs/ccs_dx_map/ccs_dx_map.csv._COPYING_
2018-12-08 04:00:16,097 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741864_1040{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 0
2018-12-08 04:00:16,102 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /ccs/ccs_dx_map/ccs_dx_map.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_-696658368_1
2018-12-08 04:00:17,951 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741865_1041{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /ccs/ccs_proc_map/ccs_proc_map.csv._COPYING_
2018-12-08 04:00:18,050 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741865_1041{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 0
2018-12-08 04:00:18,056 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /ccs/ccs_proc_map/ccs_proc_map.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1998366203_1
2018-12-08 04:00:20,018 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741866_1042{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /model/noteevents_with_topics/noteevents_with_topics.csv._COPYING_
2018-12-08 04:00:20,120 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741866_1042{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 0
2018-12-08 04:00:20,126 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /model/noteevents_with_topics/noteevents_with_topics.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_-2069626440_1
2018-12-08 04:00:22,663 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 373 Total time for transactions(ms): 25 Number of transactions batched in Syncs: 8 Number of syncs: 271 SyncTimes(ms): 476 
2018-12-08 04:00:22,707 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741867_1043{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /model/admissions_ccs_ohe/admissions_ccs_ohe.csv._COPYING_
2018-12-08 04:00:22,857 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741867_1043{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 0
2018-12-08 04:00:22,861 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /model/admissions_ccs_ohe/admissions_ccs_ohe.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_1779515447_1
2018-12-08 04:00:26,101 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741868_1044{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /model/admissions_topic_scores/admissions_topic_scores.csv._COPYING_
2018-12-08 04:00:26,227 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741868_1044{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 0
2018-12-08 04:00:26,238 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /model/admissions_topic_scores/admissions_topic_scores.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_-50847746_1
2018-12-08 04:02:38,878 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 391 Total time for transactions(ms): 25 Number of transactions batched in Syncs: 8 Number of syncs: 285 SyncTimes(ms): 498 
2018-12-08 04:03:47,182 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 398 Total time for transactions(ms): 25 Number of transactions batched in Syncs: 8 Number of syncs: 292 SyncTimes(ms): 512 
2018-12-08 04:05:06,841 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 410 Total time for transactions(ms): 25 Number of transactions batched in Syncs: 8 Number of syncs: 304 SyncTimes(ms): 665 
2018-12-08 04:09:26,724 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 413 Total time for transactions(ms): 25 Number of transactions batched in Syncs: 8 Number of syncs: 307 SyncTimes(ms): 668 
2018-12-08 04:09:26,728 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741830_1006 172.18.0.2:50010 
2018-12-08 04:09:26,863 INFO BlockStateChange: BLOCK* BlockManager: ask 172.18.0.2:50010 to delete [blk_1073741830_1006]
2018-12-08 04:13:56,781 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 414 Total time for transactions(ms): 32 Number of transactions batched in Syncs: 8 Number of syncs: 308 SyncTimes(ms): 669 
2018-12-08 04:13:56,860 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741869_1045{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /app/hbase/MasterProcWALs/state-00000000000000000002.log
2018-12-08 04:13:56,952 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741869_1045{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 0
2018-12-08 04:13:56,961 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /app/hbase/MasterProcWALs/state-00000000000000000002.log is closed by DFSClient_NONMAPREDUCE_-596810310_1
2018-12-08 04:13:57,009 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741869_1045 172.18.0.2:50010 
2018-12-08 04:13:59,755 INFO BlockStateChange: BLOCK* BlockManager: ask 172.18.0.2:50010 to delete [blk_1073741869_1045]
2018-12-08 04:21:52,785 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 420 Total time for transactions(ms): 32 Number of transactions batched in Syncs: 8 Number of syncs: 312 SyncTimes(ms): 680 
2018-12-08 04:21:53,638 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741836_1012{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 83
2018-12-08 04:21:53,658 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /app/hbase/WALs/bootcamp.local,16020,1544237905210/bootcamp.local%2C16020%2C1544237905210..meta.1544241523528.meta is closed by DFSClient_NONMAPREDUCE_-264580976_1
2018-12-08 04:21:53,679 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741835_1011{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 83
2018-12-08 04:21:53,688 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /app/hbase/WALs/bootcamp.local,16020,1544237905210/bootcamp.local%2C16020%2C1544237905210.default.1544241508611 is closed by DFSClient_NONMAPREDUCE_-264580976_1
2018-12-08 04:22:31,114 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1442ms
No GCs detected
2018-12-08 06:22:44,672 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741870_1046{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /app/hbase/MasterProcWALs/state-00000000000000000003.log
2018-12-08 06:22:44,673 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 425 Total time for transactions(ms): 33 Number of transactions batched in Syncs: 8 Number of syncs: 315 SyncTimes(ms): 688 
2018-12-08 06:22:44,701 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741870_1046{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 0
2018-12-08 06:22:44,711 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /app/hbase/MasterProcWALs/state-00000000000000000003.log is closed by DFSClient_NONMAPREDUCE_-596810310_1
2018-12-08 06:22:47,405 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1368ms
No GCs detected
2018-12-08 07:00:42,692 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1692ms
No GCs detected
2018-12-08 07:55:06,102 INFO BlockStateChange: BLOCK* processReport: from storage DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5 node DatanodeRegistration(172.18.0.2:50010, datanodeUuid=47ecd31e-43cd-4989-84ba-314b1664d0de, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-747ab8c6-1ec4-46a0-9dee-c8151846aca5;nsid=199960936;c=0), blocks: 43, hasStaleStorage: false, processing time: 97 msecs
2018-12-08 19:48:54,560 WARN org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 109991ms
No GCs detected
2018-12-08 19:49:51,052 WARN org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 10786ms
No GCs detected
2018-12-09 00:46:44,776 INFO BlockStateChange: BLOCK* processReport: from storage DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5 node DatanodeRegistration(172.18.0.2:50010, datanodeUuid=47ecd31e-43cd-4989-84ba-314b1664d0de, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-747ab8c6-1ec4-46a0-9dee-c8151846aca5;nsid=199960936;c=0), blocks: 43, hasStaleStorage: false, processing time: 6 msecs
2018-12-09 03:28:55,374 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1070ms
No GCs detected
2018-12-09 04:11:33,324 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1264ms
No GCs detected
2018-12-09 07:24:16,924 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 427 Total time for transactions(ms): 35 Number of transactions batched in Syncs: 8 Number of syncs: 317 SyncTimes(ms): 696 
2018-12-09 07:25:39,016 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 432 Total time for transactions(ms): 35 Number of transactions batched in Syncs: 8 Number of syncs: 321 SyncTimes(ms): 709 
2018-12-09 07:28:10,975 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 433 Total time for transactions(ms): 35 Number of transactions batched in Syncs: 8 Number of syncs: 322 SyncTimes(ms): 710 
2018-12-09 07:29:23,699 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 438 Total time for transactions(ms): 36 Number of transactions batched in Syncs: 8 Number of syncs: 327 SyncTimes(ms): 716 
2018-12-09 07:32:09,201 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 445 Total time for transactions(ms): 37 Number of transactions batched in Syncs: 8 Number of syncs: 334 SyncTimes(ms): 722 
2018-12-09 07:33:20,424 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 449 Total time for transactions(ms): 37 Number of transactions batched in Syncs: 8 Number of syncs: 338 SyncTimes(ms): 728 
2018-12-09 07:42:17,246 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 451 Total time for transactions(ms): 40 Number of transactions batched in Syncs: 8 Number of syncs: 340 SyncTimes(ms): 730 
2018-12-09 07:42:17,306 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741871_1047{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /mimic/admissions/ADMISSIONS.csv._COPYING_
2018-12-09 07:42:17,481 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* blk_1073741871_1047{UCState=COMMITTED, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} is not COMPLETE (ucState = COMMITTED, replication# = 0 <  minimum = 1) in file /mimic/admissions/ADMISSIONS.csv._COPYING_
2018-12-09 07:42:17,486 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741871_1047{UCState=COMMITTED, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 20373
2018-12-09 07:42:17,891 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /mimic/admissions/ADMISSIONS.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204872307_1
2018-12-09 07:42:17,904 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741838_1014 172.18.0.2:50010 
2018-12-09 07:42:18,170 INFO BlockStateChange: BLOCK* BlockManager: ask 172.18.0.2:50010 to delete [blk_1073741838_1014]
2018-12-09 07:42:20,661 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741872_1048{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /mimic/callout/CALLOUT.csv._COPYING_
2018-12-09 07:42:20,823 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741872_1048{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 0
2018-12-09 07:42:20,827 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /mimic/callout/CALLOUT.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1489844189_1
2018-12-09 07:42:20,834 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741839_1015 172.18.0.2:50010 
2018-12-09 07:42:21,173 INFO BlockStateChange: BLOCK* BlockManager: ask 172.18.0.2:50010 to delete [blk_1073741839_1015]
2018-12-09 07:42:23,565 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741873_1049{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /mimic/caregivers/CAREGIVERS.csv._COPYING_
2018-12-09 07:42:23,714 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741873_1049{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 0
2018-12-09 07:42:23,719 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /mimic/caregivers/CAREGIVERS.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1666420329_1
2018-12-09 07:42:23,727 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741840_1016 172.18.0.2:50010 
2018-12-09 07:42:24,175 INFO BlockStateChange: BLOCK* BlockManager: ask 172.18.0.2:50010 to delete [blk_1073741840_1016]
2018-12-09 07:42:26,362 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741874_1050{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /mimic/chartevents/CHARTEVENTS.csv._COPYING_
2018-12-09 07:42:26,491 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* blk_1073741874_1050{UCState=COMMITTED, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} is not COMPLETE (ucState = COMMITTED, replication# = 0 <  minimum = 1) in file /mimic/chartevents/CHARTEVENTS.csv._COPYING_
2018-12-09 07:42:26,492 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741874_1050{UCState=COMMITTED, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 9550
2018-12-09 07:42:26,900 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /mimic/chartevents/CHARTEVENTS.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_900774212_1
2018-12-09 07:42:26,906 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741841_1017 172.18.0.2:50010 
2018-12-09 07:42:27,177 INFO BlockStateChange: BLOCK* BlockManager: ask 172.18.0.2:50010 to delete [blk_1073741841_1017]
2018-12-09 07:42:29,772 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741875_1051{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /mimic/cptevents/CPTEVENTS.csv._COPYING_
2018-12-09 07:42:29,908 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741875_1051{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 0
2018-12-09 07:42:29,914 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /mimic/cptevents/CPTEVENTS.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_-955789360_1
2018-12-09 07:42:29,921 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741842_1018 172.18.0.2:50010 
2018-12-09 07:42:30,178 INFO BlockStateChange: BLOCK* BlockManager: ask 172.18.0.2:50010 to delete [blk_1073741842_1018]
2018-12-09 07:42:32,818 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741876_1052{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /mimic/datetimeevents/DATETIMEEVENTS.csv._COPYING_
2018-12-09 07:42:32,950 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741876_1052{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 0
2018-12-09 07:42:32,965 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /mimic/datetimeevents/DATETIMEEVENTS.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_1973051351_1
2018-12-09 07:42:32,972 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741843_1019 172.18.0.2:50010 
2018-12-09 07:42:33,144 INFO BlockStateChange: BLOCK* BlockManager: ask 172.18.0.2:50010 to delete [blk_1073741843_1019]
2018-12-09 07:42:37,690 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741877_1053{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /mimic/drgcodes/DRGCODES.csv._COPYING_
2018-12-09 07:42:37,832 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741877_1053{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 0
2018-12-09 07:42:37,842 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /mimic/drgcodes/DRGCODES.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_1514974797_1
2018-12-09 07:42:37,849 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741845_1021 172.18.0.2:50010 
2018-12-09 07:42:39,146 INFO BlockStateChange: BLOCK* BlockManager: ask 172.18.0.2:50010 to delete [blk_1073741845_1021]
2018-12-09 07:42:40,740 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741878_1054{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /mimic/d_cpt/D_CPT.csv._COPYING_
2018-12-09 07:42:40,879 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741878_1054{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 0
2018-12-09 07:42:40,884 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /mimic/d_cpt/D_CPT.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_1075909173_1
2018-12-09 07:42:40,894 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741846_1022 172.18.0.2:50010 
2018-12-09 07:42:42,147 INFO BlockStateChange: BLOCK* BlockManager: ask 172.18.0.2:50010 to delete [blk_1073741846_1022]
2018-12-09 07:42:43,779 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741879_1055{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /mimic/d_icd_diagnoses/D_ICD_DIAGNOSES.csv._COPYING_
2018-12-09 07:42:43,918 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741879_1055{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 0
2018-12-09 07:42:43,924 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /mimic/d_icd_diagnoses/D_ICD_DIAGNOSES.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_1654239592_1
2018-12-09 07:42:43,935 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741847_1023 172.18.0.2:50010 
2018-12-09 07:42:45,158 INFO BlockStateChange: BLOCK* BlockManager: ask 172.18.0.2:50010 to delete [blk_1073741847_1023]
2018-12-09 07:42:47,533 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741880_1056{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /mimic/d_icd_procedures/D_ICD_PROCEDURES.csv._COPYING_
2018-12-09 07:42:47,727 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741880_1056{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 0
2018-12-09 07:42:47,731 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /mimic/d_icd_procedures/D_ICD_PROCEDURES.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_-58820636_1
2018-12-09 07:42:47,741 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741848_1024 172.18.0.2:50010 
2018-12-09 07:42:48,165 INFO BlockStateChange: BLOCK* BlockManager: ask 172.18.0.2:50010 to delete [blk_1073741848_1024]
2018-12-09 07:42:50,651 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741881_1057{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /mimic/d_items/D_ITEMS.csv._COPYING_
2018-12-09 07:42:50,798 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741881_1057{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 0
2018-12-09 07:42:50,803 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /mimic/d_items/D_ITEMS.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1513531519_1
2018-12-09 07:42:50,810 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741849_1025 172.18.0.2:50010 
2018-12-09 07:42:51,167 INFO BlockStateChange: BLOCK* BlockManager: ask 172.18.0.2:50010 to delete [blk_1073741849_1025]
2018-12-09 07:42:53,554 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741882_1058{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /mimic/d_labitems/D_LABITEMS.csv._COPYING_
2018-12-09 07:42:53,703 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741882_1058{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 0
2018-12-09 07:42:53,706 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /mimic/d_labitems/D_LABITEMS.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_1637169219_1
2018-12-09 07:42:53,714 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741850_1026 172.18.0.2:50010 
2018-12-09 07:42:54,170 INFO BlockStateChange: BLOCK* BlockManager: ask 172.18.0.2:50010 to delete [blk_1073741850_1026]
2018-12-09 07:42:56,397 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741883_1059{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /mimic/icustays/ICUSTAYS.csv._COPYING_
2018-12-09 07:42:56,519 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741883_1059{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 0
2018-12-09 07:42:56,525 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /mimic/icustays/ICUSTAYS.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1713750388_1
2018-12-09 07:42:56,533 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741851_1027 172.18.0.2:50010 
2018-12-09 07:42:57,173 INFO BlockStateChange: BLOCK* BlockManager: ask 172.18.0.2:50010 to delete [blk_1073741851_1027]
2018-12-09 07:42:59,363 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741884_1060{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /mimic/inputevents_cv/INPUTEVENTS_CV.csv._COPYING_
2018-12-09 07:42:59,509 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741884_1060{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 0
2018-12-09 07:42:59,515 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /mimic/inputevents_cv/INPUTEVENTS_CV.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1604067512_1
2018-12-09 07:42:59,523 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741852_1028 172.18.0.2:50010 
2018-12-09 07:43:00,175 INFO BlockStateChange: BLOCK* BlockManager: ask 172.18.0.2:50010 to delete [blk_1073741852_1028]
2018-12-09 07:43:02,236 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741885_1061{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /mimic/inputevents_mv/INPUTEVENTS_MV.csv._COPYING_
2018-12-09 07:43:02,366 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741885_1061{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 0
2018-12-09 07:43:02,368 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /mimic/inputevents_mv/INPUTEVENTS_MV.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1326279262_1
2018-12-09 07:43:02,375 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741853_1029 172.18.0.2:50010 
2018-12-09 07:43:03,140 INFO BlockStateChange: BLOCK* BlockManager: ask 172.18.0.2:50010 to delete [blk_1073741853_1029]
2018-12-09 07:43:05,629 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741886_1062{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /mimic/labevents/LABEVENTS.csv._COPYING_
2018-12-09 07:43:05,795 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741886_1062{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 0
2018-12-09 07:43:05,802 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /mimic/labevents/LABEVENTS.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_880534473_1
2018-12-09 07:43:05,810 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741854_1030 172.18.0.2:50010 
2018-12-09 07:43:06,142 INFO BlockStateChange: BLOCK* BlockManager: ask 172.18.0.2:50010 to delete [blk_1073741854_1030]
2018-12-09 07:43:09,222 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741887_1063{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /mimic/microbiologyevents/MICROBIOLOGYEVENTS.csv._COPYING_
2018-12-09 07:43:09,490 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741887_1063{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 0
2018-12-09 07:43:09,509 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /mimic/microbiologyevents/MICROBIOLOGYEVENTS.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1604937448_1
2018-12-09 07:43:09,536 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741855_1031 172.18.0.2:50010 
2018-12-09 07:43:12,145 INFO BlockStateChange: BLOCK* BlockManager: ask 172.18.0.2:50010 to delete [blk_1073741855_1031]
2018-12-09 07:43:13,093 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741888_1064{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /mimic/noteevents/NOTEEVENTS.csv._COPYING_
2018-12-09 07:43:13,305 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741888_1064{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 0
2018-12-09 07:43:13,310 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /mimic/noteevents/NOTEEVENTS.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_203289049_1
2018-12-09 07:43:13,318 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741856_1032 172.18.0.2:50010 
2018-12-09 07:43:15,148 INFO BlockStateChange: BLOCK* BlockManager: ask 172.18.0.2:50010 to delete [blk_1073741856_1032]
2018-12-09 07:43:16,466 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741889_1065{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /mimic/outputevents/OUTPUTEVENTS.csv._COPYING_
2018-12-09 07:43:16,618 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741889_1065{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 0
2018-12-09 07:43:16,624 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /mimic/outputevents/OUTPUTEVENTS.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_1851820964_1
2018-12-09 07:43:16,631 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741857_1033 172.18.0.2:50010 
2018-12-09 07:43:18,149 INFO BlockStateChange: BLOCK* BlockManager: ask 172.18.0.2:50010 to delete [blk_1073741857_1033]
2018-12-09 07:43:19,845 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 584 Total time for transactions(ms): 45 Number of transactions batched in Syncs: 10 Number of syncs: 435 SyncTimes(ms): 889 
2018-12-09 07:43:19,896 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741890_1066{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /mimic/patients/PATIENTS.csv._COPYING_
2018-12-09 07:43:20,060 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741890_1066{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 0
2018-12-09 07:43:20,066 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /mimic/patients/PATIENTS.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1124673472_1
2018-12-09 07:43:20,074 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741858_1034 172.18.0.2:50010 
2018-12-09 07:43:21,150 INFO BlockStateChange: BLOCK* BlockManager: ask 172.18.0.2:50010 to delete [blk_1073741858_1034]
2018-12-09 07:43:23,104 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741891_1067{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /mimic/prescriptions/PRESCRIPTIONS.csv._COPYING_
2018-12-09 07:43:23,237 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741891_1067{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 0
2018-12-09 07:43:23,245 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /mimic/prescriptions/PRESCRIPTIONS.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1667650869_1
2018-12-09 07:43:23,254 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741859_1035 172.18.0.2:50010 
2018-12-09 07:43:24,151 INFO BlockStateChange: BLOCK* BlockManager: ask 172.18.0.2:50010 to delete [blk_1073741859_1035]
2018-12-09 07:43:26,411 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741892_1068{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /mimic/procedureevents_mv/PROCEDUREEVENTS_MV.csv._COPYING_
2018-12-09 07:43:26,565 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741892_1068{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 0
2018-12-09 07:43:26,572 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /mimic/procedureevents_mv/PROCEDUREEVENTS_MV.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1432050607_1
2018-12-09 07:43:26,584 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741860_1036 172.18.0.2:50010 
2018-12-09 07:43:27,152 INFO BlockStateChange: BLOCK* BlockManager: ask 172.18.0.2:50010 to delete [blk_1073741860_1036]
2018-12-09 07:43:29,733 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741893_1069{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /mimic/procedures_icd/PROCEDURES_ICD.csv._COPYING_
2018-12-09 07:43:29,863 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741893_1069{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 0
2018-12-09 07:43:29,869 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /mimic/procedures_icd/PROCEDURES_ICD.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_59844477_1
2018-12-09 07:43:29,881 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741861_1037 172.18.0.2:50010 
2018-12-09 07:43:30,155 INFO BlockStateChange: BLOCK* BlockManager: ask 172.18.0.2:50010 to delete [blk_1073741861_1037]
2018-12-09 07:43:36,051 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741894_1070{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /mimic/services/SERVICES.csv._COPYING_
2018-12-09 07:43:36,254 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741894_1070{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 0
2018-12-09 07:43:36,258 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /mimic/services/SERVICES.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_1961861372_1
2018-12-09 07:43:36,267 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741862_1038 172.18.0.2:50010 
2018-12-09 07:43:39,123 INFO BlockStateChange: BLOCK* BlockManager: ask 172.18.0.2:50010 to delete [blk_1073741862_1038]
2018-12-09 07:43:39,226 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741895_1071{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /mimic/transfers/TRANSFERS.csv._COPYING_
2018-12-09 07:43:39,363 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741895_1071{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 0
2018-12-09 07:43:39,366 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /mimic/transfers/TRANSFERS.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_627760571_1
2018-12-09 07:43:39,374 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741863_1039 172.18.0.2:50010 
2018-12-09 07:43:42,124 INFO BlockStateChange: BLOCK* BlockManager: ask 172.18.0.2:50010 to delete [blk_1073741863_1039]
2018-12-09 07:43:42,475 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741896_1072{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /ccs/ccs_dx_map/ccs_dx_map.csv._COPYING_
2018-12-09 07:43:42,642 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741896_1072{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 0
2018-12-09 07:43:42,646 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /ccs/ccs_dx_map/ccs_dx_map.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_2036108613_1
2018-12-09 07:43:42,654 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741864_1040 172.18.0.2:50010 
2018-12-09 07:43:45,125 INFO BlockStateChange: BLOCK* BlockManager: ask 172.18.0.2:50010 to delete [blk_1073741864_1040]
2018-12-09 07:43:45,491 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741897_1073{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /ccs/ccs_proc_map/ccs_proc_map.csv._COPYING_
2018-12-09 07:43:45,653 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741897_1073{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 0
2018-12-09 07:43:45,655 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /ccs/ccs_proc_map/ccs_proc_map.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_449187544_1
2018-12-09 07:43:45,662 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741865_1041 172.18.0.2:50010 
2018-12-09 07:43:48,127 INFO BlockStateChange: BLOCK* BlockManager: ask 172.18.0.2:50010 to delete [blk_1073741865_1041]
2018-12-09 07:43:48,566 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741898_1074{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /model/noteevents_with_topics/noteevents_with_topics.csv._COPYING_
2018-12-09 07:43:48,738 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741898_1074{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 0
2018-12-09 07:43:48,741 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /model/noteevents_with_topics/noteevents_with_topics.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_346088967_1
2018-12-09 07:43:48,750 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741866_1042 172.18.0.2:50010 
2018-12-09 07:43:51,129 INFO BlockStateChange: BLOCK* BlockManager: ask 172.18.0.2:50010 to delete [blk_1073741866_1042]
2018-12-09 07:43:51,695 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741899_1075{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /model/admissions_ccs_ohe/admissions_ccs_ohe.csv._COPYING_
2018-12-09 07:43:51,858 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741899_1075{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 0
2018-12-09 07:43:51,865 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /model/admissions_ccs_ohe/admissions_ccs_ohe.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_855484207_1
2018-12-09 07:43:51,873 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741867_1043 172.18.0.2:50010 
2018-12-09 07:43:54,130 INFO BlockStateChange: BLOCK* BlockManager: ask 172.18.0.2:50010 to delete [blk_1073741867_1043]
2018-12-09 07:43:54,812 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741900_1076{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /model/admissions_topic_scores/admissions_topic_scores.csv._COPYING_
2018-12-09 07:43:54,947 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741900_1076{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 0
2018-12-09 07:43:54,951 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /model/admissions_topic_scores/admissions_topic_scores.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_1637779270_1
2018-12-09 07:43:54,959 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741868_1044 172.18.0.2:50010 
2018-12-09 07:43:57,133 INFO BlockStateChange: BLOCK* BlockManager: ask 172.18.0.2:50010 to delete [blk_1073741868_1044]
2018-12-09 07:44:27,074 INFO BlockStateChange: BLOCK* processReport: from storage DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5 node DatanodeRegistration(172.18.0.2:50010, datanodeUuid=47ecd31e-43cd-4989-84ba-314b1664d0de, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-747ab8c6-1ec4-46a0-9dee-c8151846aca5;nsid=199960936;c=0), blocks: 43, hasStaleStorage: false, processing time: 1 msecs
2018-12-09 07:48:12,937 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 661 Total time for transactions(ms): 47 Number of transactions batched in Syncs: 10 Number of syncs: 490 SyncTimes(ms): 3850 
2018-12-09 07:51:19,735 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 664 Total time for transactions(ms): 50 Number of transactions batched in Syncs: 10 Number of syncs: 493 SyncTimes(ms): 3865 
2018-12-09 07:51:19,793 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741901_1077{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /mimic/admissions/ADMISSIONS.csv._COPYING_
2018-12-09 07:51:20,081 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741901_1077{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 0
2018-12-09 07:51:20,084 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /mimic/admissions/ADMISSIONS.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_1742326378_1
2018-12-09 07:51:20,096 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741871_1047 172.18.0.2:50010 
2018-12-09 07:51:20,729 INFO BlockStateChange: BLOCK* BlockManager: ask 172.18.0.2:50010 to delete [blk_1073741871_1047]
2018-12-09 07:51:23,933 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741902_1078{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /mimic/callout/CALLOUT.csv._COPYING_
2018-12-09 07:51:24,159 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741902_1078{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 0
2018-12-09 07:51:24,171 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /mimic/callout/CALLOUT.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_247109231_1
2018-12-09 07:51:24,184 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741872_1048 172.18.0.2:50010 
2018-12-09 07:51:26,730 INFO BlockStateChange: BLOCK* BlockManager: ask 172.18.0.2:50010 to delete [blk_1073741872_1048]
2018-12-09 07:51:28,288 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741903_1079{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /mimic/caregivers/CAREGIVERS.csv._COPYING_
2018-12-09 07:51:28,454 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741903_1079{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 0
2018-12-09 07:51:28,477 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /mimic/caregivers/CAREGIVERS.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_1407831545_1
2018-12-09 07:51:28,485 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741873_1049 172.18.0.2:50010 
2018-12-09 07:51:29,731 INFO BlockStateChange: BLOCK* BlockManager: ask 172.18.0.2:50010 to delete [blk_1073741873_1049]
2018-12-09 07:51:29,802 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741904_1080{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /mimic/admissions/ADMISSIONS.csv._COPYING_
2018-12-09 07:51:30,067 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741904_1080{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 0
2018-12-09 07:51:30,083 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /mimic/admissions/ADMISSIONS.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_-826485443_1
2018-12-09 07:51:30,093 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741901_1077 172.18.0.2:50010 
2018-12-09 07:51:32,408 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741905_1081{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /mimic/chartevents/CHARTEVENTS.csv._COPYING_
2018-12-09 07:51:32,583 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741905_1081{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 0
2018-12-09 07:51:32,587 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /mimic/chartevents/CHARTEVENTS.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1807606780_1
2018-12-09 07:51:32,597 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741874_1050 172.18.0.2:50010 
2018-12-09 07:51:32,700 INFO BlockStateChange: BLOCK* BlockManager: ask 172.18.0.2:50010 to delete [blk_1073741874_1050, blk_1073741901_1077]
2018-12-09 07:51:34,270 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741906_1082{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /mimic/callout/CALLOUT.csv._COPYING_
2018-12-09 07:51:34,502 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741906_1082{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 0
2018-12-09 07:51:34,514 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /mimic/callout/CALLOUT.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1919629857_1
2018-12-09 07:51:34,524 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741902_1078 172.18.0.2:50010 
2018-12-09 07:51:35,700 INFO BlockStateChange: BLOCK* BlockManager: ask 172.18.0.2:50010 to delete [blk_1073741902_1078]
2018-12-09 07:51:36,256 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741907_1083{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /mimic/cptevents/CPTEVENTS.csv._COPYING_
2018-12-09 07:51:36,451 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741907_1083{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 0
2018-12-09 07:51:36,456 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /mimic/cptevents/CPTEVENTS.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1268328171_1
2018-12-09 07:51:36,463 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741875_1051 172.18.0.2:50010 
2018-12-09 07:51:38,161 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741908_1084{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /mimic/caregivers/CAREGIVERS.csv._COPYING_
2018-12-09 07:51:38,313 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741908_1084{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 0
2018-12-09 07:51:38,317 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /mimic/caregivers/CAREGIVERS.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_1976147032_1
2018-12-09 07:51:38,330 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741903_1079 172.18.0.2:50010 
2018-12-09 07:51:38,702 INFO BlockStateChange: BLOCK* BlockManager: ask 172.18.0.2:50010 to delete [blk_1073741875_1051, blk_1073741903_1079]
2018-12-09 07:51:40,983 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741909_1085{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /mimic/datetimeevents/DATETIMEEVENTS.csv._COPYING_
2018-12-09 07:51:41,182 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741909_1085{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 0
2018-12-09 07:51:41,196 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /mimic/datetimeevents/DATETIMEEVENTS.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1522506637_1
2018-12-09 07:51:41,207 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741876_1052 172.18.0.2:50010 
2018-12-09 07:51:41,703 INFO BlockStateChange: BLOCK* BlockManager: ask 172.18.0.2:50010 to delete [blk_1073741876_1052]
2018-12-09 07:51:42,298 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741910_1086{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /mimic/chartevents/CHARTEVENTS.csv._COPYING_
2018-12-09 07:51:42,494 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741910_1086{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 0
2018-12-09 07:51:42,500 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /mimic/chartevents/CHARTEVENTS.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_-606646337_1
2018-12-09 07:51:42,508 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741905_1081 172.18.0.2:50010 
2018-12-09 07:51:44,709 INFO BlockStateChange: BLOCK* BlockManager: ask 172.18.0.2:50010 to delete [blk_1073741905_1081]
2018-12-09 07:51:45,076 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741911_1087{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /mimic/diagnoses_icd/DIAGNOSES_ICD.csv._COPYING_
2018-12-09 07:51:45,301 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741911_1087{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 0
2018-12-09 07:51:45,306 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /mimic/diagnoses_icd/DIAGNOSES_ICD.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1013723841_1
2018-12-09 07:51:45,315 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741844_1020 172.18.0.2:50010 
2018-12-09 07:51:46,643 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741912_1088{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /mimic/cptevents/CPTEVENTS.csv._COPYING_
2018-12-09 07:51:46,954 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741912_1088{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 0
2018-12-09 07:51:46,972 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /mimic/cptevents/CPTEVENTS.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1150153828_1
2018-12-09 07:51:46,988 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741907_1083 172.18.0.2:50010 
2018-12-09 07:51:47,710 INFO BlockStateChange: BLOCK* BlockManager: ask 172.18.0.2:50010 to delete [blk_1073741907_1083, blk_1073741844_1020]
2018-12-09 07:51:49,401 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741913_1089{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /mimic/drgcodes/DRGCODES.csv._COPYING_
2018-12-09 07:51:49,604 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741913_1089{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 0
2018-12-09 07:51:49,609 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /mimic/drgcodes/DRGCODES.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_266512765_1
2018-12-09 07:51:49,617 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741877_1053 172.18.0.2:50010 
2018-12-09 07:51:50,711 INFO BlockStateChange: BLOCK* BlockManager: ask 172.18.0.2:50010 to delete [blk_1073741877_1053]
2018-12-09 07:51:50,784 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741914_1090{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /mimic/datetimeevents/DATETIMEEVENTS.csv._COPYING_
2018-12-09 07:51:50,961 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741914_1090{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 0
2018-12-09 07:51:50,967 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /mimic/datetimeevents/DATETIMEEVENTS.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_-226122338_1
2018-12-09 07:51:50,974 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741909_1085 172.18.0.2:50010 
2018-12-09 07:51:51,870 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741915_1091{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /mimic/admissions/ADMISSIONS.csv._COPYING_
2018-12-09 07:51:52,013 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741915_1091{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 0
2018-12-09 07:51:52,020 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /mimic/admissions/ADMISSIONS.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_1703481240_1
2018-12-09 07:51:52,032 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741904_1080 172.18.0.2:50010 
2018-12-09 07:51:53,027 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741916_1092{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /mimic/d_cpt/D_CPT.csv._COPYING_
2018-12-09 07:51:53,247 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741916_1092{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 0
2018-12-09 07:51:53,259 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /mimic/d_cpt/D_CPT.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_-2007368731_1
2018-12-09 07:51:53,275 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741878_1054 172.18.0.2:50010 
2018-12-09 07:51:53,712 INFO BlockStateChange: BLOCK* BlockManager: ask 172.18.0.2:50010 to delete [blk_1073741904_1080, blk_1073741909_1085, blk_1073741878_1054]
2018-12-09 07:51:54,674 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741917_1093{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /mimic/diagnoses_icd/DIAGNOSES_ICD.csv._COPYING_
2018-12-09 07:51:54,858 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741917_1093{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 0
2018-12-09 07:51:54,867 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /mimic/diagnoses_icd/DIAGNOSES_ICD.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_1318105886_1
2018-12-09 07:51:54,874 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741911_1087 172.18.0.2:50010 
2018-12-09 07:51:55,462 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741918_1094{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /mimic/callout/CALLOUT.csv._COPYING_
2018-12-09 07:51:55,657 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741918_1094{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 0
2018-12-09 07:51:55,670 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /mimic/callout/CALLOUT.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_-613756118_1
2018-12-09 07:51:55,682 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741906_1082 172.18.0.2:50010 
2018-12-09 07:51:56,713 INFO BlockStateChange: BLOCK* BlockManager: ask 172.18.0.2:50010 to delete [blk_1073741906_1082, blk_1073741911_1087]
2018-12-09 07:51:57,021 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741919_1095{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /mimic/d_icd_diagnoses/D_ICD_DIAGNOSES.csv._COPYING_
2018-12-09 07:51:57,256 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741919_1095{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 0
2018-12-09 07:51:57,262 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /mimic/d_icd_diagnoses/D_ICD_DIAGNOSES.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1292660935_1
2018-12-09 07:51:57,276 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741879_1055 172.18.0.2:50010 
2018-12-09 07:51:58,709 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741920_1096{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /mimic/drgcodes/DRGCODES.csv._COPYING_
2018-12-09 07:51:58,902 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741920_1096{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 0
2018-12-09 07:51:58,911 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /mimic/drgcodes/DRGCODES.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1765404662_1
2018-12-09 07:51:58,921 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741913_1089 172.18.0.2:50010 
2018-12-09 07:51:59,712 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741921_1097{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /mimic/caregivers/CAREGIVERS.csv._COPYING_
2018-12-09 07:51:59,714 INFO BlockStateChange: BLOCK* BlockManager: ask 172.18.0.2:50010 to delete [blk_1073741879_1055, blk_1073741913_1089]
2018-12-09 07:51:59,923 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741921_1097{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 0
2018-12-09 07:51:59,925 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /mimic/caregivers/CAREGIVERS.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_1684829084_1
2018-12-09 07:51:59,933 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741908_1084 172.18.0.2:50010 
2018-12-09 07:52:01,275 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741922_1098{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /mimic/d_icd_procedures/D_ICD_PROCEDURES.csv._COPYING_
2018-12-09 07:52:01,466 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741922_1098{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 0
2018-12-09 07:52:01,478 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /mimic/d_icd_procedures/D_ICD_PROCEDURES.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_210609639_1
2018-12-09 07:52:01,487 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741880_1056 172.18.0.2:50010 
2018-12-09 07:52:02,679 INFO BlockStateChange: BLOCK* BlockManager: ask 172.18.0.2:50010 to delete [blk_1073741908_1084, blk_1073741880_1056]
2018-12-09 07:52:02,803 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741923_1099{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /mimic/d_cpt/D_CPT.csv._COPYING_
2018-12-09 07:52:03,052 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741923_1099{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 0
2018-12-09 07:52:03,057 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /mimic/d_cpt/D_CPT.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_-857794630_1
2018-12-09 07:52:03,066 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741916_1092 172.18.0.2:50010 
2018-12-09 07:52:04,014 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741924_1100{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /mimic/chartevents/CHARTEVENTS.csv._COPYING_
2018-12-09 07:52:04,240 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741924_1100{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 0
2018-12-09 07:52:04,261 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /mimic/chartevents/CHARTEVENTS.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_-2110986436_1
2018-12-09 07:52:04,280 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741910_1086 172.18.0.2:50010 
2018-12-09 07:52:05,308 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741925_1101{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /mimic/d_items/D_ITEMS.csv._COPYING_
2018-12-09 07:52:05,527 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741925_1101{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 0
2018-12-09 07:52:05,532 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /mimic/d_items/D_ITEMS.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_331392387_1
2018-12-09 07:52:05,543 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741881_1057 172.18.0.2:50010 
2018-12-09 07:52:05,680 INFO BlockStateChange: BLOCK* BlockManager: ask 172.18.0.2:50010 to delete [blk_1073741910_1086, blk_1073741881_1057, blk_1073741916_1092]
2018-12-09 07:52:06,933 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741926_1102{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /mimic/d_icd_diagnoses/D_ICD_DIAGNOSES.csv._COPYING_
2018-12-09 07:52:07,120 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741926_1102{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 0
2018-12-09 07:52:07,129 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /mimic/d_icd_diagnoses/D_ICD_DIAGNOSES.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_-446790528_1
2018-12-09 07:52:07,137 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741919_1095 172.18.0.2:50010 
2018-12-09 07:52:08,079 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741927_1103{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /mimic/cptevents/CPTEVENTS.csv._COPYING_
2018-12-09 07:52:08,359 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741927_1103{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 0
2018-12-09 07:52:08,372 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /mimic/cptevents/CPTEVENTS.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_-895408909_1
2018-12-09 07:52:08,380 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741912_1088 172.18.0.2:50010 
2018-12-09 07:52:08,681 INFO BlockStateChange: BLOCK* BlockManager: ask 172.18.0.2:50010 to delete [blk_1073741912_1088, blk_1073741919_1095]
2018-12-09 07:52:09,311 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741928_1104{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /mimic/d_labitems/D_LABITEMS.csv._COPYING_
2018-12-09 07:52:09,487 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741928_1104{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 0
2018-12-09 07:52:09,503 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /mimic/d_labitems/D_LABITEMS.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1279950423_1
2018-12-09 07:52:09,513 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741882_1058 172.18.0.2:50010 
2018-12-09 07:52:10,655 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741929_1105{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /mimic/d_icd_procedures/D_ICD_PROCEDURES.csv._COPYING_
2018-12-09 07:52:10,844 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741929_1105{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 0
2018-12-09 07:52:10,849 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /mimic/d_icd_procedures/D_ICD_PROCEDURES.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1387874709_1
2018-12-09 07:52:10,857 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741922_1098 172.18.0.2:50010 
2018-12-09 07:52:11,683 INFO BlockStateChange: BLOCK* BlockManager: ask 172.18.0.2:50010 to delete [blk_1073741922_1098, blk_1073741882_1058]
2018-12-09 07:52:11,892 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741930_1106{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /mimic/datetimeevents/DATETIMEEVENTS.csv._COPYING_
2018-12-09 07:52:12,199 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741930_1106{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 0
2018-12-09 07:52:12,205 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /mimic/datetimeevents/DATETIMEEVENTS.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_1943122838_1
2018-12-09 07:52:12,213 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741914_1090 172.18.0.2:50010 
2018-12-09 07:52:13,048 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741931_1107{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /mimic/icustays/ICUSTAYS.csv._COPYING_
2018-12-09 07:52:13,184 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741931_1107{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 0
2018-12-09 07:52:13,194 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /mimic/icustays/ICUSTAYS.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_132181162_1
2018-12-09 07:52:13,202 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741883_1059 172.18.0.2:50010 
2018-12-09 07:52:14,497 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741932_1108{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /mimic/d_items/D_ITEMS.csv._COPYING_
2018-12-09 07:52:14,685 INFO BlockStateChange: BLOCK* BlockManager: ask 172.18.0.2:50010 to delete [blk_1073741914_1090, blk_1073741883_1059]
2018-12-09 07:52:14,726 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741932_1108{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 0
2018-12-09 07:52:14,732 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /mimic/d_items/D_ITEMS.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_2130053100_1
2018-12-09 07:52:14,741 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741925_1101 172.18.0.2:50010 
2018-12-09 07:52:15,642 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741933_1109{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /mimic/diagnoses_icd/DIAGNOSES_ICD.csv._COPYING_
2018-12-09 07:52:15,868 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741933_1109{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 0
2018-12-09 07:52:15,874 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /mimic/diagnoses_icd/DIAGNOSES_ICD.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_2047340915_1
2018-12-09 07:52:15,883 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741917_1093 172.18.0.2:50010 
2018-12-09 07:52:16,759 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741934_1110{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /mimic/inputevents_cv/INPUTEVENTS_CV.csv._COPYING_
2018-12-09 07:52:16,949 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741934_1110{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 0
2018-12-09 07:52:16,953 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /mimic/inputevents_cv/INPUTEVENTS_CV.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_886705619_1
2018-12-09 07:52:16,961 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741884_1060 172.18.0.2:50010 
2018-12-09 07:52:17,686 INFO BlockStateChange: BLOCK* BlockManager: ask 172.18.0.2:50010 to delete [blk_1073741925_1101, blk_1073741884_1060, blk_1073741917_1093]
2018-12-09 07:52:18,364 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741935_1111{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /mimic/d_labitems/D_LABITEMS.csv._COPYING_
2018-12-09 07:52:18,593 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741935_1111{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 0
2018-12-09 07:52:18,598 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /mimic/d_labitems/D_LABITEMS.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_-2010340075_1
2018-12-09 07:52:18,608 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741928_1104 172.18.0.2:50010 
2018-12-09 07:52:19,373 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741936_1112{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /mimic/drgcodes/DRGCODES.csv._COPYING_
2018-12-09 07:52:19,558 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741936_1112{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 0
2018-12-09 07:52:19,585 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /mimic/drgcodes/DRGCODES.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_-937478755_1
2018-12-09 07:52:19,595 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741920_1096 172.18.0.2:50010 
2018-12-09 07:52:20,305 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 916 Total time for transactions(ms): 68 Number of transactions batched in Syncs: 10 Number of syncs: 673 SyncTimes(ms): 4118 
2018-12-09 07:52:20,362 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741937_1113{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /mimic/inputevents_mv/INPUTEVENTS_MV.csv._COPYING_
2018-12-09 07:52:20,621 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741937_1113{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 0
2018-12-09 07:52:20,629 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /mimic/inputevents_mv/INPUTEVENTS_MV.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_-423961798_1
2018-12-09 07:52:20,639 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741885_1061 172.18.0.2:50010 
2018-12-09 07:52:20,688 INFO BlockStateChange: BLOCK* BlockManager: ask 172.18.0.2:50010 to delete [blk_1073741920_1096, blk_1073741928_1104, blk_1073741885_1061]
2018-12-09 07:52:22,298 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741938_1114{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /mimic/icustays/ICUSTAYS.csv._COPYING_
2018-12-09 07:52:22,469 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741938_1114{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 0
2018-12-09 07:52:22,478 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /mimic/icustays/ICUSTAYS.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_703358400_1
2018-12-09 07:52:22,486 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741931_1107 172.18.0.2:50010 
2018-12-09 07:52:23,240 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741939_1115{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /mimic/d_cpt/D_CPT.csv._COPYING_
2018-12-09 07:52:23,391 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741939_1115{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 0
2018-12-09 07:52:23,396 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /mimic/d_cpt/D_CPT.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_-2133913353_1
2018-12-09 07:52:23,405 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741923_1099 172.18.0.2:50010 
2018-12-09 07:52:23,688 INFO BlockStateChange: BLOCK* BlockManager: ask 172.18.0.2:50010 to delete [blk_1073741923_1099, blk_1073741931_1107]
2018-12-09 07:52:24,438 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741940_1116{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /mimic/labevents/LABEVENTS.csv._COPYING_
2018-12-09 07:52:24,710 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741940_1116{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 0
2018-12-09 07:52:24,715 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /mimic/labevents/LABEVENTS.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_-45484873_1
2018-12-09 07:52:24,722 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741886_1062 172.18.0.2:50010 
2018-12-09 07:52:26,237 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741941_1117{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /mimic/inputevents_cv/INPUTEVENTS_CV.csv._COPYING_
2018-12-09 07:52:26,415 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741941_1117{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 0
2018-12-09 07:52:26,418 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /mimic/inputevents_cv/INPUTEVENTS_CV.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_-391854024_1
2018-12-09 07:52:26,426 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741934_1110 172.18.0.2:50010 
2018-12-09 07:52:26,689 INFO BlockStateChange: BLOCK* BlockManager: ask 172.18.0.2:50010 to delete [blk_1073741934_1110, blk_1073741886_1062]
2018-12-09 07:52:27,397 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741942_1118{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /mimic/d_icd_diagnoses/D_ICD_DIAGNOSES.csv._COPYING_
2018-12-09 07:52:27,629 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741942_1118{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 0
2018-12-09 07:52:27,633 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /mimic/d_icd_diagnoses/D_ICD_DIAGNOSES.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_402398111_1
2018-12-09 07:52:27,641 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741926_1102 172.18.0.2:50010 
2018-12-09 07:52:28,197 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741943_1119{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /mimic/microbiologyevents/MICROBIOLOGYEVENTS.csv._COPYING_
2018-12-09 07:52:28,427 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741943_1119{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 0
2018-12-09 07:52:28,438 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /mimic/microbiologyevents/MICROBIOLOGYEVENTS.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_521549909_1
2018-12-09 07:52:28,448 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741887_1063 172.18.0.2:50010 
2018-12-09 07:52:29,690 INFO BlockStateChange: BLOCK* BlockManager: ask 172.18.0.2:50010 to delete [blk_1073741926_1102, blk_1073741887_1063]
2018-12-09 07:52:30,003 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741944_1120{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /mimic/inputevents_mv/INPUTEVENTS_MV.csv._COPYING_
2018-12-09 07:52:30,176 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741944_1120{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 0
2018-12-09 07:52:30,183 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /mimic/inputevents_mv/INPUTEVENTS_MV.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_496504165_1
2018-12-09 07:52:30,191 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741937_1113 172.18.0.2:50010 
2018-12-09 07:52:31,184 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741945_1121{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /mimic/d_icd_procedures/D_ICD_PROCEDURES.csv._COPYING_
2018-12-09 07:52:31,300 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741945_1121{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 0
2018-12-09 07:52:31,305 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /mimic/d_icd_procedures/D_ICD_PROCEDURES.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1494791964_1
2018-12-09 07:52:31,313 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741929_1105 172.18.0.2:50010 
2018-12-09 07:52:32,283 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741946_1122{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /mimic/noteevents/NOTEEVENTS.csv._COPYING_
2018-12-09 07:52:32,640 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741946_1122{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 0
2018-12-09 07:52:32,642 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /mimic/noteevents/NOTEEVENTS.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_-286348894_1
2018-12-09 07:52:32,650 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741888_1064 172.18.0.2:50010 
2018-12-09 07:52:32,656 INFO BlockStateChange: BLOCK* BlockManager: ask 172.18.0.2:50010 to delete [blk_1073741888_1064, blk_1073741937_1113, blk_1073741929_1105]
2018-12-09 07:52:33,779 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741947_1123{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /mimic/labevents/LABEVENTS.csv._COPYING_
2018-12-09 07:52:33,990 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741947_1123{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 0
2018-12-09 07:52:33,994 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /mimic/labevents/LABEVENTS.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_-958887521_1
2018-12-09 07:52:34,007 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741940_1116 172.18.0.2:50010 
2018-12-09 07:52:34,807 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741948_1124{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /mimic/d_items/D_ITEMS.csv._COPYING_
2018-12-09 07:52:34,953 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741948_1124{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 0
2018-12-09 07:52:34,988 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /mimic/d_items/D_ITEMS.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_1890170661_1
2018-12-09 07:52:34,996 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741932_1108 172.18.0.2:50010 
2018-12-09 07:52:35,658 INFO BlockStateChange: BLOCK* BlockManager: ask 172.18.0.2:50010 to delete [blk_1073741940_1116, blk_1073741932_1108]
2018-12-09 07:52:36,287 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741949_1125{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /mimic/outputevents/OUTPUTEVENTS.csv._COPYING_
2018-12-09 07:52:36,488 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741949_1125{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 0
2018-12-09 07:52:36,493 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /mimic/outputevents/OUTPUTEVENTS.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_1525517931_1
2018-12-09 07:52:36,501 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741889_1065 172.18.0.2:50010 
2018-12-09 07:52:37,908 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741950_1126{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /mimic/microbiologyevents/MICROBIOLOGYEVENTS.csv._COPYING_
2018-12-09 07:52:38,152 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741950_1126{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 0
2018-12-09 07:52:38,158 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /mimic/microbiologyevents/MICROBIOLOGYEVENTS.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_1957933133_1
2018-12-09 07:52:38,166 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741943_1119 172.18.0.2:50010 
2018-12-09 07:52:38,435 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741951_1127{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /mimic/d_labitems/D_LABITEMS.csv._COPYING_
2018-12-09 07:52:38,609 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741951_1127{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 0
2018-12-09 07:52:38,627 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /mimic/d_labitems/D_LABITEMS.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_-2112849190_1
2018-12-09 07:52:38,638 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741935_1111 172.18.0.2:50010 
2018-12-09 07:52:38,660 INFO BlockStateChange: BLOCK* BlockManager: ask 172.18.0.2:50010 to delete [blk_1073741889_1065, blk_1073741943_1119, blk_1073741935_1111]
2018-12-09 07:52:40,622 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741952_1128{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /mimic/patients/PATIENTS.csv._COPYING_
2018-12-09 07:52:40,918 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741952_1128{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 0
2018-12-09 07:52:40,926 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /mimic/patients/PATIENTS.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_1287852181_1
2018-12-09 07:52:40,951 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741890_1066 172.18.0.2:50010 
2018-12-09 07:52:41,662 INFO BlockStateChange: BLOCK* BlockManager: ask 172.18.0.2:50010 to delete [blk_1073741890_1066]
2018-12-09 07:52:42,571 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741953_1129{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /mimic/noteevents/NOTEEVENTS.csv._COPYING_
2018-12-09 07:52:42,652 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741954_1130{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /mimic/icustays/ICUSTAYS.csv._COPYING_
2018-12-09 07:52:42,823 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741953_1129{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 0
2018-12-09 07:52:42,829 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /mimic/noteevents/NOTEEVENTS.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_417144484_1
2018-12-09 07:52:42,848 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741946_1122 172.18.0.2:50010 
2018-12-09 07:52:42,857 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741954_1130{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 0
2018-12-09 07:52:42,863 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /mimic/icustays/ICUSTAYS.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_817826216_1
2018-12-09 07:52:42,871 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741938_1114 172.18.0.2:50010 
2018-12-09 07:52:44,662 INFO BlockStateChange: BLOCK* BlockManager: ask 172.18.0.2:50010 to delete [blk_1073741938_1114, blk_1073741946_1122]
2018-12-09 07:52:44,807 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741955_1131{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /mimic/prescriptions/PRESCRIPTIONS.csv._COPYING_
2018-12-09 07:52:45,012 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741955_1131{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 0
2018-12-09 07:52:45,015 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /mimic/prescriptions/PRESCRIPTIONS.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_1418564510_1
2018-12-09 07:52:45,030 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741891_1067 172.18.0.2:50010 
2018-12-09 07:52:46,932 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741956_1132{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /mimic/outputevents/OUTPUTEVENTS.csv._COPYING_
2018-12-09 07:52:46,964 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741957_1133{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /mimic/inputevents_cv/INPUTEVENTS_CV.csv._COPYING_
2018-12-09 07:52:47,106 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741956_1132{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 0
2018-12-09 07:52:47,113 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /mimic/outputevents/OUTPUTEVENTS.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_430902806_1
2018-12-09 07:52:47,121 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741949_1125 172.18.0.2:50010 
2018-12-09 07:52:47,227 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741957_1133{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 0
2018-12-09 07:52:47,231 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /mimic/inputevents_cv/INPUTEVENTS_CV.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_-822462725_1
2018-12-09 07:52:47,241 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741941_1117 172.18.0.2:50010 
2018-12-09 07:52:47,664 INFO BlockStateChange: BLOCK* BlockManager: ask 172.18.0.2:50010 to delete [blk_1073741891_1067, blk_1073741941_1117, blk_1073741949_1125]
2018-12-09 07:52:48,747 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741958_1134{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /mimic/procedureevents_mv/PROCEDUREEVENTS_MV.csv._COPYING_
2018-12-09 07:52:48,965 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741958_1134{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 0
2018-12-09 07:52:48,969 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /mimic/procedureevents_mv/PROCEDUREEVENTS_MV.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_973906289_1
2018-12-09 07:52:48,978 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741892_1068 172.18.0.2:50010 
2018-12-09 07:52:50,665 INFO BlockStateChange: BLOCK* BlockManager: ask 172.18.0.2:50010 to delete [blk_1073741892_1068]
2018-12-09 07:52:50,851 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741959_1135{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /mimic/inputevents_mv/INPUTEVENTS_MV.csv._COPYING_
2018-12-09 07:52:51,005 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741959_1135{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 0
2018-12-09 07:52:51,009 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /mimic/inputevents_mv/INPUTEVENTS_MV.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_-2025623576_1
2018-12-09 07:52:51,017 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741944_1120 172.18.0.2:50010 
2018-12-09 07:52:51,047 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741960_1136{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /mimic/patients/PATIENTS.csv._COPYING_
2018-12-09 07:52:51,253 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741960_1136{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 0
2018-12-09 07:52:51,259 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /mimic/patients/PATIENTS.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_161413704_1
2018-12-09 07:52:51,275 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741952_1128 172.18.0.2:50010 
2018-12-09 07:52:52,644 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741961_1137{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /mimic/procedures_icd/PROCEDURES_ICD.csv._COPYING_
2018-12-09 07:52:52,784 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741961_1137{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 0
2018-12-09 07:52:52,792 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /mimic/procedures_icd/PROCEDURES_ICD.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1758004636_1
2018-12-09 07:52:52,801 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741893_1069 172.18.0.2:50010 
2018-12-09 07:52:53,666 INFO BlockStateChange: BLOCK* BlockManager: ask 172.18.0.2:50010 to delete [blk_1073741952_1128, blk_1073741893_1069, blk_1073741944_1120]
2018-12-09 07:52:54,755 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741962_1138{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /mimic/labevents/LABEVENTS.csv._COPYING_
2018-12-09 07:52:54,913 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741962_1138{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 0
2018-12-09 07:52:54,936 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /mimic/labevents/LABEVENTS.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_-23847381_1
2018-12-09 07:52:54,949 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741947_1123 172.18.0.2:50010 
2018-12-09 07:52:55,115 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741963_1139{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /mimic/prescriptions/PRESCRIPTIONS.csv._COPYING_
2018-12-09 07:52:55,267 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741963_1139{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 0
2018-12-09 07:52:55,273 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /mimic/prescriptions/PRESCRIPTIONS.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_1356927167_1
2018-12-09 07:52:55,283 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741955_1131 172.18.0.2:50010 
2018-12-09 07:52:56,402 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741964_1140{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /mimic/services/SERVICES.csv._COPYING_
2018-12-09 07:52:56,618 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741964_1140{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 0
2018-12-09 07:52:56,623 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /mimic/services/SERVICES.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1390230453_1
2018-12-09 07:52:56,646 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741894_1070 172.18.0.2:50010 
2018-12-09 07:52:56,667 INFO BlockStateChange: BLOCK* BlockManager: ask 172.18.0.2:50010 to delete [blk_1073741955_1131, blk_1073741894_1070, blk_1073741947_1123]
2018-12-09 07:52:58,324 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741965_1141{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /mimic/microbiologyevents/MICROBIOLOGYEVENTS.csv._COPYING_
2018-12-09 07:52:58,607 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741965_1141{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 0
2018-12-09 07:52:58,613 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /mimic/microbiologyevents/MICROBIOLOGYEVENTS.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_1821859706_1
2018-12-09 07:52:58,625 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741950_1126 172.18.0.2:50010 
2018-12-09 07:52:58,986 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741966_1142{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /mimic/procedureevents_mv/PROCEDUREEVENTS_MV.csv._COPYING_
2018-12-09 07:52:59,151 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741966_1142{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 0
2018-12-09 07:52:59,157 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /mimic/procedureevents_mv/PROCEDUREEVENTS_MV.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1393267987_1
2018-12-09 07:52:59,164 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741958_1134 172.18.0.2:50010 
2018-12-09 07:52:59,668 INFO BlockStateChange: BLOCK* BlockManager: ask 172.18.0.2:50010 to delete [blk_1073741958_1134, blk_1073741950_1126]
2018-12-09 07:53:00,217 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741967_1143{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /mimic/transfers/TRANSFERS.csv._COPYING_
2018-12-09 07:53:00,444 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741967_1143{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 0
2018-12-09 07:53:00,448 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /mimic/transfers/TRANSFERS.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1459551635_1
2018-12-09 07:53:00,455 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741895_1071 172.18.0.2:50010 
2018-12-09 07:53:02,271 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741968_1144{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /mimic/noteevents/NOTEEVENTS.csv._COPYING_
2018-12-09 07:53:02,609 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741968_1144{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 0
2018-12-09 07:53:02,613 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /mimic/noteevents/NOTEEVENTS.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_-40782656_1
2018-12-09 07:53:02,622 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741953_1129 172.18.0.2:50010 
2018-12-09 07:53:02,634 INFO BlockStateChange: BLOCK* BlockManager: ask 172.18.0.2:50010 to delete [blk_1073741953_1129, blk_1073741895_1071]
2018-12-09 07:53:02,985 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741969_1145{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /mimic/procedures_icd/PROCEDURES_ICD.csv._COPYING_
2018-12-09 07:53:03,187 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741969_1145{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 0
2018-12-09 07:53:03,191 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /mimic/procedures_icd/PROCEDURES_ICD.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_-258999975_1
2018-12-09 07:53:03,198 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741961_1137 172.18.0.2:50010 
2018-12-09 07:53:04,283 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741970_1146{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /ccs/ccs_dx_map/ccs_dx_map.csv._COPYING_
2018-12-09 07:53:04,598 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741970_1146{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 0
2018-12-09 07:53:04,601 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /ccs/ccs_dx_map/ccs_dx_map.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_-118071226_1
2018-12-09 07:53:04,611 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741896_1072 172.18.0.2:50010 
2018-12-09 07:53:05,635 INFO BlockStateChange: BLOCK* BlockManager: ask 172.18.0.2:50010 to delete [blk_1073741896_1072, blk_1073741961_1137]
2018-12-09 07:53:06,257 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741971_1147{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /mimic/outputevents/OUTPUTEVENTS.csv._COPYING_
2018-12-09 07:53:06,434 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741971_1147{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 0
2018-12-09 07:53:06,439 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /mimic/outputevents/OUTPUTEVENTS.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1623909509_1
2018-12-09 07:53:06,449 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741956_1132 172.18.0.2:50010 
2018-12-09 07:53:06,935 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741972_1148{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /mimic/services/SERVICES.csv._COPYING_
2018-12-09 07:53:07,128 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741972_1148{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 0
2018-12-09 07:53:07,135 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /mimic/services/SERVICES.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_1569942666_1
2018-12-09 07:53:07,143 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741964_1140 172.18.0.2:50010 
2018-12-09 07:53:08,255 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741973_1149{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /ccs/ccs_proc_map/ccs_proc_map.csv._COPYING_
2018-12-09 07:53:08,465 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741973_1149{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 0
2018-12-09 07:53:08,469 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /ccs/ccs_proc_map/ccs_proc_map.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_1630814799_1
2018-12-09 07:53:08,483 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741897_1073 172.18.0.2:50010 
2018-12-09 07:53:08,637 INFO BlockStateChange: BLOCK* BlockManager: ask 172.18.0.2:50010 to delete [blk_1073741956_1132, blk_1073741897_1073, blk_1073741964_1140]
2018-12-09 07:53:10,112 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741974_1150{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /mimic/patients/PATIENTS.csv._COPYING_
2018-12-09 07:53:10,355 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741974_1150{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 0
2018-12-09 07:53:10,361 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /mimic/patients/PATIENTS.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1127018581_1
2018-12-09 07:53:10,369 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741960_1136 172.18.0.2:50010 
2018-12-09 07:53:11,057 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741975_1151{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /mimic/transfers/TRANSFERS.csv._COPYING_
2018-12-09 07:53:11,262 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741975_1151{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 0
2018-12-09 07:53:11,267 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /mimic/transfers/TRANSFERS.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_-511488648_1
2018-12-09 07:53:11,281 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741967_1143 172.18.0.2:50010 
2018-12-09 07:53:11,638 INFO BlockStateChange: BLOCK* BlockManager: ask 172.18.0.2:50010 to delete [blk_1073741960_1136, blk_1073741967_1143]
2018-12-09 07:53:12,329 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741976_1152{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /model/noteevents_with_topics/noteevents_with_topics.csv._COPYING_
2018-12-09 07:53:12,523 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741976_1152{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 0
2018-12-09 07:53:12,527 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /model/noteevents_with_topics/noteevents_with_topics.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_67517723_1
2018-12-09 07:53:12,538 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741898_1074 172.18.0.2:50010 
2018-12-09 07:53:13,823 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741977_1153{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /mimic/prescriptions/PRESCRIPTIONS.csv._COPYING_
2018-12-09 07:53:13,978 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741977_1153{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 0
2018-12-09 07:53:13,986 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /mimic/prescriptions/PRESCRIPTIONS.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1417283913_1
2018-12-09 07:53:14,005 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741963_1139 172.18.0.2:50010 
2018-12-09 07:53:14,640 INFO BlockStateChange: BLOCK* BlockManager: ask 172.18.0.2:50010 to delete [blk_1073741898_1074, blk_1073741963_1139]
2018-12-09 07:53:15,066 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741978_1154{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /ccs/ccs_dx_map/ccs_dx_map.csv._COPYING_
2018-12-09 07:53:15,280 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741978_1154{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 0
2018-12-09 07:53:15,283 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /ccs/ccs_dx_map/ccs_dx_map.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_117507149_1
2018-12-09 07:53:15,310 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741970_1146 172.18.0.2:50010 
2018-12-09 07:53:16,669 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741979_1155{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /model/admissions_ccs_ohe/admissions_ccs_ohe.csv._COPYING_
2018-12-09 07:53:16,962 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741979_1155{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 0
2018-12-09 07:53:16,966 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /model/admissions_ccs_ohe/admissions_ccs_ohe.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_759434921_1
2018-12-09 07:53:16,975 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741899_1075 172.18.0.2:50010 
2018-12-09 07:53:17,641 INFO BlockStateChange: BLOCK* BlockManager: ask 172.18.0.2:50010 to delete [blk_1073741970_1146, blk_1073741899_1075]
2018-12-09 07:53:18,225 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741980_1156{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /mimic/procedureevents_mv/PROCEDUREEVENTS_MV.csv._COPYING_
2018-12-09 07:53:18,436 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741980_1156{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 0
2018-12-09 07:53:18,455 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /mimic/procedureevents_mv/PROCEDUREEVENTS_MV.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_881805603_1
2018-12-09 07:53:18,463 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741966_1142 172.18.0.2:50010 
2018-12-09 07:53:19,239 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741981_1157{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /ccs/ccs_proc_map/ccs_proc_map.csv._COPYING_
2018-12-09 07:53:19,382 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741981_1157{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 0
2018-12-09 07:53:19,387 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /ccs/ccs_proc_map/ccs_proc_map.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_964388020_1
2018-12-09 07:53:19,395 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741973_1149 172.18.0.2:50010 
2018-12-09 07:53:20,450 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 1231 Total time for transactions(ms): 80 Number of transactions batched in Syncs: 10 Number of syncs: 898 SyncTimes(ms): 4527 
2018-12-09 07:53:20,539 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741982_1158{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /model/admissions_topic_scores/admissions_topic_scores.csv._COPYING_
2018-12-09 07:53:20,642 INFO BlockStateChange: BLOCK* BlockManager: ask 172.18.0.2:50010 to delete [blk_1073741973_1149, blk_1073741966_1142]
2018-12-09 07:53:20,751 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741982_1158{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 0
2018-12-09 07:53:20,757 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /model/admissions_topic_scores/admissions_topic_scores.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_-511203432_1
2018-12-09 07:53:20,766 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741900_1076 172.18.0.2:50010 
2018-12-09 07:53:21,890 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741983_1159{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /mimic/procedures_icd/PROCEDURES_ICD.csv._COPYING_
2018-12-09 07:53:22,063 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741983_1159{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 0
2018-12-09 07:53:22,069 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /mimic/procedures_icd/PROCEDURES_ICD.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_932295517_1
2018-12-09 07:53:22,081 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741969_1145 172.18.0.2:50010 
2018-12-09 07:53:22,712 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741984_1160{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /model/noteevents_with_topics/noteevents_with_topics.csv._COPYING_
2018-12-09 07:53:22,885 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741984_1160{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 0
2018-12-09 07:53:22,891 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /model/noteevents_with_topics/noteevents_with_topics.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_1596190010_1
2018-12-09 07:53:22,902 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741976_1152 172.18.0.2:50010 
2018-12-09 07:53:23,643 INFO BlockStateChange: BLOCK* BlockManager: ask 172.18.0.2:50010 to delete [blk_1073741969_1145, blk_1073741976_1152, blk_1073741900_1076]
2018-12-09 07:53:25,183 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741985_1161{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /mimic/services/SERVICES.csv._COPYING_
2018-12-09 07:53:25,344 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741985_1161{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 0
2018-12-09 07:53:25,349 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /mimic/services/SERVICES.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1944583378_1
2018-12-09 07:53:25,358 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741972_1148 172.18.0.2:50010 
2018-12-09 07:53:26,015 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741986_1162{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /model/admissions_ccs_ohe/admissions_ccs_ohe.csv._COPYING_
2018-12-09 07:53:26,180 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741986_1162{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 0
2018-12-09 07:53:26,185 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /model/admissions_ccs_ohe/admissions_ccs_ohe.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_583947798_1
2018-12-09 07:53:26,194 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741979_1155 172.18.0.2:50010 
2018-12-09 07:53:26,650 INFO BlockStateChange: BLOCK* BlockManager: ask 172.18.0.2:50010 to delete [blk_1073741972_1148, blk_1073741979_1155]
2018-12-09 07:53:29,196 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741987_1163{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /mimic/transfers/TRANSFERS.csv._COPYING_
2018-12-09 07:53:29,403 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* blk_1073741987_1163{UCState=COMMITTED, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} is not COMPLETE (ucState = COMMITTED, replication# = 0 <  minimum = 1) in file /mimic/transfers/TRANSFERS.csv._COPYING_
2018-12-09 07:53:29,404 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741987_1163{UCState=COMMITTED, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 9239
2018-12-09 07:53:29,811 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /mimic/transfers/TRANSFERS.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_1627101357_1
2018-12-09 07:53:29,817 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741975_1151 172.18.0.2:50010 
2018-12-09 07:53:29,974 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741988_1164{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /model/admissions_topic_scores/admissions_topic_scores.csv._COPYING_
2018-12-09 07:53:30,117 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* blk_1073741988_1164{UCState=COMMITTED, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} is not COMPLETE (ucState = COMMITTED, replication# = 0 <  minimum = 1) in file /model/admissions_topic_scores/admissions_topic_scores.csv._COPYING_
2018-12-09 07:53:30,118 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741988_1164{UCState=COMMITTED, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 44316
2018-12-09 07:53:30,523 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /model/admissions_topic_scores/admissions_topic_scores.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_-824701474_1
2018-12-09 07:53:30,529 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741982_1158 172.18.0.2:50010 
2018-12-09 07:53:32,617 INFO BlockStateChange: BLOCK* BlockManager: ask 172.18.0.2:50010 to delete [blk_1073741975_1151, blk_1073741982_1158]
2018-12-09 07:53:32,948 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741989_1165{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /ccs/ccs_dx_map/ccs_dx_map.csv._COPYING_
2018-12-09 07:53:33,113 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741989_1165{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 0
2018-12-09 07:53:33,117 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /ccs/ccs_dx_map/ccs_dx_map.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_-548065974_1
2018-12-09 07:53:33,133 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741978_1154 172.18.0.2:50010 
2018-12-09 07:53:35,618 INFO BlockStateChange: BLOCK* BlockManager: ask 172.18.0.2:50010 to delete [blk_1073741978_1154]
2018-12-09 07:53:36,184 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741990_1166{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /ccs/ccs_proc_map/ccs_proc_map.csv._COPYING_
2018-12-09 07:53:36,346 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741990_1166{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 0
2018-12-09 07:53:36,352 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /ccs/ccs_proc_map/ccs_proc_map.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1728117489_1
2018-12-09 07:53:36,361 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741981_1157 172.18.0.2:50010 
2018-12-09 07:53:38,619 INFO BlockStateChange: BLOCK* BlockManager: ask 172.18.0.2:50010 to delete [blk_1073741981_1157]
2018-12-09 07:53:39,487 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741991_1167{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /model/noteevents_with_topics/noteevents_with_topics.csv._COPYING_
2018-12-09 07:53:39,640 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741991_1167{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 0
2018-12-09 07:53:39,644 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /model/noteevents_with_topics/noteevents_with_topics.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_397342158_1
2018-12-09 07:53:39,653 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741984_1160 172.18.0.2:50010 
2018-12-09 07:53:41,621 INFO BlockStateChange: BLOCK* BlockManager: ask 172.18.0.2:50010 to delete [blk_1073741984_1160]
2018-12-09 07:53:42,906 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741992_1168{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /model/admissions_ccs_ohe/admissions_ccs_ohe.csv._COPYING_
2018-12-09 07:53:43,088 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741992_1168{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 0
2018-12-09 07:53:43,093 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /model/admissions_ccs_ohe/admissions_ccs_ohe.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_2146389843_1
2018-12-09 07:53:43,100 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741986_1162 172.18.0.2:50010 
2018-12-09 07:53:44,623 INFO BlockStateChange: BLOCK* BlockManager: ask 172.18.0.2:50010 to delete [blk_1073741986_1162]
2018-12-09 07:53:45,995 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741993_1169{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} for /model/admissions_topic_scores/admissions_topic_scores.csv._COPYING_
2018-12-09 07:53:46,140 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.2:50010 is added to blk_1073741993_1169{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5:NORMAL:172.18.0.2:50010|RBW]]} size 0
2018-12-09 07:53:46,143 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /model/admissions_topic_scores/admissions_topic_scores.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_889520537_1
2018-12-09 07:53:46,151 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741988_1164 172.18.0.2:50010 
2018-12-09 07:53:47,625 INFO BlockStateChange: BLOCK* BlockManager: ask 172.18.0.2:50010 to delete [blk_1073741988_1164]
2018-12-09 07:56:50,054 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 1315 Total time for transactions(ms): 84 Number of transactions batched in Syncs: 12 Number of syncs: 958 SyncTimes(ms): 4623 
2018-12-09 07:58:06,382 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 1320 Total time for transactions(ms): 84 Number of transactions batched in Syncs: 12 Number of syncs: 963 SyncTimes(ms): 4629 
2018-12-09 13:44:02,118 INFO BlockStateChange: BLOCK* processReport: from storage DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5 node DatanodeRegistration(172.18.0.2:50010, datanodeUuid=47ecd31e-43cd-4989-84ba-314b1664d0de, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-747ab8c6-1ec4-46a0-9dee-c8151846aca5;nsid=199960936;c=0), blocks: 43, hasStaleStorage: false, processing time: 5 msecs
2018-12-09 19:43:34,148 INFO BlockStateChange: BLOCK* processReport: from storage DS-cf0e0e6e-c373-4082-b7c3-aa84651cc8c5 node DatanodeRegistration(172.18.0.2:50010, datanodeUuid=47ecd31e-43cd-4989-84ba-314b1664d0de, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-747ab8c6-1ec4-46a0-9dee-c8151846aca5;nsid=199960936;c=0), blocks: 43, hasStaleStorage: false, processing time: 23 msecs
2018-12-09 22:05:52,554 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 1327 Total time for transactions(ms): 86 Number of transactions batched in Syncs: 12 Number of syncs: 970 SyncTimes(ms): 4635 
2018-12-09 22:38:12,451 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 1330 Total time for transactions(ms): 88 Number of transactions batched in Syncs: 12 Number of syncs: 973 SyncTimes(ms): 4642 
2018-12-09 22:51:41,686 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1005ms
No GCs detected
2018-12-09 23:14:57,340 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NameNode
STARTUP_MSG:   user = hdfs
STARTUP_MSG:   host = bootcamp.local/172.18.0.2
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.8.4
STARTUP_MSG:   classpath = /etc/hadoop/conf:/usr/lib/hadoop/lib/httpcore-4.4.4.jar:/usr/lib/hadoop/lib/asm-3.2.jar:/usr/lib/hadoop/lib/jackson-jaxrs-1.9.13.jar:/usr/lib/hadoop/lib/api-asn1-api-1.0.0-M20.jar:/usr/lib/hadoop/lib/jersey-json-1.9.jar:/usr/lib/hadoop/lib/gson-2.2.4.jar:/usr/lib/hadoop/lib/commons-net-3.1.jar:/usr/lib/hadoop/lib/commons-digester-1.8.jar:/usr/lib/hadoop/lib/guava-11.0.2.jar:/usr/lib/hadoop/lib/api-util-1.0.0-M20.jar:/usr/lib/hadoop/lib/jets3t-0.9.0.jar:/usr/lib/hadoop/lib/snappy-java-1.0.4.1.jar:/usr/lib/hadoop/lib/commons-compress-1.4.1.jar:/usr/lib/hadoop/lib/activation-1.1.jar:/usr/lib/hadoop/lib/slf4j-log4j12-1.7.10.jar:/usr/lib/hadoop/lib/curator-framework-2.7.1.jar:/usr/lib/hadoop/lib/jackson-core-asl-1.9.13.jar:/usr/lib/hadoop/lib/json-smart-1.3.1.jar:/usr/lib/hadoop/lib/commons-beanutils-1.7.0.jar:/usr/lib/hadoop/lib/curator-client-2.7.1.jar:/usr/lib/hadoop/lib/jsr305-3.0.0.jar:/usr/lib/hadoop/lib/avro-1.7.4.jar:/usr/lib/hadoop/lib/jackson-xc-1.9.13.jar:/usr/lib/hadoop/lib/jcip-annotations-1.0-1.jar:/usr/lib/hadoop/lib/commons-configuration-1.6.jar:/usr/lib/hadoop/lib/commons-math3-3.1.1.jar:/usr/lib/hadoop/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/lib/hadoop/lib/jaxb-api-2.2.2.jar:/usr/lib/hadoop/lib/netty-3.6.2.Final.jar:/usr/lib/hadoop/lib/curator-recipes-2.7.1.jar:/usr/lib/hadoop/lib/mockito-all-1.8.5.jar:/usr/lib/hadoop/lib/commons-codec-1.4.jar:/usr/lib/hadoop/lib/jettison-1.1.jar:/usr/lib/hadoop/lib/java-xmlbuilder-0.4.jar:/usr/lib/hadoop/lib/xz-1.0.jar:/usr/lib/hadoop/lib/commons-logging-1.1.3.jar:/usr/lib/hadoop/lib/log4j-1.2.17.jar:/usr/lib/hadoop/lib/zookeeper-3.4.6.jar:/usr/lib/hadoop/lib/commons-lang-2.6.jar:/usr/lib/hadoop/lib/hamcrest-core-1.3.jar:/usr/lib/hadoop/lib/commons-cli-1.2.jar:/usr/lib/hadoop/lib/commons-io-2.4.jar:/usr/lib/hadoop/lib/apacheds-i18n-2.0.0-M15.jar:/usr/lib/hadoop/lib/jetty-util-6.1.26.jar:/usr/lib/hadoop/lib/jetty-sslengine-6.1.26.jar:/usr/lib/hadoop/lib/jackson-mapper-asl-1.9.13.jar:/usr/lib/hadoop/lib/htrace-core4-4.0.1-incubating.jar:/usr/lib/hadoop/lib/httpclient-4.5.2.jar:/usr/lib/hadoop/lib/jsch-0.1.54.jar:/usr/lib/hadoop/lib/paranamer-2.3.jar:/usr/lib/hadoop/lib/xmlenc-0.52.jar:/usr/lib/hadoop/lib/nimbus-jose-jwt-4.41.1.jar:/usr/lib/hadoop/lib/jaxb-impl-2.2.3-1.jar:/usr/lib/hadoop/lib/commons-beanutils-core-1.8.0.jar:/usr/lib/hadoop/lib/jersey-server-1.9.jar:/usr/lib/hadoop/lib/slf4j-api-1.7.10.jar:/usr/lib/hadoop/lib/jsp-api-2.1.jar:/usr/lib/hadoop/lib/jetty-6.1.26.jar:/usr/lib/hadoop/lib/junit-4.11.jar:/usr/lib/hadoop/lib/servlet-api-2.5.jar:/usr/lib/hadoop/lib/protobuf-java-2.5.0.jar:/usr/lib/hadoop/lib/jersey-core-1.9.jar:/usr/lib/hadoop/lib/stax-api-1.0-2.jar:/usr/lib/hadoop/lib/commons-collections-3.2.2.jar:/usr/lib/hadoop/.//hadoop-common-2.8.4.jar:/usr/lib/hadoop/.//hadoop-nfs.jar:/usr/lib/hadoop/.//hadoop-common.jar:/usr/lib/hadoop/.//hadoop-nfs-2.8.4.jar:/usr/lib/hadoop/.//hadoop-auth.jar:/usr/lib/hadoop/.//hadoop-common-2.8.4-tests.jar:/usr/lib/hadoop/.//hadoop-annotations.jar:/usr/lib/hadoop/.//hadoop-auth-2.8.4.jar:/usr/lib/hadoop/.//hadoop-annotations-2.8.4.jar:/usr/lib/hadoop-hdfs/./:/usr/lib/hadoop-hdfs/lib/asm-3.2.jar:/usr/lib/hadoop-hdfs/lib/xercesImpl-2.9.1.jar:/usr/lib/hadoop-hdfs/lib/guava-11.0.2.jar:/usr/lib/hadoop-hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/lib/hadoop-hdfs/lib/jsr305-3.0.0.jar:/usr/lib/hadoop-hdfs/lib/leveldbjni-all-1.8.jar:/usr/lib/hadoop-hdfs/lib/netty-3.6.2.Final.jar:/usr/lib/hadoop-hdfs/lib/netty-all-4.0.23.Final.jar:/usr/lib/hadoop-hdfs/lib/commons-codec-1.4.jar:/usr/lib/hadoop-hdfs/lib/xml-apis-1.3.04.jar:/usr/lib/hadoop-hdfs/lib/okhttp-2.4.0.jar:/usr/lib/hadoop-hdfs/lib/commons-logging-1.1.3.jar:/usr/lib/hadoop-hdfs/lib/log4j-1.2.17.jar:/usr/lib/hadoop-hdfs/lib/commons-lang-2.6.jar:/usr/lib/hadoop-hdfs/lib/commons-cli-1.2.jar:/usr/lib/hadoop-hdfs/lib/commons-io-2.4.jar:/usr/lib/hadoop-hdfs/lib/jetty-util-6.1.26.jar:/usr/lib/hadoop-hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/lib/hadoop-hdfs/lib/htrace-core4-4.0.1-incubating.jar:/usr/lib/hadoop-hdfs/lib/xmlenc-0.52.jar:/usr/lib/hadoop-hdfs/lib/jersey-server-1.9.jar:/usr/lib/hadoop-hdfs/lib/jetty-6.1.26.jar:/usr/lib/hadoop-hdfs/lib/okio-1.4.0.jar:/usr/lib/hadoop-hdfs/lib/commons-daemon-1.0.13.jar:/usr/lib/hadoop-hdfs/lib/servlet-api-2.5.jar:/usr/lib/hadoop-hdfs/lib/protobuf-java-2.5.0.jar:/usr/lib/hadoop-hdfs/lib/jersey-core-1.9.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs-nfs.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs-native-client.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs-2.8.4.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs-native-client-2.8.4-tests.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs-nfs-2.8.4.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs-2.8.4-tests.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs-client-2.8.4-tests.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs-client-2.8.4.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs-native-client-2.8.4.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs-client.jar:/usr/lib/hadoop-yarn/lib/asm-3.2.jar:/usr/lib/hadoop-yarn/lib/jackson-jaxrs-1.9.13.jar:/usr/lib/hadoop-yarn/lib/jersey-json-1.9.jar:/usr/lib/hadoop-yarn/lib/jersey-client-1.9.jar:/usr/lib/hadoop-yarn/lib/guava-11.0.2.jar:/usr/lib/hadoop-yarn/lib/jersey-guice-1.9.jar:/usr/lib/hadoop-yarn/lib/commons-compress-1.4.1.jar:/usr/lib/hadoop-yarn/lib/activation-1.1.jar:/usr/lib/hadoop-yarn/lib/guice-servlet-3.0.jar:/usr/lib/hadoop-yarn/lib/zookeeper-3.4.6-tests.jar:/usr/lib/hadoop-yarn/lib/jackson-core-asl-1.9.13.jar:/usr/lib/hadoop-yarn/lib/curator-client-2.7.1.jar:/usr/lib/hadoop-yarn/lib/jsr305-3.0.0.jar:/usr/lib/hadoop-yarn/lib/jackson-xc-1.9.13.jar:/usr/lib/hadoop-yarn/lib/leveldbjni-all-1.8.jar:/usr/lib/hadoop-yarn/lib/jaxb-api-2.2.2.jar:/usr/lib/hadoop-yarn/lib/netty-3.6.2.Final.jar:/usr/lib/hadoop-yarn/lib/java-util-1.9.0.jar:/usr/lib/hadoop-yarn/lib/javax.inject-1.jar:/usr/lib/hadoop-yarn/lib/commons-codec-1.4.jar:/usr/lib/hadoop-yarn/lib/jettison-1.1.jar:/usr/lib/hadoop-yarn/lib/json-io-2.5.1.jar:/usr/lib/hadoop-yarn/lib/guice-3.0.jar:/usr/lib/hadoop-yarn/lib/commons-math-2.2.jar:/usr/lib/hadoop-yarn/lib/xz-1.0.jar:/usr/lib/hadoop-yarn/lib/commons-logging-1.1.3.jar:/usr/lib/hadoop-yarn/lib/log4j-1.2.17.jar:/usr/lib/hadoop-yarn/lib/zookeeper-3.4.6.jar:/usr/lib/hadoop-yarn/lib/commons-lang-2.6.jar:/usr/lib/hadoop-yarn/lib/commons-cli-1.2.jar:/usr/lib/hadoop-yarn/lib/commons-io-2.4.jar:/usr/lib/hadoop-yarn/lib/jetty-util-6.1.26.jar:/usr/lib/hadoop-yarn/lib/jackson-mapper-asl-1.9.13.jar:/usr/lib/hadoop-yarn/lib/javassist-3.18.1-GA.jar:/usr/lib/hadoop-yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/lib/hadoop-yarn/lib/jersey-server-1.9.jar:/usr/lib/hadoop-yarn/lib/aopalliance-1.0.jar:/usr/lib/hadoop-yarn/lib/fst-2.50.jar:/usr/lib/hadoop-yarn/lib/jetty-6.1.26.jar:/usr/lib/hadoop-yarn/lib/servlet-api-2.5.jar:/usr/lib/hadoop-yarn/lib/curator-test-2.7.1.jar:/usr/lib/hadoop-yarn/lib/protobuf-java-2.5.0.jar:/usr/lib/hadoop-yarn/lib/jersey-core-1.9.jar:/usr/lib/hadoop-yarn/lib/stax-api-1.0-2.jar:/usr/lib/hadoop-yarn/lib/commons-collections-3.2.2.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-resourcemanager.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-timeline-pluginstorage.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-registry.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-tests.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-nodemanager-2.8.4.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-common.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-applications-distributedshell.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-client.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-common-2.8.4.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-applications-unmanaged-am-launcher.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-applications-unmanaged-am-launcher-2.8.4.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-tests-2.8.4.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-client-2.8.4.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-web-proxy.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-api.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-timeline-pluginstorage-2.8.4.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-applicationhistoryservice-2.8.4.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-api-2.8.4.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-sharedcachemanager-2.8.4.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-common.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-nodemanager.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-sharedcachemanager.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-resourcemanager-2.8.4.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-common-2.8.4.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-web-proxy-2.8.4.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-registry-2.8.4.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-applicationhistoryservice.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-applications-distributedshell-2.8.4.jar:/usr/lib/hadoop-mapreduce/lib/asm-3.2.jar:/usr/lib/hadoop-mapreduce/lib/jersey-guice-1.9.jar:/usr/lib/hadoop-mapreduce/lib/snappy-java-1.0.4.1.jar:/usr/lib/hadoop-mapreduce/lib/commons-compress-1.4.1.jar:/usr/lib/hadoop-mapreduce/lib/guice-servlet-3.0.jar:/usr/lib/hadoop-mapreduce/lib/jackson-core-asl-1.9.13.jar:/usr/lib/hadoop-mapreduce/lib/avro-1.7.4.jar:/usr/lib/hadoop-mapreduce/lib/leveldbjni-all-1.8.jar:/usr/lib/hadoop-mapreduce/lib/netty-3.6.2.Final.jar:/usr/lib/hadoop-mapreduce/lib/javax.inject-1.jar:/usr/lib/hadoop-mapreduce/lib/guice-3.0.jar:/usr/lib/hadoop-mapreduce/lib/xz-1.0.jar:/usr/lib/hadoop-mapreduce/lib/log4j-1.2.17.jar:/usr/lib/hadoop-mapreduce/lib/hamcrest-core-1.3.jar:/usr/lib/hadoop-mapreduce/lib/commons-io-2.4.jar:/usr/lib/hadoop-mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/usr/lib/hadoop-mapreduce/lib/paranamer-2.3.jar:/usr/lib/hadoop-mapreduce/lib/jersey-server-1.9.jar:/usr/lib/hadoop-mapreduce/lib/aopalliance-1.0.jar:/usr/lib/hadoop-mapreduce/lib/junit-4.11.jar:/usr/lib/hadoop-mapreduce/lib/protobuf-java-2.5.0.jar:/usr/lib/hadoop-mapreduce/lib/jersey-core-1.9.jar:/usr/lib/hadoop-mapreduce/.//jackson-core-2.2.3.jar:/usr/lib/hadoop-mapreduce/.//hadoop-archives-2.8.4.jar:/usr/lib/hadoop-mapreduce/.//metrics-core-3.0.1.jar:/usr/lib/hadoop-mapreduce/.//httpcore-4.4.4.jar:/usr/lib/hadoop-mapreduce/.//asm-3.2.jar:/usr/lib/hadoop-mapreduce/.//hadoop-datajoin-2.8.4.jar:/usr/lib/hadoop-mapreduce/.//jackson-jaxrs-1.9.13.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-shuffle-2.8.4.jar:/usr/lib/hadoop-mapreduce/.//api-asn1-api-1.0.0-M20.jar:/usr/lib/hadoop-mapreduce/.//jersey-json-1.9.jar:/usr/lib/hadoop-mapreduce/.//gson-2.2.4.jar:/usr/lib/hadoop-mapreduce/.//commons-net-3.1.jar:/usr/lib/hadoop-mapreduce/.//commons-digester-1.8.jar:/usr/lib/hadoop-mapreduce/.//guava-11.0.2.jar:/usr/lib/hadoop-mapreduce/.//azure-data-lake-store-sdk-2.2.3.jar:/usr/lib/hadoop-mapreduce/.//api-util-1.0.0-M20.jar:/usr/lib/hadoop-mapreduce/.//hadoop-extras-2.8.4.jar:/usr/lib/hadoop-mapreduce/.//jets3t-0.9.0.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-jobclient-2.8.4-tests.jar:/usr/lib/hadoop-mapreduce/.//snappy-java-1.0.4.1.jar:/usr/lib/hadoop-mapreduce/.//hadoop-gridmix-2.8.4.jar:/usr/lib/hadoop-mapreduce/.//commons-compress-1.4.1.jar:/usr/lib/hadoop-mapreduce/.//activation-1.1.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-examples-2.8.4.jar:/usr/lib/hadoop-mapreduce/.//curator-framework-2.7.1.jar:/usr/lib/hadoop-mapreduce/.//hadoop-archives.jar:/usr/lib/hadoop-mapreduce/.//hadoop-aws.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-app-2.8.4.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-core.jar:/usr/lib/hadoop-mapreduce/.//jackson-core-asl-1.9.13.jar:/usr/lib/hadoop-mapreduce/.//azure-storage-2.2.0.jar:/usr/lib/hadoop-mapreduce/.//hadoop-archive-logs-2.8.4.jar:/usr/lib/hadoop-mapreduce/.//json-smart-1.3.1.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-hs.jar:/usr/lib/hadoop-mapreduce/.//commons-beanutils-1.7.0.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-jobclient-2.8.4.jar:/usr/lib/hadoop-mapreduce/.//curator-client-2.7.1.jar:/usr/lib/hadoop-mapreduce/.//jsr305-3.0.0.jar:/usr/lib/hadoop-mapreduce/.//avro-1.7.4.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-jobclient.jar:/usr/lib/hadoop-mapreduce/.//hadoop-gridmix.jar:/usr/lib/hadoop-mapreduce/.//hadoop-distcp.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-app.jar:/usr/lib/hadoop-mapreduce/.//jackson-xc-1.9.13.jar:/usr/lib/hadoop-mapreduce/.//jcip-annotations-1.0-1.jar:/usr/lib/hadoop-mapreduce/.//commons-configuration-1.6.jar:/usr/lib/hadoop-mapreduce/.//commons-math3-3.1.1.jar:/usr/lib/hadoop-mapreduce/.//apacheds-kerberos-codec-2.0.0-M15.jar:/usr/lib/hadoop-mapreduce/.//hadoop-ant.jar:/usr/lib/hadoop-mapreduce/.//hadoop-auth.jar:/usr/lib/hadoop-mapreduce/.//jaxb-api-2.2.2.jar:/usr/lib/hadoop-mapreduce/.//netty-3.6.2.Final.jar:/usr/lib/hadoop-mapreduce/.//curator-recipes-2.7.1.jar:/usr/lib/hadoop-mapreduce/.//hadoop-azure-2.8.4.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-hs-plugins.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-core-2.8.4.jar:/usr/lib/hadoop-mapreduce/.//hadoop-rumen-2.8.4.jar:/usr/lib/hadoop-mapreduce/.//hadoop-openstack.jar:/usr/lib/hadoop-mapreduce/.//jackson-annotations-2.2.3.jar:/usr/lib/hadoop-mapreduce/.//commons-codec-1.4.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-hs-plugins-2.8.4.jar:/usr/lib/hadoop-mapreduce/.//jettison-1.1.jar:/usr/lib/hadoop-mapreduce/.//commons-httpclient-3.1.jar:/usr/lib/hadoop-mapreduce/.//hadoop-sls.jar:/usr/lib/hadoop-mapreduce/.//hadoop-aws-2.8.4.jar:/usr/lib/hadoop-mapreduce/.//jackson-databind-2.2.3.jar:/usr/lib/hadoop-mapreduce/.//okhttp-2.4.0.jar:/usr/lib/hadoop-mapreduce/.//aws-java-sdk-kms-1.10.6.jar:/usr/lib/hadoop-mapreduce/.//hadoop-streaming-2.8.4.jar:/usr/lib/hadoop-mapreduce/.//hadoop-auth-2.8.4.jar:/usr/lib/hadoop-mapreduce/.//java-xmlbuilder-0.4.jar:/usr/lib/hadoop-mapreduce/.//hadoop-sls-2.8.4.jar:/usr/lib/hadoop-mapreduce/.//xz-1.0.jar:/usr/lib/hadoop-mapreduce/.//hadoop-rumen.jar:/usr/lib/hadoop-mapreduce/.//commons-logging-1.1.3.jar:/usr/lib/hadoop-mapreduce/.//log4j-1.2.17.jar:/usr/lib/hadoop-mapreduce/.//zookeeper-3.4.6.jar:/usr/lib/hadoop-mapreduce/.//hadoop-datajoin.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-common-2.8.4.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-hs-2.8.4.jar:/usr/lib/hadoop-mapreduce/.//hadoop-ant-2.8.4.jar:/usr/lib/hadoop-mapreduce/.//commons-lang-2.6.jar:/usr/lib/hadoop-mapreduce/.//aws-java-sdk-core-1.10.6.jar:/usr/lib/hadoop-mapreduce/.//commons-lang3-3.3.2.jar:/usr/lib/hadoop-mapreduce/.//commons-cli-1.2.jar:/usr/lib/hadoop-mapreduce/.//commons-io-2.4.jar:/usr/lib/hadoop-mapreduce/.//apacheds-i18n-2.0.0-M15.jar:/usr/lib/hadoop-mapreduce/.//jetty-util-6.1.26.jar:/usr/lib/hadoop-mapreduce/.//jetty-sslengine-6.1.26.jar:/usr/lib/hadoop-mapreduce/.//jackson-mapper-asl-1.9.13.jar:/usr/lib/hadoop-mapreduce/.//htrace-core4-4.0.1-incubating.jar:/usr/lib/hadoop-mapreduce/.//httpclient-4.5.2.jar:/usr/lib/hadoop-mapreduce/.//hadoop-openstack-2.8.4.jar:/usr/lib/hadoop-mapreduce/.//hadoop-azure-datalake.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-common.jar:/usr/lib/hadoop-mapreduce/.//jsch-0.1.54.jar:/usr/lib/hadoop-mapreduce/.//paranamer-2.3.jar:/usr/lib/hadoop-mapreduce/.//hadoop-extras.jar:/usr/lib/hadoop-mapreduce/.//xmlenc-0.52.jar:/usr/lib/hadoop-mapreduce/.//nimbus-jose-jwt-4.41.1.jar:/usr/lib/hadoop-mapreduce/.//hadoop-azure-datalake-2.8.4.jar:/usr/lib/hadoop-mapreduce/.//jaxb-impl-2.2.3-1.jar:/usr/lib/hadoop-mapreduce/.//commons-beanutils-core-1.8.0.jar:/usr/lib/hadoop-mapreduce/.//jersey-server-1.9.jar:/usr/lib/hadoop-mapreduce/.//aws-java-sdk-s3-1.10.6.jar:/usr/lib/hadoop-mapreduce/.//hadoop-archive-logs.jar:/usr/lib/hadoop-mapreduce/.//jsp-api-2.1.jar:/usr/lib/hadoop-mapreduce/.//jetty-6.1.26.jar:/usr/lib/hadoop-mapreduce/.//okio-1.4.0.jar:/usr/lib/hadoop-mapreduce/.//joda-time-2.9.4.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-examples.jar:/usr/lib/hadoop-mapreduce/.//hadoop-azure.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-shuffle.jar:/usr/lib/hadoop-mapreduce/.//hadoop-distcp-2.8.4.jar:/usr/lib/hadoop-mapreduce/.//hadoop-streaming.jar:/usr/lib/hadoop-mapreduce/.//servlet-api-2.5.jar:/usr/lib/hadoop-mapreduce/.//protobuf-java-2.5.0.jar:/usr/lib/hadoop-mapreduce/.//jersey-core-1.9.jar:/usr/lib/hadoop-mapreduce/.//stax-api-1.0-2.jar:/usr/lib/hadoop-mapreduce/.//commons-collections-3.2.2.jar:/usr/lib/hadoop/contrib/capacity-scheduler/*.jar:/usr/lib/hadoop/contrib/capacity-scheduler/*.jar:/usr/lib/hadoop/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/bigtop.git -r 7f701affa76db42bf59f5784bca901e11e9f9deb; compiled by 'jenkins' on 2018-10-23T02:15Z
STARTUP_MSG:   java = 1.8.0_191
************************************************************/
2018-12-09 23:14:57,352 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2018-12-09 23:14:57,362 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: createNameNode []
2018-12-09 23:14:57,776 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2018-12-09 23:14:57,881 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2018-12-09 23:14:57,882 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NameNode metrics system started
2018-12-09 23:14:57,902 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: fs.defaultFS is hdfs://bootcamp.local:9000
2018-12-09 23:14:57,907 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Clients are to use bootcamp.local:9000 to access this namenode/service.
2018-12-09 23:14:58,175 INFO org.apache.hadoop.util.JvmPauseMonitor: Starting JVM pause monitor
2018-12-09 23:14:58,197 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for hdfs at: http://0.0.0.0:50070
2018-12-09 23:14:58,259 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2018-12-09 23:14:58,270 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2018-12-09 23:14:58,290 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.namenode is not defined
2018-12-09 23:14:58,300 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2018-12-09 23:14:58,304 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2018-12-09 23:14:58,304 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2018-12-09 23:14:58,305 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2018-12-09 23:14:58,443 INFO org.apache.hadoop.http.HttpServer2: Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2018-12-09 23:14:58,445 INFO org.apache.hadoop.http.HttpServer2: addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2018-12-09 23:14:58,464 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50070
2018-12-09 23:14:58,464 INFO org.mortbay.log: jetty-6.1.26
2018-12-09 23:14:58,630 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:50070
2018-12-09 23:14:58,665 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one image storage directory (dfs.namenode.name.dir) configured. Beware of data loss due to lack of redundant storage directories!
2018-12-09 23:14:58,665 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one namespace edits storage directory (dfs.namenode.edits.dir) configured. Beware of data loss due to lack of redundant storage directories!
2018-12-09 23:14:58,745 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Edit logging is async:true
2018-12-09 23:14:58,757 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: KeyProvider: null
2018-12-09 23:14:58,759 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair: true
2018-12-09 23:14:58,762 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Detailed lock hold time metrics enabled: false
2018-12-09 23:14:58,830 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2018-12-09 23:14:58,831 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2018-12-09 23:14:58,833 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2018-12-09 23:14:58,835 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2018 Dec 09 23:14:58
2018-12-09 23:14:58,839 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2018-12-09 23:14:58,839 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2018-12-09 23:14:58,845 INFO org.apache.hadoop.util.GSet: 2.0% max memory 889 MB = 17.8 MB
2018-12-09 23:14:58,845 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2018-12-09 23:14:58,863 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2018-12-09 23:14:58,866 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 1
2018-12-09 23:14:58,867 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2018-12-09 23:14:58,868 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2018-12-09 23:14:58,868 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2018-12-09 23:14:58,869 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2018-12-09 23:14:58,869 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2018-12-09 23:14:58,870 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2018-12-09 23:14:58,881 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = hdfs (auth:SIMPLE)
2018-12-09 23:14:58,882 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2018-12-09 23:14:58,883 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2018-12-09 23:14:58,883 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2018-12-09 23:14:58,886 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2018-12-09 23:14:58,990 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2018-12-09 23:14:58,991 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2018-12-09 23:14:58,992 INFO org.apache.hadoop.util.GSet: 1.0% max memory 889 MB = 8.9 MB
2018-12-09 23:14:58,993 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2018-12-09 23:14:58,994 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: ACLs enabled? false
2018-12-09 23:14:58,995 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: XAttrs enabled? true
2018-12-09 23:14:58,995 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occurring more than 10 times
2018-12-09 23:14:59,082 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2018-12-09 23:14:59,083 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2018-12-09 23:14:59,084 INFO org.apache.hadoop.util.GSet: 0.25% max memory 889 MB = 2.2 MB
2018-12-09 23:14:59,084 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2018-12-09 23:14:59,086 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2018-12-09 23:14:59,087 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2018-12-09 23:14:59,088 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2018-12-09 23:14:59,094 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.window.num.buckets = 10
2018-12-09 23:14:59,094 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.num.users = 10
2018-12-09 23:14:59,095 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2018-12-09 23:14:59,100 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache on namenode is enabled
2018-12-09 23:14:59,101 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2018-12-09 23:14:59,103 INFO org.apache.hadoop.util.GSet: Computing capacity for map NameNodeRetryCache
2018-12-09 23:14:59,104 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2018-12-09 23:14:59,104 INFO org.apache.hadoop.util.GSet: 0.029999999329447746% max memory 889 MB = 273.1 KB
2018-12-09 23:14:59,105 INFO org.apache.hadoop.util.GSet: capacity      = 2^15 = 32768 entries
2018-12-09 23:14:59,121 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /data/name/in_use.lock acquired by nodename 750@bootcamp.local
2018-12-09 23:14:59,142 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Recovering unfinalized segments in /data/name/current
2018-12-09 23:14:59,176 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /data/name/current/edits_inprogress_0000000000000000001 -> /data/name/current/edits_0000000000000000001-0000000000000000014
2018-12-09 23:14:59,233 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Planning to load image: FSImageFile(file=/data/name/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2018-12-09 23:14:59,274 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Loading 1 INodes.
2018-12-09 23:14:59,301 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Loaded FSImage in 0 seconds.
2018-12-09 23:14:59,302 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 0 from /data/name/current/fsimage_0000000000000000000
2018-12-09 23:14:59,303 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@662f5666 expecting start txid #1
2018-12-09 23:14:59,304 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /data/name/current/edits_0000000000000000001-0000000000000000014
2018-12-09 23:14:59,306 INFO org.apache.hadoop.hdfs.server.namenode.EditLogInputStream: Fast-forwarding stream '/data/name/current/edits_0000000000000000001-0000000000000000014' to transaction ID 1
2018-12-09 23:14:59,346 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /data/name/current/edits_0000000000000000001-0000000000000000014 of size 1048576 edits # 14 loaded in 0 seconds
2018-12-09 23:14:59,347 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2018-12-09 23:14:59,348 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 15
2018-12-09 23:14:59,465 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2018-12-09 23:14:59,465 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Finished loading FSImage in 356 msecs
2018-12-09 23:14:59,625 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: RPC server is binding to bootcamp.local:9000
2018-12-09 23:14:59,633 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2018-12-09 23:14:59,646 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 9000
2018-12-09 23:14:59,705 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Registered FSNamesystemState MBean
2018-12-09 23:14:59,714 INFO org.apache.hadoop.hdfs.server.namenode.LeaseManager: Number of blocks under construction: 0
2018-12-09 23:14:59,715 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: initializing replication queues
2018-12-09 23:14:59,716 INFO org.apache.hadoop.hdfs.StateChange: STATE* Leaving safe mode after 0 secs
2018-12-09 23:14:59,716 INFO org.apache.hadoop.hdfs.StateChange: STATE* Network topology has 0 racks and 0 datanodes
2018-12-09 23:14:59,717 INFO org.apache.hadoop.hdfs.StateChange: STATE* UnderReplicatedBlocks has 0 blocks
2018-12-09 23:14:59,728 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Total number of blocks            = 0
2018-12-09 23:14:59,728 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of invalid blocks          = 0
2018-12-09 23:14:59,729 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of under-replicated blocks = 0
2018-12-09 23:14:59,729 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of  over-replicated blocks = 0
2018-12-09 23:14:59,736 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of blocks being written    = 0
2018-12-09 23:14:59,737 INFO org.apache.hadoop.hdfs.StateChange: STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 21 msec
2018-12-09 23:14:59,763 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2018-12-09 23:14:59,764 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 9000: starting
2018-12-09 23:14:59,767 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: NameNode RPC up at: bootcamp.local/172.18.0.2:9000
2018-12-09 23:14:59,773 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Starting services required for active state
2018-12-09 23:14:59,774 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Initializing quota with 4 thread(s)
2018-12-09 23:14:59,780 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Quota initialization completed in 5 milliseconds
name space=8
storage space=0
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0
2018-12-09 23:14:59,784 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Starting CacheReplicationMonitor with interval 30000 milliseconds
2018-12-09 23:15:08,697 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(172.18.0.2:50010, datanodeUuid=095e4930-ee10-452b-bba9-ea1d76f04efc, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-57;cid=CID-bb9b1db8-7c08-4376-9eaf-2b0aa96d167e;nsid=212088389;c=1544396815977) storage 095e4930-ee10-452b-bba9-ea1d76f04efc
2018-12-09 23:15:08,698 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/172.18.0.2:50010
2018-12-09 23:15:08,699 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockReportLeaseManager: Registered DN 095e4930-ee10-452b-bba9-ea1d76f04efc (172.18.0.2:50010).
2018-12-09 23:15:08,771 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Adding new storage ID DS-f541c8b5-4c54-4986-a55f-c745d8545f6b for DN 172.18.0.2:50010
2018-12-09 23:15:08,810 INFO BlockStateChange: BLOCK* processReport 0x777eb1190ac402d: Processing first storage report for DS-f541c8b5-4c54-4986-a55f-c745d8545f6b from datanode 095e4930-ee10-452b-bba9-ea1d76f04efc
2018-12-09 23:15:08,812 INFO BlockStateChange: BLOCK* processReport 0x777eb1190ac402d: from storage DS-f541c8b5-4c54-4986-a55f-c745d8545f6b node DatanodeRegistration(172.18.0.2:50010, datanodeUuid=095e4930-ee10-452b-bba9-ea1d76f04efc, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-57;cid=CID-bb9b1db8-7c08-4376-9eaf-2b0aa96d167e;nsid=212088389;c=1544396815977), blocks: 0, hasStaleStorage: false, processing time: 2 msecs, invalidatedBlocks: 0
2018-12-09 23:15:44,752 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741825_1001, replicas=172.18.0.2:50010 for /app/hbase/.tmp/hbase.version
2018-12-09 23:15:45,362 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* blk_1073741825_1001 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /app/hbase/.tmp/hbase.version
2018-12-09 23:15:45,785 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /app/hbase/.tmp/hbase.version is closed by DFSClient_NONMAPREDUCE_-251611999_1
2018-12-09 23:15:45,873 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741826_1002, replicas=172.18.0.2:50010 for /app/hbase/.tmp/hbase.id
2018-12-09 23:15:45,947 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /app/hbase/.tmp/hbase.id is closed by DFSClient_NONMAPREDUCE_-251611999_1
2018-12-09 23:15:46,343 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741827_1003, replicas=172.18.0.2:50010 for /app/hbase/data/hbase/meta/1588230740/.regioninfo
2018-12-09 23:15:46,407 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* blk_1073741827_1003 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /app/hbase/data/hbase/meta/1588230740/.regioninfo
2018-12-09 23:15:46,814 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /app/hbase/data/hbase/meta/1588230740/.regioninfo is closed by DFSClient_NONMAPREDUCE_-251611999_1
2018-12-09 23:15:47,105 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /app/hbase/data/hbase/meta/1588230740/recovered.edits/2.seqid is closed by DFSClient_NONMAPREDUCE_-251611999_1
2018-12-09 23:15:47,156 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741828_1004, replicas=172.18.0.2:50010 for /app/hbase/data/hbase/meta/.tmp/.tableinfo.0000000001
2018-12-09 23:15:47,192 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /app/hbase/data/hbase/meta/.tmp/.tableinfo.0000000001 is closed by DFSClient_NONMAPREDUCE_-251611999_1
2018-12-09 23:15:52,146 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741829_1005, replicas=172.18.0.2:50010 for /app/hbase/WALs/bootcamp.local,16020,1544397335818/bootcamp.local%2C16020%2C1544397335818.1544397351865
2018-12-09 23:15:52,304 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* fsync: /app/hbase/WALs/bootcamp.local,16020,1544397335818/bootcamp.local%2C16020%2C1544397335818.1544397351865 for DFSClient_NONMAPREDUCE_-357163669_13
2018-12-09 23:15:53,403 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741830_1006, replicas=172.18.0.2:50010 for /app/hbase/WALs/bootcamp.local,16020,1544397335818/bootcamp.local%2C16020%2C1544397335818.meta.1544397353367.meta
2018-12-09 23:15:53,449 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* fsync: /app/hbase/WALs/bootcamp.local,16020,1544397335818/bootcamp.local%2C16020%2C1544397335818.meta.1544397353367.meta for DFSClient_NONMAPREDUCE_-357163669_13
2018-12-09 23:15:54,060 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /app/hbase/data/hbase/meta/1588230740/recovered.edits/3.seqid is closed by DFSClient_NONMAPREDUCE_-357163669_13
2018-12-09 23:15:54,921 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741831_1007, replicas=172.18.0.2:50010 for /app/hbase/MasterProcWALs/state-00000000000000000001.log
2018-12-09 23:15:54,973 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* fsync: /app/hbase/MasterProcWALs/state-00000000000000000001.log for DFSClient_NONMAPREDUCE_-251611999_1
2018-12-09 23:15:55,242 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741832_1008, replicas=172.18.0.2:50010 for /app/hbase/.tmp/data/hbase/namespace/.tmp/.tableinfo.0000000001
2018-12-09 23:15:55,272 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /app/hbase/.tmp/data/hbase/namespace/.tmp/.tableinfo.0000000001 is closed by DFSClient_NONMAPREDUCE_-251611999_1
2018-12-09 23:15:55,303 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741833_1009, replicas=172.18.0.2:50010 for /app/hbase/.tmp/data/hbase/namespace/31204b170e968aadad88a1edfe27ef8f/.regioninfo
2018-12-09 23:15:55,327 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /app/hbase/.tmp/data/hbase/namespace/31204b170e968aadad88a1edfe27ef8f/.regioninfo is closed by DFSClient_NONMAPREDUCE_-251611999_1
2018-12-09 23:15:56,072 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /app/hbase/data/hbase/namespace/31204b170e968aadad88a1edfe27ef8f/recovered.edits/2.seqid is closed by DFSClient_NONMAPREDUCE_-357163669_13
2018-12-09 23:16:18,015 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 90 Total time for transactions(ms): 20 Number of transactions batched in Syncs: 31 Number of syncs: 73 SyncTimes(ms): 174 
2018-12-09 23:16:18,030 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /app/hbase/MasterProcWALs/state-00000000000000000001.log is closed by DFSClient_NONMAPREDUCE_-251611999_1
2018-12-09 23:21:28,081 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 93 Total time for transactions(ms): 20 Number of transactions batched in Syncs: 31 Number of syncs: 76 SyncTimes(ms): 176 
2018-12-09 23:21:28,290 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741834_1010, replicas=172.18.0.2:50010 for /app/hbase/data/hbase/meta/1588230740/.tmp/103ac1667a594c298420fda2d77e0456
2018-12-09 23:21:28,327 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /app/hbase/data/hbase/meta/1588230740/.tmp/103ac1667a594c298420fda2d77e0456 is closed by DFSClient_NONMAPREDUCE_-357163669_13
2018-12-09 23:25:28,332 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 100 Total time for transactions(ms): 22 Number of transactions batched in Syncs: 32 Number of syncs: 82 SyncTimes(ms): 345 
2018-12-09 23:25:28,360 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741835_1011, replicas=172.18.0.2:50010 for /app/hbase/data/hbase/namespace/31204b170e968aadad88a1edfe27ef8f/.tmp/fee9cd3cbc3d4fc0bd2c3b6da87ebeee
2018-12-09 23:25:28,378 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /app/hbase/data/hbase/namespace/31204b170e968aadad88a1edfe27ef8f/.tmp/fee9cd3cbc3d4fc0bd2c3b6da87ebeee is closed by DFSClient_NONMAPREDUCE_-357163669_13
2018-12-10 00:04:58,379 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 108 Total time for transactions(ms): 26 Number of transactions batched in Syncs: 33 Number of syncs: 88 SyncTimes(ms): 350 
2018-12-10 00:05:58,568 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 139 Total time for transactions(ms): 35 Number of transactions batched in Syncs: 36 Number of syncs: 117 SyncTimes(ms): 467 
2018-12-10 00:06:09,474 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741836_1012, replicas=172.18.0.2:50010 for /mimic/admissions/ADMISSIONS.csv._COPYING_
2018-12-10 00:06:09,542 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /mimic/admissions/ADMISSIONS.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_1745208143_1
2018-12-10 00:06:11,509 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741837_1013, replicas=172.18.0.2:50010 for /mimic/callout/CALLOUT.csv._COPYING_
2018-12-10 00:06:11,574 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /mimic/callout/CALLOUT.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_-2145824810_1
2018-12-10 00:06:13,670 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741838_1014, replicas=172.18.0.2:50010 for /mimic/caregivers/CAREGIVERS.csv._COPYING_
2018-12-10 00:06:13,758 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /mimic/caregivers/CAREGIVERS.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1159826152_1
2018-12-10 00:06:15,887 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741839_1015, replicas=172.18.0.2:50010 for /mimic/chartevents/CHARTEVENTS.csv._COPYING_
2018-12-10 00:06:15,958 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /mimic/chartevents/CHARTEVENTS.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1669905890_1
2018-12-10 00:06:18,126 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741840_1016, replicas=172.18.0.2:50010 for /mimic/cptevents/CPTEVENTS.csv._COPYING_
2018-12-10 00:06:18,198 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /mimic/cptevents/CPTEVENTS.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_-882759565_1
2018-12-10 00:06:20,159 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741841_1017, replicas=172.18.0.2:50010 for /mimic/datetimeevents/DATETIMEEVENTS.csv._COPYING_
2018-12-10 00:06:20,223 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /mimic/datetimeevents/DATETIMEEVENTS.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_505673458_1
2018-12-10 00:06:22,245 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741842_1018, replicas=172.18.0.2:50010 for /mimic/diagnoses_icd/DIAGNOSES_ICD.csv._COPYING_
2018-12-10 00:06:22,306 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /mimic/diagnoses_icd/DIAGNOSES_ICD.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_-755216833_1
2018-12-10 00:06:24,343 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741843_1019, replicas=172.18.0.2:50010 for /mimic/drgcodes/DRGCODES.csv._COPYING_
2018-12-10 00:06:24,413 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /mimic/drgcodes/DRGCODES.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_-584018526_1
2018-12-10 00:06:26,445 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741844_1020, replicas=172.18.0.2:50010 for /mimic/d_cpt/D_CPT.csv._COPYING_
2018-12-10 00:06:26,516 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /mimic/d_cpt/D_CPT.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_-102712478_1
2018-12-10 00:06:28,533 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741845_1021, replicas=172.18.0.2:50010 for /mimic/d_icd_diagnoses/D_ICD_DIAGNOSES.csv._COPYING_
2018-12-10 00:06:28,597 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /mimic/d_icd_diagnoses/D_ICD_DIAGNOSES.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_1098510728_1
2018-12-10 00:06:30,644 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741846_1022, replicas=172.18.0.2:50010 for /mimic/d_icd_procedures/D_ICD_PROCEDURES.csv._COPYING_
2018-12-10 00:06:30,704 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /mimic/d_icd_procedures/D_ICD_PROCEDURES.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1163605145_1
2018-12-10 00:06:32,730 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741847_1023, replicas=172.18.0.2:50010 for /mimic/d_items/D_ITEMS.csv._COPYING_
2018-12-10 00:06:32,805 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /mimic/d_items/D_ITEMS.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1016646593_1
2018-12-10 00:06:34,874 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741848_1024, replicas=172.18.0.2:50010 for /mimic/d_labitems/D_LABITEMS.csv._COPYING_
2018-12-10 00:06:34,937 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /mimic/d_labitems/D_LABITEMS.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_-302907318_1
2018-12-10 00:06:36,932 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741849_1025, replicas=172.18.0.2:50010 for /mimic/icustays/ICUSTAYS.csv._COPYING_
2018-12-10 00:06:36,994 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /mimic/icustays/ICUSTAYS.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_-275687380_1
2018-12-10 00:06:39,086 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741850_1026, replicas=172.18.0.2:50010 for /mimic/inputevents_cv/INPUTEVENTS_CV.csv._COPYING_
2018-12-10 00:06:39,149 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /mimic/inputevents_cv/INPUTEVENTS_CV.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_1746823741_1
2018-12-10 00:06:41,180 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741851_1027, replicas=172.18.0.2:50010 for /mimic/inputevents_mv/INPUTEVENTS_MV.csv._COPYING_
2018-12-10 00:06:41,241 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /mimic/inputevents_mv/INPUTEVENTS_MV.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_587943511_1
2018-12-10 00:06:43,297 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741852_1028, replicas=172.18.0.2:50010 for /mimic/labevents/LABEVENTS.csv._COPYING_
2018-12-10 00:06:43,373 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /mimic/labevents/LABEVENTS.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_-120664533_1
2018-12-10 00:06:45,404 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741853_1029, replicas=172.18.0.2:50010 for /mimic/microbiologyevents/MICROBIOLOGYEVENTS.csv._COPYING_
2018-12-10 00:06:45,470 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /mimic/microbiologyevents/MICROBIOLOGYEVENTS.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_1879261207_1
2018-12-10 00:06:47,433 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741854_1030, replicas=172.18.0.2:50010 for /mimic/noteevents/NOTEEVENTS.csv._COPYING_
2018-12-10 00:06:47,573 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /mimic/noteevents/NOTEEVENTS.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_-381521964_1
2018-12-10 00:06:49,639 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741855_1031, replicas=172.18.0.2:50010 for /mimic/outputevents/OUTPUTEVENTS.csv._COPYING_
2018-12-10 00:06:49,702 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /mimic/outputevents/OUTPUTEVENTS.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_1410059055_1
2018-12-10 00:06:51,706 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741856_1032, replicas=172.18.0.2:50010 for /mimic/patients/PATIENTS.csv._COPYING_
2018-12-10 00:06:51,780 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /mimic/patients/PATIENTS.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1530858095_1
2018-12-10 00:06:53,797 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741857_1033, replicas=172.18.0.2:50010 for /mimic/prescriptions/PRESCRIPTIONS.csv._COPYING_
2018-12-10 00:06:53,866 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /mimic/prescriptions/PRESCRIPTIONS.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_1775902133_1
2018-12-10 00:06:55,854 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741858_1034, replicas=172.18.0.2:50010 for /mimic/procedureevents_mv/PROCEDUREEVENTS_MV.csv._COPYING_
2018-12-10 00:06:55,922 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /mimic/procedureevents_mv/PROCEDUREEVENTS_MV.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_771754890_1
2018-12-10 00:06:57,919 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741859_1035, replicas=172.18.0.2:50010 for /mimic/procedures_icd/PROCEDURES_ICD.csv._COPYING_
2018-12-10 00:06:57,977 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /mimic/procedures_icd/PROCEDURES_ICD.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_390993167_1
2018-12-10 00:06:59,939 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 319 Total time for transactions(ms): 47 Number of transactions batched in Syncs: 60 Number of syncs: 273 SyncTimes(ms): 654 
2018-12-10 00:06:59,969 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741860_1036, replicas=172.18.0.2:50010 for /mimic/services/SERVICES.csv._COPYING_
2018-12-10 00:07:00,028 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /mimic/services/SERVICES.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_683407729_1
2018-12-10 00:07:02,012 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741861_1037, replicas=172.18.0.2:50010 for /mimic/transfers/TRANSFERS.csv._COPYING_
2018-12-10 00:07:02,091 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /mimic/transfers/TRANSFERS.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_831778034_1
2018-12-10 00:07:04,134 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741862_1038, replicas=172.18.0.2:50010 for /ccs/ccs_dx_map/ccs_dx_map.csv._COPYING_
2018-12-10 00:07:04,205 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /ccs/ccs_dx_map/ccs_dx_map.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_-535854227_1
2018-12-10 00:07:06,343 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741863_1039, replicas=172.18.0.2:50010 for /ccs/ccs_proc_map/ccs_proc_map.csv._COPYING_
2018-12-10 00:07:06,412 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /ccs/ccs_proc_map/ccs_proc_map.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1011571407_1
2018-12-10 00:07:08,469 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741864_1040, replicas=172.18.0.2:50010 for /model/noteevents_with_topics/noteevents_with_topics.csv._COPYING_
2018-12-10 00:07:08,532 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /model/noteevents_with_topics/noteevents_with_topics.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_1054354412_1
2018-12-10 00:07:10,718 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741865_1041, replicas=172.18.0.2:50010 for /model/admissions_ccs_ohe/admissions_ccs_ohe.csv._COPYING_
2018-12-10 00:07:10,786 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /model/admissions_ccs_ohe/admissions_ccs_ohe.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_1481126651_1
2018-12-10 00:07:13,372 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741866_1042, replicas=172.18.0.2:50010 for /model/admissions_topic_scores/admissions_topic_scores.csv._COPYING_
2018-12-10 00:07:13,444 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /model/admissions_topic_scores/admissions_topic_scores.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_198926176_1
2018-12-10 00:14:13,192 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 361 Total time for transactions(ms): 48 Number of transactions batched in Syncs: 67 Number of syncs: 308 SyncTimes(ms): 703 
2018-12-10 00:14:13,225 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741867_1043, replicas=172.18.0.2:50010 for /mimic/admissions/ADMISSIONS.csv._COPYING_
2018-12-10 00:14:13,289 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /mimic/admissions/ADMISSIONS.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_139676296_1
2018-12-10 00:14:15,288 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741868_1044, replicas=172.18.0.2:50010 for /mimic/callout/CALLOUT.csv._COPYING_
2018-12-10 00:14:15,349 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /mimic/callout/CALLOUT.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1018835698_1
2018-12-10 00:14:17,380 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741869_1045, replicas=172.18.0.2:50010 for /mimic/caregivers/CAREGIVERS.csv._COPYING_
2018-12-10 00:14:17,442 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /mimic/caregivers/CAREGIVERS.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1228287473_1
2018-12-10 00:14:19,283 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741870_1046, replicas=172.18.0.2:50010 for /mimic/chartevents/CHARTEVENTS.csv._COPYING_
2018-12-10 00:14:19,344 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /mimic/chartevents/CHARTEVENTS.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_1063796141_1
2018-12-10 00:14:21,268 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741871_1047, replicas=172.18.0.2:50010 for /mimic/cptevents/CPTEVENTS.csv._COPYING_
2018-12-10 00:14:21,329 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /mimic/cptevents/CPTEVENTS.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_623847646_1
2018-12-10 00:14:23,372 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741872_1048, replicas=172.18.0.2:50010 for /mimic/datetimeevents/DATETIMEEVENTS.csv._COPYING_
2018-12-10 00:14:23,434 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /mimic/datetimeevents/DATETIMEEVENTS.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1373983623_1
2018-12-10 00:14:25,391 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741873_1049, replicas=172.18.0.2:50010 for /mimic/diagnoses_icd/DIAGNOSES_ICD.csv._COPYING_
2018-12-10 00:14:25,450 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /mimic/diagnoses_icd/DIAGNOSES_ICD.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1655571858_1
2018-12-10 00:14:27,406 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741874_1050, replicas=172.18.0.2:50010 for /mimic/drgcodes/DRGCODES.csv._COPYING_
2018-12-10 00:14:27,468 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /mimic/drgcodes/DRGCODES.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_-646926186_1
2018-12-10 00:14:29,432 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741875_1051, replicas=172.18.0.2:50010 for /mimic/d_cpt/D_CPT.csv._COPYING_
2018-12-10 00:14:29,493 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /mimic/d_cpt/D_CPT.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_1138662953_1
2018-12-10 00:14:31,598 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741876_1052, replicas=172.18.0.2:50010 for /mimic/d_icd_diagnoses/D_ICD_DIAGNOSES.csv._COPYING_
2018-12-10 00:14:31,654 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /mimic/d_icd_diagnoses/D_ICD_DIAGNOSES.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_1786783553_1
2018-12-10 00:14:33,685 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741877_1053, replicas=172.18.0.2:50010 for /mimic/d_icd_procedures/D_ICD_PROCEDURES.csv._COPYING_
2018-12-10 00:14:33,748 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /mimic/d_icd_procedures/D_ICD_PROCEDURES.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_1173452001_1
2018-12-10 00:14:35,828 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741878_1054, replicas=172.18.0.2:50010 for /mimic/d_items/D_ITEMS.csv._COPYING_
2018-12-10 00:14:35,886 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /mimic/d_items/D_ITEMS.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1837507050_1
2018-12-10 00:14:37,779 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741879_1055, replicas=172.18.0.2:50010 for /mimic/d_labitems/D_LABITEMS.csv._COPYING_
2018-12-10 00:14:37,847 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /mimic/d_labitems/D_LABITEMS.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_1864714011_1
2018-12-10 00:14:40,001 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741880_1056, replicas=172.18.0.2:50010 for /mimic/icustays/ICUSTAYS.csv._COPYING_
2018-12-10 00:14:40,073 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /mimic/icustays/ICUSTAYS.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1293859925_1
2018-12-10 00:14:42,232 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741881_1057, replicas=172.18.0.2:50010 for /mimic/inputevents_cv/INPUTEVENTS_CV.csv._COPYING_
2018-12-10 00:14:42,302 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /mimic/inputevents_cv/INPUTEVENTS_CV.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_-2012339777_1
2018-12-10 00:14:44,703 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741882_1058, replicas=172.18.0.2:50010 for /mimic/inputevents_mv/INPUTEVENTS_MV.csv._COPYING_
2018-12-10 00:14:44,778 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /mimic/inputevents_mv/INPUTEVENTS_MV.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_-39685858_1
2018-12-10 00:14:47,031 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741883_1059, replicas=172.18.0.2:50010 for /mimic/labevents/LABEVENTS.csv._COPYING_
2018-12-10 00:14:47,093 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /mimic/labevents/LABEVENTS.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_502607498_1
2018-12-10 00:14:50,589 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741884_1060, replicas=172.18.0.2:50010 for /mimic/microbiologyevents/MICROBIOLOGYEVENTS.csv._COPYING_
2018-12-10 00:14:50,668 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /mimic/microbiologyevents/MICROBIOLOGYEVENTS.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1202131617_1
2018-12-10 00:14:53,186 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741885_1061, replicas=172.18.0.2:50010 for /mimic/noteevents/NOTEEVENTS.csv._COPYING_
2018-12-10 00:14:53,321 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /mimic/noteevents/NOTEEVENTS.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_897620751_1
2018-12-10 00:14:55,676 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741886_1062, replicas=172.18.0.2:50010 for /mimic/outputevents/OUTPUTEVENTS.csv._COPYING_
2018-12-10 00:14:55,744 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /mimic/outputevents/OUTPUTEVENTS.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_1280661425_1
2018-12-10 00:14:58,129 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741887_1063, replicas=172.18.0.2:50010 for /mimic/patients/PATIENTS.csv._COPYING_
2018-12-10 00:14:58,202 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /mimic/patients/PATIENTS.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_544400930_1
2018-12-10 00:15:00,275 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741888_1064, replicas=172.18.0.2:50010 for /mimic/prescriptions/PRESCRIPTIONS.csv._COPYING_
2018-12-10 00:15:00,335 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /mimic/prescriptions/PRESCRIPTIONS.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_1886787394_1
2018-12-10 00:15:02,438 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741889_1065, replicas=172.18.0.2:50010 for /mimic/procedureevents_mv/PROCEDUREEVENTS_MV.csv._COPYING_
2018-12-10 00:15:02,502 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /mimic/procedureevents_mv/PROCEDUREEVENTS_MV.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1939213938_1
2018-12-10 00:15:04,626 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741890_1066, replicas=172.18.0.2:50010 for /mimic/procedures_icd/PROCEDURES_ICD.csv._COPYING_
2018-12-10 00:15:04,686 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /mimic/procedures_icd/PROCEDURES_ICD.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1082300985_1
2018-12-10 00:15:06,857 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741891_1067, replicas=172.18.0.2:50010 for /mimic/services/SERVICES.csv._COPYING_
2018-12-10 00:15:06,920 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /mimic/services/SERVICES.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_195689125_1
2018-12-10 00:15:09,013 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741892_1068, replicas=172.18.0.2:50010 for /mimic/transfers/TRANSFERS.csv._COPYING_
2018-12-10 00:15:09,078 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /mimic/transfers/TRANSFERS.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_102578802_1
2018-12-10 00:15:11,438 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741893_1069, replicas=172.18.0.2:50010 for /ccs/ccs_dx_map/ccs_dx_map.csv._COPYING_
2018-12-10 00:15:11,505 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /ccs/ccs_dx_map/ccs_dx_map.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_1807009785_1
2018-12-10 00:15:13,596 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 550 Total time for transactions(ms): 55 Number of transactions batched in Syncs: 94 Number of syncs: 470 SyncTimes(ms): 915 
2018-12-10 00:15:13,628 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741894_1070, replicas=172.18.0.2:50010 for /ccs/ccs_proc_map/ccs_proc_map.csv._COPYING_
2018-12-10 00:15:13,700 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /ccs/ccs_proc_map/ccs_proc_map.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_570654469_1
2018-12-10 00:15:15,739 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741895_1071, replicas=172.18.0.2:50010 for /model/noteevents_with_topics/noteevents_with_topics.csv._COPYING_
2018-12-10 00:15:15,802 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /model/noteevents_with_topics/noteevents_with_topics.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1839667483_1
2018-12-10 00:15:17,985 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741896_1072, replicas=172.18.0.2:50010 for /model/admissions_ccs_ohe/admissions_ccs_ohe.csv._COPYING_
2018-12-10 00:15:18,046 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /model/admissions_ccs_ohe/admissions_ccs_ohe.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1724505718_1
2018-12-10 00:15:20,104 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741897_1073, replicas=172.18.0.2:50010 for /model/admissions_topic_scores/admissions_topic_scores.csv._COPYING_
2018-12-10 00:15:20,174 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /model/admissions_topic_scores/admissions_topic_scores.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_-891140606_1
2018-12-10 00:15:46,040 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741898_1074, replicas=172.18.0.2:50010 for /app/hbase/WALs/bootcamp.local,16020,1544397335818/bootcamp.local%2C16020%2C1544397335818.1544400946027
2018-12-10 00:15:46,055 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* fsync: /app/hbase/WALs/bootcamp.local,16020,1544397335818/bootcamp.local%2C16020%2C1544397335818.1544400946027 for DFSClient_NONMAPREDUCE_-357163669_13
2018-12-10 00:15:46,066 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /app/hbase/WALs/bootcamp.local,16020,1544397335818/bootcamp.local%2C16020%2C1544397335818.1544397351865 is closed by DFSClient_NONMAPREDUCE_-357163669_13
2018-12-10 00:16:00,972 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741899_1075, replicas=172.18.0.2:50010 for /app/hbase/WALs/bootcamp.local,16020,1544397335818/bootcamp.local%2C16020%2C1544397335818.meta.1544400960962.meta
2018-12-10 00:16:00,981 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* fsync: /app/hbase/WALs/bootcamp.local,16020,1544397335818/bootcamp.local%2C16020%2C1544397335818.meta.1544400960962.meta for DFSClient_NONMAPREDUCE_-357163669_13
2018-12-10 00:16:00,989 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /app/hbase/WALs/bootcamp.local,16020,1544397335818/bootcamp.local%2C16020%2C1544397335818.meta.1544397353367.meta is closed by DFSClient_NONMAPREDUCE_-357163669_13
2018-12-10 00:16:15,336 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 594 Total time for transactions(ms): 55 Number of transactions batched in Syncs: 100 Number of syncs: 508 SyncTimes(ms): 962 
2018-12-10 00:16:15,342 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741900_1076, replicas=172.18.0.2:50010 for /app/hbase/MasterProcWALs/state-00000000000000000002.log
2018-12-10 00:16:15,353 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /app/hbase/MasterProcWALs/state-00000000000000000002.log is closed by DFSClient_NONMAPREDUCE_-251611999_1
2018-12-10 00:25:36,262 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 600 Total time for transactions(ms): 56 Number of transactions batched in Syncs: 101 Number of syncs: 513 SyncTimes(ms): 966 
2018-12-10 00:25:36,770 INFO BlockStateChange: BLOCK* processReport 0x777eb1190ac402e: from storage DS-f541c8b5-4c54-4986-a55f-c745d8545f6b node DatanodeRegistration(172.18.0.2:50010, datanodeUuid=095e4930-ee10-452b-bba9-ea1d76f04efc, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-57;cid=CID-bb9b1db8-7c08-4376-9eaf-2b0aa96d167e;nsid=212088389;c=1544396815977), blocks: 43, hasStaleStorage: false, processing time: 1 msecs, invalidatedBlocks: 0
2018-12-10 00:26:40,720 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 604 Total time for transactions(ms): 56 Number of transactions batched in Syncs: 101 Number of syncs: 517 SyncTimes(ms): 971 
2018-12-10 00:27:40,968 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 608 Total time for transactions(ms): 57 Number of transactions batched in Syncs: 101 Number of syncs: 521 SyncTimes(ms): 984 
2018-12-10 00:28:41,214 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 610 Total time for transactions(ms): 57 Number of transactions batched in Syncs: 101 Number of syncs: 523 SyncTimes(ms): 988 
2018-12-10 00:29:41,520 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 612 Total time for transactions(ms): 57 Number of transactions batched in Syncs: 101 Number of syncs: 525 SyncTimes(ms): 990 
2018-12-10 00:30:17,391 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741901_1077, replicas=172.18.0.2:50010 for /mimic/admissions/ADMISSIONS.csv._COPYING_
2018-12-10 00:30:17,452 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /mimic/admissions/ADMISSIONS.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1911484520_1
2018-12-10 00:30:19,392 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741902_1078, replicas=172.18.0.2:50010 for /mimic/callout/CALLOUT.csv._COPYING_
2018-12-10 00:30:19,454 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /mimic/callout/CALLOUT.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_1493794048_1
2018-12-10 00:30:21,378 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741903_1079, replicas=172.18.0.2:50010 for /mimic/caregivers/CAREGIVERS.csv._COPYING_
2018-12-10 00:30:21,439 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /mimic/caregivers/CAREGIVERS.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_-27224732_1
2018-12-10 00:30:23,394 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741904_1080, replicas=172.18.0.2:50010 for /mimic/chartevents/CHARTEVENTS.csv._COPYING_
2018-12-10 00:30:23,456 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /mimic/chartevents/CHARTEVENTS.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_-159516928_1
2018-12-10 00:30:25,455 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741905_1081, replicas=172.18.0.2:50010 for /mimic/cptevents/CPTEVENTS.csv._COPYING_
2018-12-10 00:30:25,517 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /mimic/cptevents/CPTEVENTS.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1173457300_1
2018-12-10 00:30:27,403 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741906_1082, replicas=172.18.0.2:50010 for /mimic/datetimeevents/DATETIMEEVENTS.csv._COPYING_
2018-12-10 00:30:27,458 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /mimic/datetimeevents/DATETIMEEVENTS.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_2072814446_1
2018-12-10 00:30:29,348 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741907_1083, replicas=172.18.0.2:50010 for /mimic/diagnoses_icd/DIAGNOSES_ICD.csv._COPYING_
2018-12-10 00:30:29,405 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /mimic/diagnoses_icd/DIAGNOSES_ICD.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_-536133768_1
2018-12-10 00:30:31,358 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741908_1084, replicas=172.18.0.2:50010 for /mimic/drgcodes/DRGCODES.csv._COPYING_
2018-12-10 00:30:31,421 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /mimic/drgcodes/DRGCODES.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_2024881627_1
2018-12-10 00:30:33,385 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741909_1085, replicas=172.18.0.2:50010 for /mimic/d_cpt/D_CPT.csv._COPYING_
2018-12-10 00:30:33,444 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /mimic/d_cpt/D_CPT.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_641430382_1
2018-12-10 00:30:35,424 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741910_1086, replicas=172.18.0.2:50010 for /mimic/d_icd_diagnoses/D_ICD_DIAGNOSES.csv._COPYING_
2018-12-10 00:30:35,482 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /mimic/d_icd_diagnoses/D_ICD_DIAGNOSES.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1226202838_1
2018-12-10 00:30:37,464 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741911_1087, replicas=172.18.0.2:50010 for /mimic/d_icd_procedures/D_ICD_PROCEDURES.csv._COPYING_
2018-12-10 00:30:37,518 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /mimic/d_icd_procedures/D_ICD_PROCEDURES.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_-374369740_1
2018-12-10 00:30:39,510 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741912_1088, replicas=172.18.0.2:50010 for /mimic/d_items/D_ITEMS.csv._COPYING_
2018-12-10 00:30:39,565 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /mimic/d_items/D_ITEMS.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1825399833_1
2018-12-10 00:30:41,512 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 698 Total time for transactions(ms): 61 Number of transactions batched in Syncs: 113 Number of syncs: 599 SyncTimes(ms): 1093 
2018-12-10 00:30:41,545 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741913_1089, replicas=172.18.0.2:50010 for /mimic/d_labitems/D_LABITEMS.csv._COPYING_
2018-12-10 00:30:41,610 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* blk_1073741913_1089 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /mimic/d_labitems/D_LABITEMS.csv._COPYING_
2018-12-10 00:30:42,014 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /mimic/d_labitems/D_LABITEMS.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_-606761735_1
2018-12-10 00:30:43,989 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741914_1090, replicas=172.18.0.2:50010 for /mimic/icustays/ICUSTAYS.csv._COPYING_
2018-12-10 00:30:44,050 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /mimic/icustays/ICUSTAYS.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_1426786512_1
2018-12-10 00:30:45,985 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741915_1091, replicas=172.18.0.2:50010 for /mimic/inputevents_cv/INPUTEVENTS_CV.csv._COPYING_
2018-12-10 00:30:46,044 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /mimic/inputevents_cv/INPUTEVENTS_CV.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_-540151488_1
2018-12-10 00:30:48,009 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741916_1092, replicas=172.18.0.2:50010 for /mimic/inputevents_mv/INPUTEVENTS_MV.csv._COPYING_
2018-12-10 00:30:48,068 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /mimic/inputevents_mv/INPUTEVENTS_MV.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_-466758038_1
2018-12-10 00:30:50,071 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741917_1093, replicas=172.18.0.2:50010 for /mimic/labevents/LABEVENTS.csv._COPYING_
2018-12-10 00:30:50,134 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /mimic/labevents/LABEVENTS.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_1434316249_1
2018-12-10 00:30:52,181 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741918_1094, replicas=172.18.0.2:50010 for /mimic/microbiologyevents/MICROBIOLOGYEVENTS.csv._COPYING_
2018-12-10 00:30:52,244 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /mimic/microbiologyevents/MICROBIOLOGYEVENTS.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_437486896_1
2018-12-10 00:30:54,307 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741919_1095, replicas=172.18.0.2:50010 for /mimic/noteevents/NOTEEVENTS.csv._COPYING_
2018-12-10 00:30:54,437 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /mimic/noteevents/NOTEEVENTS.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_-241671661_1
2018-12-10 00:30:56,476 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741920_1096, replicas=172.18.0.2:50010 for /mimic/outputevents/OUTPUTEVENTS.csv._COPYING_
2018-12-10 00:30:56,533 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /mimic/outputevents/OUTPUTEVENTS.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_-687913119_1
2018-12-10 00:30:58,508 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741921_1097, replicas=172.18.0.2:50010 for /mimic/patients/PATIENTS.csv._COPYING_
2018-12-10 00:30:58,571 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /mimic/patients/PATIENTS.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_-22952477_1
2018-12-10 00:31:00,726 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741922_1098, replicas=172.18.0.2:50010 for /mimic/prescriptions/PRESCRIPTIONS.csv._COPYING_
2018-12-10 00:31:00,784 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /mimic/prescriptions/PRESCRIPTIONS.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_1462843838_1
2018-12-10 00:31:02,872 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741923_1099, replicas=172.18.0.2:50010 for /mimic/procedureevents_mv/PROCEDUREEVENTS_MV.csv._COPYING_
2018-12-10 00:31:02,951 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /mimic/procedureevents_mv/PROCEDUREEVENTS_MV.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_397922246_1
2018-12-10 00:31:04,910 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741924_1100, replicas=172.18.0.2:50010 for /mimic/procedures_icd/PROCEDURES_ICD.csv._COPYING_
2018-12-10 00:31:04,966 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /mimic/procedures_icd/PROCEDURES_ICD.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_-310707809_1
2018-12-10 00:31:06,953 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741925_1101, replicas=172.18.0.2:50010 for /mimic/services/SERVICES.csv._COPYING_
2018-12-10 00:31:07,008 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /mimic/services/SERVICES.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_1072328802_1
2018-12-10 00:31:08,969 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741926_1102, replicas=172.18.0.2:50010 for /mimic/transfers/TRANSFERS.csv._COPYING_
2018-12-10 00:31:09,025 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /mimic/transfers/TRANSFERS.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_-930467534_1
2018-12-10 00:31:10,911 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741927_1103, replicas=172.18.0.2:50010 for /ccs/ccs_dx_map/ccs_dx_map.csv._COPYING_
2018-12-10 00:31:10,980 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /ccs/ccs_dx_map/ccs_dx_map.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_1073731286_1
2018-12-10 00:31:12,801 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741928_1104, replicas=172.18.0.2:50010 for /ccs/ccs_proc_map/ccs_proc_map.csv._COPYING_
2018-12-10 00:31:12,858 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /ccs/ccs_proc_map/ccs_proc_map.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_1022095701_1
2018-12-10 00:31:14,671 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741929_1105, replicas=172.18.0.2:50010 for /model/noteevents_with_topics/noteevents_with_topics.csv._COPYING_
2018-12-10 00:31:14,727 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /model/noteevents_with_topics/noteevents_with_topics.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_1138906073_1
2018-12-10 00:31:16,781 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741930_1106, replicas=172.18.0.2:50010 for /model/admissions_ccs_ohe/admissions_ccs_ohe.csv._COPYING_
2018-12-10 00:31:16,836 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /model/admissions_ccs_ohe/admissions_ccs_ohe.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_1281325986_1
2018-12-10 00:31:18,784 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741931_1107, replicas=172.18.0.2:50010 for /model/admissions_topic_scores/admissions_topic_scores.csv._COPYING_
2018-12-10 00:31:18,841 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /model/admissions_topic_scores/admissions_topic_scores.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_200254107_1
2018-12-10 00:31:42,015 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 833 Total time for transactions(ms): 63 Number of transactions batched in Syncs: 132 Number of syncs: 715 SyncTimes(ms): 1249 
2018-12-10 00:32:42,232 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 835 Total time for transactions(ms): 63 Number of transactions batched in Syncs: 132 Number of syncs: 717 SyncTimes(ms): 1253 
2018-12-10 00:33:42,475 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 837 Total time for transactions(ms): 63 Number of transactions batched in Syncs: 132 Number of syncs: 719 SyncTimes(ms): 1255 
2018-12-10 00:34:42,727 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 839 Total time for transactions(ms): 63 Number of transactions batched in Syncs: 132 Number of syncs: 721 SyncTimes(ms): 1256 
2018-12-10 00:35:42,981 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 841 Total time for transactions(ms): 63 Number of transactions batched in Syncs: 132 Number of syncs: 723 SyncTimes(ms): 1259 
2018-12-10 00:46:37,032 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 854 Total time for transactions(ms): 63 Number of transactions batched in Syncs: 132 Number of syncs: 736 SyncTimes(ms): 1269 
2018-12-10 00:47:43,809 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 856 Total time for transactions(ms): 63 Number of transactions batched in Syncs: 132 Number of syncs: 738 SyncTimes(ms): 1273 
2018-12-10 00:48:24,461 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741932_1108, replicas=172.18.0.2:50010 for /mimic/admissions/ADMISSIONS.csv._COPYING_
2018-12-10 00:48:24,552 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /mimic/admissions/ADMISSIONS.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_309600680_1
2018-12-10 00:48:27,339 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741933_1109, replicas=172.18.0.2:50010 for /mimic/callout/CALLOUT.csv._COPYING_
2018-12-10 00:48:27,420 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /mimic/callout/CALLOUT.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_-191844753_1
2018-12-10 00:48:30,158 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741934_1110, replicas=172.18.0.2:50010 for /mimic/caregivers/CAREGIVERS.csv._COPYING_
2018-12-10 00:48:30,239 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /mimic/caregivers/CAREGIVERS.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1504138357_1
2018-12-10 00:48:33,249 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741935_1111, replicas=172.18.0.2:50010 for /mimic/chartevents/CHARTEVENTS.csv._COPYING_
2018-12-10 00:48:33,338 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /mimic/chartevents/CHARTEVENTS.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1572523954_1
2018-12-10 00:48:35,991 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741936_1112, replicas=172.18.0.2:50010 for /mimic/cptevents/CPTEVENTS.csv._COPYING_
2018-12-10 00:48:36,067 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /mimic/cptevents/CPTEVENTS.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_-778326502_1
2018-12-10 00:48:39,390 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741937_1113, replicas=172.18.0.2:50010 for /mimic/datetimeevents/DATETIMEEVENTS.csv._COPYING_
2018-12-10 00:48:39,487 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /mimic/datetimeevents/DATETIMEEVENTS.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1185274084_1
2018-12-10 00:48:42,429 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741938_1114, replicas=172.18.0.2:50010 for /mimic/diagnoses_icd/DIAGNOSES_ICD.csv._COPYING_
2018-12-10 00:48:42,512 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /mimic/diagnoses_icd/DIAGNOSES_ICD.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_-345295004_1
2018-12-10 00:48:44,436 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 907 Total time for transactions(ms): 65 Number of transactions batched in Syncs: 139 Number of syncs: 782 SyncTimes(ms): 1347 
2018-12-10 00:48:45,886 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741939_1115, replicas=172.18.0.2:50010 for /mimic/drgcodes/DRGCODES.csv._COPYING_
2018-12-10 00:48:45,987 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /mimic/drgcodes/DRGCODES.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_-361596848_1
2018-12-10 00:48:48,828 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741940_1116, replicas=172.18.0.2:50010 for /mimic/d_cpt/D_CPT.csv._COPYING_
2018-12-10 00:48:48,903 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /mimic/d_cpt/D_CPT.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_-502982883_1
2018-12-10 00:48:51,628 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741941_1117, replicas=172.18.0.2:50010 for /mimic/d_icd_diagnoses/D_ICD_DIAGNOSES.csv._COPYING_
2018-12-10 00:48:51,706 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /mimic/d_icd_diagnoses/D_ICD_DIAGNOSES.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1499712432_1
2018-12-10 00:48:55,806 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741942_1118, replicas=172.18.0.2:50010 for /mimic/d_icd_procedures/D_ICD_PROCEDURES.csv._COPYING_
2018-12-10 00:48:55,904 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /mimic/d_icd_procedures/D_ICD_PROCEDURES.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_414917068_1
2018-12-10 00:49:00,474 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741943_1119, replicas=172.18.0.2:50010 for /mimic/d_items/D_ITEMS.csv._COPYING_
2018-12-10 00:49:00,611 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /mimic/d_items/D_ITEMS.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_-426799855_1
2018-12-10 00:49:04,883 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741944_1120, replicas=172.18.0.2:50010 for /mimic/d_labitems/D_LABITEMS.csv._COPYING_
2018-12-10 00:49:05,006 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /mimic/d_labitems/D_LABITEMS.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_1064711923_1
2018-12-10 00:49:09,300 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741945_1121, replicas=172.18.0.2:50010 for /mimic/icustays/ICUSTAYS.csv._COPYING_
2018-12-10 00:49:09,422 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /mimic/icustays/ICUSTAYS.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_2046036678_1
2018-12-10 00:49:13,976 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741946_1122, replicas=172.18.0.2:50010 for /mimic/inputevents_cv/INPUTEVENTS_CV.csv._COPYING_
2018-12-10 00:49:14,083 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /mimic/inputevents_cv/INPUTEVENTS_CV.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_821578483_1
2018-12-10 00:49:17,697 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741947_1123, replicas=172.18.0.2:50010 for /mimic/inputevents_mv/INPUTEVENTS_MV.csv._COPYING_
2018-12-10 00:49:17,804 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /mimic/inputevents_mv/INPUTEVENTS_MV.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_492434906_1
2018-12-10 00:49:21,132 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741948_1124, replicas=172.18.0.2:50010 for /mimic/labevents/LABEVENTS.csv._COPYING_
2018-12-10 00:49:21,249 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /mimic/labevents/LABEVENTS.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_1557689119_1
2018-12-10 00:49:25,204 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741949_1125, replicas=172.18.0.2:50010 for /mimic/microbiologyevents/MICROBIOLOGYEVENTS.csv._COPYING_
2018-12-10 00:49:25,336 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /mimic/microbiologyevents/MICROBIOLOGYEVENTS.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_1143449405_1
2018-12-10 00:49:28,904 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741950_1126, replicas=172.18.0.2:50010 for /mimic/noteevents/NOTEEVENTS.csv._COPYING_
2018-12-10 00:49:29,133 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /mimic/noteevents/NOTEEVENTS.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_701911536_1
2018-12-10 00:49:32,809 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741951_1127, replicas=172.18.0.2:50010 for /mimic/outputevents/OUTPUTEVENTS.csv._COPYING_
2018-12-10 00:49:32,961 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /mimic/outputevents/OUTPUTEVENTS.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_17768154_1
2018-12-10 00:49:36,786 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741952_1128, replicas=172.18.0.2:50010 for /mimic/patients/PATIENTS.csv._COPYING_
2018-12-10 00:49:36,916 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /mimic/patients/PATIENTS.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1803485700_1
2018-12-10 00:49:40,167 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741953_1129, replicas=172.18.0.2:50010 for /mimic/prescriptions/PRESCRIPTIONS.csv._COPYING_
2018-12-10 00:49:40,276 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /mimic/prescriptions/PRESCRIPTIONS.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1439064686_1
2018-12-10 00:49:43,950 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741954_1130, replicas=172.18.0.2:50010 for /mimic/procedureevents_mv/PROCEDUREEVENTS_MV.csv._COPYING_
2018-12-10 00:49:44,068 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /mimic/procedureevents_mv/PROCEDUREEVENTS_MV.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_540617374_1
2018-12-10 00:49:45,087 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 1021 Total time for transactions(ms): 75 Number of transactions batched in Syncs: 155 Number of syncs: 880 SyncTimes(ms): 1542 
2018-12-10 00:49:47,829 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741955_1131, replicas=172.18.0.2:50010 for /mimic/procedures_icd/PROCEDURES_ICD.csv._COPYING_
2018-12-10 00:49:48,730 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /mimic/procedures_icd/PROCEDURES_ICD.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_-2103541445_1
2018-12-10 00:49:52,284 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741956_1132, replicas=172.18.0.2:50010 for /mimic/services/SERVICES.csv._COPYING_
2018-12-10 00:49:52,381 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /mimic/services/SERVICES.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1747414901_1
2018-12-10 00:49:55,676 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741957_1133, replicas=172.18.0.2:50010 for /mimic/transfers/TRANSFERS.csv._COPYING_
2018-12-10 00:49:55,786 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /mimic/transfers/TRANSFERS.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_-373323702_1
2018-12-10 00:49:59,351 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741958_1134, replicas=172.18.0.2:50010 for /ccs/ccs_dx_map/ccs_dx_map.csv._COPYING_
2018-12-10 00:49:59,456 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /ccs/ccs_dx_map/ccs_dx_map.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_969925731_1
2018-12-10 00:50:03,185 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741959_1135, replicas=172.18.0.2:50010 for /ccs/ccs_proc_map/ccs_proc_map.csv._COPYING_
2018-12-10 00:50:03,297 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /ccs/ccs_proc_map/ccs_proc_map.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_-934985656_1
2018-12-10 00:50:06,878 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741960_1136, replicas=172.18.0.2:50010 for /model/noteevents_with_topics/noteevents_with_topics.csv._COPYING_
2018-12-10 00:50:07,007 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /model/noteevents_with_topics/noteevents_with_topics.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1724798640_1
2018-12-10 00:50:10,274 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741961_1137, replicas=172.18.0.2:50010 for /model/admissions_ccs_ohe/admissions_ccs_ohe.csv._COPYING_
2018-12-10 00:50:10,361 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /model/admissions_ccs_ohe/admissions_ccs_ohe.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1544534833_1
2018-12-10 00:50:14,029 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741962_1138, replicas=172.18.0.2:50010 for /model/admissions_topic_scores/admissions_topic_scores.csv._COPYING_
2018-12-10 00:50:14,139 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /model/admissions_topic_scores/admissions_topic_scores.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1388963584_1
2018-12-10 00:50:45,755 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 1079 Total time for transactions(ms): 80 Number of transactions batched in Syncs: 163 Number of syncs: 930 SyncTimes(ms): 1637 
2018-12-10 00:51:46,128 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 1083 Total time for transactions(ms): 80 Number of transactions batched in Syncs: 163 Number of syncs: 934 SyncTimes(ms): 1646 
2018-12-10 00:52:46,425 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 1085 Total time for transactions(ms): 80 Number of transactions batched in Syncs: 163 Number of syncs: 936 SyncTimes(ms): 1647 
2018-12-10 00:53:46,697 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 1087 Total time for transactions(ms): 80 Number of transactions batched in Syncs: 163 Number of syncs: 938 SyncTimes(ms): 1650 
